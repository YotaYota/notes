<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Notes</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="network/network.html"><strong aria-hidden="true">1.</strong> Network</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="network/letsencrypy.html"><strong aria-hidden="true">1.1.</strong> letsencrypt</a></li><li class="chapter-item expanded "><a href="network/netconf_yang.html"><strong aria-hidden="true">1.2.</strong> NETConf YANG</a></li><li class="chapter-item expanded "><a href="network/tls.html"><strong aria-hidden="true">1.3.</strong> SSL/TLS</a></li></ol></li><li class="chapter-item expanded "><a href="js/js.html"><strong aria-hidden="true">2.</strong> Javascript</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="js/angular.html"><strong aria-hidden="true">2.1.</strong> angular</a></li><li class="chapter-item expanded "><a href="js/jest.html"><strong aria-hidden="true">2.2.</strong> jest</a></li><li class="chapter-item expanded "><a href="js/js.html"><strong aria-hidden="true">2.3.</strong> js</a></li><li class="chapter-item expanded "><a href="js/react.html"><strong aria-hidden="true">2.4.</strong> react</a></li></ol></li><li class="chapter-item expanded "><a href="python/main.html"><strong aria-hidden="true">3.</strong> Python</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="python/dist.html"><strong aria-hidden="true">3.1.</strong> dist</a></li></ol></li><li class="chapter-item expanded "><a href="aws/aws.html"><strong aria-hidden="true">4.</strong> AWS</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="aws/api_gateway.html"><strong aria-hidden="true">4.1.</strong> API Gateway</a></li><li class="chapter-item expanded "><a href="aws/ccp.html"><strong aria-hidden="true">4.2.</strong> CCP</a></li><li class="chapter-item expanded "><a href="aws/cli.html"><strong aria-hidden="true">4.3.</strong> CLI</a></li><li class="chapter-item expanded "><a href="aws/cognito.html"><strong aria-hidden="true">4.4.</strong> Cognito</a></li><li class="chapter-item expanded "><a href="aws/dynamodb.html"><strong aria-hidden="true">4.5.</strong> DynamoDB</a></li><li class="chapter-item expanded "><a href="aws/static_website.html"><strong aria-hidden="true">4.6.</strong> Static Website</a></li><li class="chapter-item expanded "><a href="aws/iam.html"><strong aria-hidden="true">4.7.</strong> IAM</a></li><li class="chapter-item expanded "><a href="aws/lambda.html"><strong aria-hidden="true">4.8.</strong> Lambda</a></li></ol></li><li class="chapter-item expanded "><a href="linux/linux.html"><strong aria-hidden="true">5.</strong> Linux - Systemd</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="linux/systemd.html"><strong aria-hidden="true">5.1.</strong> systemd</a></li><li class="chapter-item expanded "><a href="linux/users-groups.html"><strong aria-hidden="true">5.2.</strong> users-groups</a></li><li class="chapter-item expanded "><a href="linux/deb_pkg.html"><strong aria-hidden="true">5.3.</strong> Debian Packaging</a></li><li class="chapter-item expanded "><a href="linux/essential_tools.html"><strong aria-hidden="true">5.4.</strong> Essential Tools</a></li><li class="chapter-item expanded "><a href="linux/iproute2.html"><strong aria-hidden="true">5.5.</strong> IProute2</a></li><li class="chapter-item expanded "><a href="linux/wireguard.html"><strong aria-hidden="true">5.6.</strong> Wireguard</a></li><li class="chapter-item expanded "><a href="linux/kvm.html"><strong aria-hidden="true">5.7.</strong> KVM</a></li><li class="chapter-item expanded "><a href="linux/logging.html"><strong aria-hidden="true">5.8.</strong> Logging</a></li><li class="chapter-item expanded "><a href="linux/lutris.html"><strong aria-hidden="true">5.9.</strong> Lutris</a></li><li class="chapter-item expanded "><a href="linux/nftables.html"><strong aria-hidden="true">5.10.</strong> nftables</a></li><li class="chapter-item expanded "><a href="linux/screen.html"><strong aria-hidden="true">5.11.</strong> screen</a></li><li class="chapter-item expanded "><a href="linux/wine.html"><strong aria-hidden="true">5.12.</strong> Wine</a></li></ol></li><li class="chapter-item expanded "><a href="rust/rust.html"><strong aria-hidden="true">6.</strong> rust</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="rust/rust_web_app.html"><strong aria-hidden="true">6.1.</strong> Web App</a></li><li class="chapter-item expanded "><a href="rust/bevy.html"><strong aria-hidden="true">6.2.</strong> Bevy</a></li></ol></li><li class="chapter-item expanded "><a href="gpg.html"><strong aria-hidden="true">7.</strong> gpg</a></li><li class="chapter-item expanded "><a href="ssh.html"><strong aria-hidden="true">8.</strong> ssh</a></li><li class="chapter-item expanded "><a href="yubikey.html"><strong aria-hidden="true">9.</strong> yubikey</a></li><li class="chapter-item expanded "><a href="git.html"><strong aria-hidden="true">10.</strong> git</a></li><li class="chapter-item expanded "><a href="neovim.html"><strong aria-hidden="true">11.</strong> neovim</a></li><li class="chapter-item expanded "><a href="compdocs.html"><strong aria-hidden="true">12.</strong> compdocs</a></li><li class="chapter-item expanded "><a href="cpp.html"><strong aria-hidden="true">13.</strong> C++</a></li><li class="chapter-item expanded "><a href="docker.html"><strong aria-hidden="true">14.</strong> Docker</a></li><li class="chapter-item expanded "><a href="flatbuffers.html"><strong aria-hidden="true">15.</strong> flatbuffers</a></li><li class="chapter-item expanded "><a href="protbuf.html"><strong aria-hidden="true">16.</strong> protbuf</a></li><li class="chapter-item expanded "><a href="geojson.html"><strong aria-hidden="true">17.</strong> geojson</a></li><li class="chapter-item expanded "><a href="java.html"><strong aria-hidden="true">18.</strong> Java</a></li><li class="chapter-item expanded "><a href="jwt.html"><strong aria-hidden="true">19.</strong> JWT</a></li><li class="chapter-item expanded "><a href="kubernetes.html"><strong aria-hidden="true">20.</strong> Kubernetes</a></li><li class="chapter-item expanded "><a href="patterns.html"><strong aria-hidden="true">21.</strong> Patterns</a></li><li class="chapter-item expanded "><a href="puppet.html"><strong aria-hidden="true">22.</strong> puppet</a></li><li class="chapter-item expanded "><a href="raid.html"><strong aria-hidden="true">23.</strong> RAID</a></li><li class="chapter-item expanded "><a href="scrum.html"><strong aria-hidden="true">24.</strong> SCRUM</a></li><li class="chapter-item expanded "><a href="serverless-framework.html"><strong aria-hidden="true">25.</strong> serverless-framework</a></li><li class="chapter-item expanded "><a href="spring.html"><strong aria-hidden="true">26.</strong> Spring</a></li><li class="chapter-item expanded "><a href="sql.html"><strong aria-hidden="true">27.</strong> SQL</a></li><li class="chapter-item expanded "><a href="terraform.html"><strong aria-hidden="true">28.</strong> Terraform</a></li><li class="chapter-item expanded "><a href="clean_architecture.html"><strong aria-hidden="true">29.</strong> Clean Architecture</a></li><li class="chapter-item expanded "><a href="vocabulary.html"><strong aria-hidden="true">30.</strong> Vocabulary</a></li><li class="chapter-item expanded "><a href="work_strategy.html"><strong aria-hidden="true">31.</strong> Work Stratrgy</a></li><li class="chapter-item expanded "><a href="project.html"><strong aria-hidden="true">32.</strong> Project</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Notes</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="network"><a class="header" href="#network">Network</a></h1>
<ul>
<li><code>ip link list</code></li>
<li><code>ip address show</code></li>
<li><code>ip neigh show</code> ARP table</li>
<li><code>ip route show</code></li>
</ul>
<p>Default gateway is know throught the word <strong>via</strong> in the output.</p>
<h2 id="osi"><a class="header" href="#osi">OSI</a></h2>
<div class="table-wrapper"><table><thead><tr><th></th><th></th></tr></thead><tbody>
<tr><td><strong>Userspace</strong></td><td></td></tr>
<tr><td>Layer 7</td><td>Application</td></tr>
<tr><td>Layer 6</td><td>Presentation</td></tr>
<tr><td>Layer 5</td><td>Session</td></tr>
<tr><td><strong>Kernel</strong></td><td></td></tr>
<tr><td>Layer 4</td><td>Transport</td></tr>
<tr><td>Layer 3</td><td>Network</td></tr>
<tr><td>Layer 2</td><td>Data Link</td></tr>
<tr><td><strong>Physical</strong></td><td></td></tr>
<tr><td>Layer 1</td><td>Physical</td></tr>
</tbody></table>
</div>
<p>The 7 layer model is outdated, in preference of the 4 layer model. The only important legacy is the numbering system.</p>
<h2 id="routing-table"><a class="header" href="#routing-table">Routing Table</a></h2>
<p>A list of every Layer 3 network the router knows about and how to get there.</p>
<p><code>ip rule list</code> lists the rules.</p>
<p>By default there are 3 tables: <em>main</em>, <em>local</em> and <em>default</em>. ip tool modifies main and local.</p>
<p><code>ip route list table main</code></p>
<p>route tables are in <em>/etc/iproute2/rt_tables</em>.</p>
<p><code>ip route get &lt;ip&gt;</code> shows kernel's routing for an ip.</p>
<p>A router has a <em>Forwarding Information Base</em> (<strong>FIB</strong>) and a <em>Routing Information Base</em> (<strong>RIB</strong>). A router uses the RIB (in the <em>Control Plane</em>) to determine optimized, best routing rules.</p>
<p><strong>Note</strong>: FIB is not the same as routing table. A routing table maps IPs to a route - a FIB knows which headers to put on the packet.</p>
<h3 id="example"><a class="header" href="#example">Example</a></h3>
<pre><code>echo 200 John &gt;&gt; /etc/iproute2/rt_tables
</code></pre>
<p>creates a table <em>John</em>.</p>
<pre><code>ip rule add from 10.0.0.10 table John
</code></pre>
<p>creates a rule for <em>John</em> table.</p>
<p>Now <code>ip rule ls</code> will also list</p>
<pre><code>32765:	from 10.0.0.10 lookup John
</code></pre>
<h2 id="ip"><a class="header" href="#ip">IP</a></h2>
<p>These IPs are reserved for private use (<a href="https://datatracker.ietf.org/doc/html/rfc1918">RFC 1918</a>)</p>
<pre><code>     10.0.0.0        -   10.255.255.255  (10/8 prefix)
     172.16.0.0      -   172.31.255.255  (172.16/12 prefix)
     192.168.0.0     -   192.168.255.255 (192.168/16 prefix)
</code></pre>
<p>Similar for IPv6 is <a href="https://datatracker.ietf.org/doc/html/rfc4193">RFC 4193</a>.</p>
<p>loopback 127.0.0.1 address is so that the system can talk to itself and do self diagnostics.</p>
<h2 id="random-commands"><a class="header" href="#random-commands">Random commands</a></h2>
<pre><code>sudo ss -nltpu
</code></pre>
<pre><code>nstat
</code></pre>
<h2 id="dhcp"><a class="header" href="#dhcp">DHCP</a></h2>
<p>UDP, then Port 67 and 68 unicast.</p>
<ol>
<li>DHCP Discover (broadcast)</li>
<li>DHCP Offer (broadcast beacuse no ip assigned yet): network information such as client ip, subnet mask, default gateway ip, dns ip, ip lease time, dhcp server ip</li>
<li>DHCP Request: approves the ip</li>
<li>DHCP Ack (broadcast) with same information as in offer</li>
</ol>
<p>dhcpd deprecated in favor of kea.</p>
<h2 id="dns"><a class="header" href="#dns">DNS</a></h2>
<p>DNS - Domain Name System. Communicates on port 53.</p>
<p>Traditionally resolvconf, but replaced with systemd-resolved.</p>
<p>On Ubuntu <code>/etc/resolv.conf</code> is a link to <code>/run/systemd/resolve/stub-resolv.conf</code>.</p>
<p>systemd-resolved.service</p>
<pre><code>resolvectl status
</code></pre>
<p>DHCP is to dynamically get an IP. It communicates on ports 67 and 68.</p>
<p>If DHCP, then DNS server will be set automatically.</p>
<pre><code>dhclient
</code></pre>
<h3 id="letsencrypt-and-acme"><a class="header" href="#letsencrypt-and-acme">letsencrypt and ACME</a></h3>
<p>letsencrypt uses ACME protocol (<a href="https://datatracker.ietf.org/doc/html/rfc8555">RFC 8555</a>).</p>
<h2 id="network-interface"><a class="header" href="#network-interface">Network Interface</a></h2>
<p>Each connection to a node is called a "network interface". Linux gives these names like "eth0". <code>ip a</code> lists them.</p>
<p>The first of theese <code>lo</code> (loopback) represents the linux host itself.</p>
<ul>
<li><code>UP</code> means that the kernel thinks the interface is up</li>
<li><code>LOWER_UP</code> means that we have established a link at the physical layer; an electrical signal.</li>
</ul>
<h2 id="protocols"><a class="header" href="#protocols">Protocols</a></h2>
<ul>
<li>TCP</li>
<li>UDP</li>
<li>ICMP</li>
<li>BGP for updating routing tables (Bird)</li>
</ul>
<hr />
<h2 id="cs144"><a class="header" href="#cs144">CS144</a></h2>
<p>Biderectional, reliable byte stream.</p>
<p>Byte Stream Model.</p>
<p>HTTP document centric. Verbs and folder structure.</p>
<p>Packets: data and header.</p>
<p>4 layer model</p>
<div class="table-wrapper"><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Application</td><td>Biderectional reliable byte stream between two applications</td><td>HTTP, SMTP, SSH, FTP</td></tr>
<tr><td>Transport</td><td>Guarentees correct, in-order delivery of data end-to-end. Controls congestion</td><td>TCP, UDP, RTP</td></tr>
<tr><td>Network</td><td>Delivers datagrams end-to-end. Best-effor - no guarantees</td><td>Must use IP</td></tr>
<tr><td>Link</td><td>Delivers data over a single link</td><td>Ethernet. WiFi, DSL, 3G</td></tr>
</tbody></table>
</div>
<p>A router uses a Forwarding Table.</p>
<p><strong>Packet switching</strong>: Independently for each arriving packet, pick its outgoing link. If the link is free, send it. Else hold the packet for later.</p>
<p><strong>Flow</strong>: A collection of datagrams belonging to the same end-to-end communication.</p>
<p><strong>Connection</strong>: ?</p>
<h4 id="making-the-network-layer-work"><a class="header" href="#making-the-network-layer-work">Making the Network Layer Work</a></h4>
<ol>
<li>The IP protocol
<ul>
<li>Creation of IP datagrams</li>
<li>hop-by-hop delivery from end to end</li>
</ul>
</li>
<li>Routing Tables
<ul>
<li>Algorithm to populate forwarding tables</li>
</ul>
</li>
<li>ICMP
<ul>
<li>Communicates network layer information between end hosts and routers</li>
<li>Reports error conditions</li>
<li>Helps in diagnosing problems</li>
</ul>
</li>
</ol>
<h3 id="ip-1"><a class="header" href="#ip-1">IP</a></h3>
<ul>
<li>Datagram</li>
<li>Unreliable</li>
<li>Best effort</li>
<li>Connectionless</li>
</ul>
<p>IP makes no guarantees; that is the concern of the transport layer.</p>
<p>IP Service Model:</p>
<ol>
<li>Tries to prevent looping forever (TTL)</li>
<li>Will fragments if they are too long</li>
<li>Uses a header checksum to reduce chances od delivering datagram to wrong destination</li>
<li>Allows for new versions of IP</li>
<li>Allows for new options to be added to header</li>
</ol>
<pre><code>Bit 0
    0                   1                   2                   3
    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |Version|  IHL  |Type of Service|          Total Length         |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |         Identification        |Flags|      Fragment Offset    |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |  Time to Live |    Protocol   |         Header Checksum       |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                       Source Address                          |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                    Destination Address                        |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                   (Options)                   |   (Padding)   |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
IPv4 Datagram

IHL: Header Length
</code></pre>
<h3 id="principle-layering"><a class="header" href="#principle-layering">Principle: Layering</a></h3>
<p>Is the name we give to the organization of the system into a number of functional components or "layers".
Layers are hiearchial and communicate sequentially. Ie, each layer has only an interface to the layer directly above/below.</p>
<p>Each layer provides a service and abstracts it in an interface for the layers above.</p>
<p>Layering creates</p>
<ul>
<li>enables modularity (breaks down into smaller more manageable modules)</li>
<li>well-defined service (provides interface towards layer above)</li>
<li>reuse (layers below can be reused)</li>
<li>separation of concerns (caring about its own job without caring how other layers do theirs)</li>
<li>continuous improvement</li>
</ul>
<h3 id="principle-encapsulation"><a class="header" href="#principle-encapsulation">Principle: Encapsulation</a></h3>
<p>When combining layering and packet switching.</p>
<h3 id="endianess"><a class="header" href="#endianess">Endianess</a></h3>
<ul>
<li><strong>LSB</strong> Least Significant Byte or Little-Endian</li>
<li><strong>MSB</strong> Most Significant Byte or Big-Endian</li>
</ul>
<p>Network packets are Big-Endian.</p>
<h3 id="netmask"><a class="header" href="#netmask">Netmask</a></h3>
<p>Netmasks tells you witch IPs are local, or if packets needs to go through a router.</p>
<p><strong>CIDR</strong> Classless Inter-Domain Routing has powers of 2.</p>
<p>IANA is responsible of giving out /8s to RIRs.</p>
<h3 id="router"><a class="header" href="#router">Router</a></h3>
<p>A router have many links. To devcide on which link to forward packets, it uses <em>Longest Prefix Match</em>.
This is used to decide which link to take in a <strong>Forwarding Table</strong>. A Forwarding Table consists of two parts: a CIDR entry, and a <em>next-hop</em> for that CIDR entry.
The <em>default</em> route is the least specific match.</p>
<h3 id="arp"><a class="header" href="#arp">ARP</a></h3>
<p>Hosts needs to keep a mapping between MAC address and IP address.</p>
<h3 id="tcp"><a class="header" href="#tcp">TCP</a></h3>
<p>3-way-handshake:</p>
<ol>
<li>SYN</li>
<li>SYN + ACK</li>
<li>ACK</li>
</ol>
<p>A stream of bytes are delivered using TCP segments.</p>
<p>Teardown:</p>
<ol>
<li>A sends FIN to B</li>
<li>B continues to send Data + ACK (if it needs to)</li>
<li>B sends FIN</li>
<li>A sends ACK</li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>Property</th><th>Behavior</th></tr></thead><tbody>
<tr><td>Stream of bytes</td><td>Reliable byte delivery service</td></tr>
<tr><td>Reliable delivery</td><td><ol><li>ACK indicate correct delivery<li>Checksums detect corrupted data<li>Sequence numbers detect missing data<li>Flow-control prevents overriding reciever</ol></td></tr>
<tr><td>In-sequence</td><td>Data delivered to application in sequence transmitted</td></tr>
<tr><td>(Congestion Control)</td><td>Controls network congestion</td></tr>
</tbody></table>
</div>
<pre><code> 0                   1                   2                   3
 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|          Source Port          |       Destination Port        |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                        Sequence Number                        |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                    Acknowledgment Number                      |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|  Data |       |C|E|U|A|P|R|S|F|                               |
| Offset| Rsrvd |W|C|R|C|S|S|Y|I|            Window             |
|       |       |R|E|G|K|H|T|N|N|                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|           Checksum            |         Urgent Pointer        |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                           [Options]                           |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                                                               :
:                             Data                              :
:                                                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
TCP packet
</code></pre>
<p>The 5-tuple: (src addr, src port, dst port, dps addr, protocol) is a globally unique identifier of the connection. There is however a small chance that it could overlap a previous connection that has lingered on the net (eg in a router's buffer), therefore TCP also sends an initial sequence number (ISN) to minimize the chance of an ID-overlap.</p>
<h3 id="udp"><a class="header" href="#udp">UDP</a></h3>
<pre><code> 0      7 8     15 16    23 24    31
+--------+--------+--------+--------+
|     Source      |   Destination   |
|      Port       |      Port       |
+--------+--------+--------+--------+
|                 |                 |
|     Length      |    Checksum     |
+--------+--------+--------+--------+
|
|          data octets ...
+---------------- ...

     User Datagram Header Format
</code></pre>
<p>UDP checksum includes pieces of information from the IP layer, thus violating the layering principle. The upshot is that that UDP protocol can detect if datagrams were delivered to the wrong destination.</p>
<div class="table-wrapper"><table><thead><tr><th>Property</th><th>Behavior</th></tr></thead><tbody>
<tr><td>Connectionless Datagram Service</td><td>No connection established. Packets may show up in any order.</td></tr>
<tr><td>Self contained datagrams</td><td></td></tr>
<tr><td>Unreliable delivery</td><td><ol><li>no ACK<li>No mechanism to detect missing or mis-sequenced datagrams<li>No Flow-control</ol></td></tr>
</tbody></table>
</div>
<p>UDP prvides a simple datagram serice between processes. It is mostly used in cases where the datagram is self contained, eg DNS, NTP and DHCP.</p>
<h3 id="icmp"><a class="header" href="#icmp">ICMP</a></h3>
<p>Internet Control Message Protocol.</p>
<p>Transport layer protocol.</p>
<p>Used by ping and traceroute.</p>
<div class="table-wrapper"><table><thead><tr><th>Property</th><th>Behavior</th></tr></thead><tbody>
<tr><td>Reporting Message</td><td>Self-contained message reporting error</td></tr>
<tr><td>Unreliable</td><td>Simple datagram service - no retries</td></tr>
</tbody></table>
</div>
<h4 id="traceroute"><a class="header" href="#traceroute">Traceroute</a></h4>
<p>ICMP error message data takes the IP header and the first 8 bites of the IP payload. It then adds the headers Type and Code.</p>
<p>Client sends an UDP message with TTL set to 1. The next hop will return an ICMP message with the IP headers and the first 8 bytes of the original message - this information is enough for the client to figure out which was the original UDP message.
The client continues to do this with increasing TTL.
When reaching the host the client has deliberately chosen a strange port, so that the host will return an ICMP message "port unreachable".</p>
<h3 id="end-to-end-principle"><a class="header" href="#end-to-end-principle">End-to-End Principle</a></h3>
<p>First described by Saltzer, Reed and Clark in 1984.
Two principles: Weak and Strong.</p>
<p>The weak principle says that the network can only provide extra features if it has information about what the endpoints wants to achieve. Eg security can only be done correctly if the end applications does it.</p>
<p>The string principle says that nothing extra should be done in the network.
"The network's job is to transmit datagrams as efficiently and flexibly as possible. Eerything else should be done at the fringes..." - RFC 1958</p>
<p>The Strong End-to-End Principle makes extending network is easier (SOLID).</p>
<h3 id="error-detection-3-schemes"><a class="header" href="#error-detection-3-schemes">Error Detection: 3 schemes</a></h3>
<p>At a hight level, error detection bits are calculated over the payload data, and is then appended or prepended to the payload.</p>
<p>Networks in general uses 3 different error detection algorithms:</p>
<ul>
<li>Checksums adds up all the bytes (TCP and IP)
<ul>
<li>fast and easy to compute</li>
<li>not robust</li>
</ul>
</li>
<li>CRC, Cyclic Recundancy Codes (Ethernet)
<ul>
<li>A CRC of length c can detect any 2 bit errors, any burst of errors &lt; c bits long, any odd number of errors.</li>
</ul>
</li>
<li>MAC, Message Authentication Codes (TLS)
<ul>
<li>combines the message with some secret information to generate a value</li>
<li>robust to malicious modifications</li>
<li>any 2 messages have 2^(-c) chance of having the same code</li>
<li>Ceyptographically strong; not good for detection errors</li>
</ul>
</li>
</ul>
<h3 id="finite-state-machine-fsm"><a class="header" href="#finite-state-machine-fsm">Finite State Machine (FSM)</a></h3>
<p>Commonly used when specifying network protocols and systems.</p>
<p>A <strong>state</strong> is a particular configuration of the system. The system can only be in 1 state.</p>
<p><strong>Edges</strong> define how to transition between states. It includes information about <em>events</em> causing state transition, and <em>actions</em> taken on state transition.</p>
<p><img src="network/img/fsm_tcp_connection.png" alt="FSM for TCP Connection" /></p>
<h3 id="flow-control"><a class="header" href="#flow-control">Flow Control</a></h3>
<p>Don't send more packets than receiver can process. Receiver gives sender feedback.</p>
<p>Two basic approaches:</p>
<ul>
<li>Stop and wait</li>
<li>Sliding window</li>
</ul>
<h4 id="stop-and-wait"><a class="header" href="#stop-and-wait">Stop and Wait</a></h4>
<p>At most 1 packet in flight at any time.</p>
<p>Reciever recieves data and sends ACK.
Sender sends data, then waits for ACK until sending next. If no ACK is received until a timeout, it sends the packet again.</p>
<p>A bad scenario is if the ACK get received after the timeout, which triggers both a resend, and a send of new data. If one of those messages gets lost, and only one ACK is received from those, this could result in duplicates.</p>
<p>1-bit counter is an approach to handle this scenario, but it is only reliable if the network does not duplicate the package and packets are not delayed multiple timouts.</p>
<h4 id="sliding-window"><a class="header" href="#sliding-window">Sliding Window</a></h4>
<ul>
<li>A generalization of stop-and-wait: allow multiple un-acked segments.</li>
<li>Bound on number of un-acked segments, called <strong>window</strong>.</li>
<li>Sliding Window can keep the pipe full, ie utilizing the receiver's full potential.</li>
<li>Uses <em>cumulative acknowledgments</em>.
For sender:</li>
</ul>
<p>Every segment has a sequence number <strong>SeqNo</strong>.</p>
<p>Sender maintains 3 variables:</p>
<ul>
<li><strong>SWS</strong>: Send Window Size</li>
<li><strong>LAR</strong>: Last Acknowledgment Received</li>
<li><strong>LSS</strong>: Last Segment Sent</li>
</ul>
<p>Sender maintains the invariant</p>
<pre><code>(LSS - LAR) =&lt; SWS
</code></pre>
<p>Sender advances LAR on new acknowledgment. It cannot send LSS greater than SWS + LAR.</p>
<p>Receiver maintains 3 variables:</p>
<ul>
<li><strong>RWS</strong>: Received Window Size</li>
<li><strong>LAS</strong>: Last Acceptable Segment</li>
<li><strong>LSR</strong>: Last Segment Received</li>
</ul>
<p>Recceiver maintains the invariant</p>
<pre><code>(LAS - LSR) =&lt; RWS
</code></pre>
<p>If received packet is &lt; LAS, send cumulative acknowledgment (ie not always the last received, but the cumulativevly last received).</p>
<p><strong>Note</strong>: TCP is a sliding window protocol, but ACKs are instead next expected data, ie LAS + 1</p>
<h3 id="retransmission-strategies"><a class="header" href="#retransmission-strategies">Retransmission Strategies</a></h3>
<p>Essentially 2 strategies:</p>
<ul>
<li><strong>Go-back-N</strong>: one loss will lead to entire window retransmitting (pessimistic)</li>
<li><strong>Selective Repeat</strong>: one loss will lead to only that packet retransmitting (optimistic)</li>
</ul>
<h3 id="tcp-header"><a class="header" href="#tcp-header">TCP Header</a></h3>
<p>Standard TCP header is 20 bytes long.</p>
<p><em>checksum</em>: includes part of the IP header.</p>
<p>Flags:</p>
<ul>
<li>CWR + ECE: used warn senders of congestion thereby avoiding packet drops and retransmissions.</li>
<li>URG: Urgent</li>
<li>ACK: Acknowldegment</li>
<li>PSH: Push</li>
<li>RST: Reset to sequence number</li>
<li>SYN: Synchronize sequence number</li>
<li>FIN: For teardown</li>
</ul>
<h3 id="tcp-setup-and-teardown"><a class="header" href="#tcp-setup-and-teardown">TCP Setup and Teardown</a></h3>
<ul>
<li>3-way-handshake</li>
<li>simultaneous open</li>
<li>TCP state machine</li>
</ul>
<p>Having state on both ends turns out to be more efficient.</p>
<p><strong>3-way-handshake</strong></p>
<ol>
<li>Active opener sends a packet with the SYN bit set with a sequence number (often randomized).</li>
<li>Passive opener responds with SYN with a sequence number, it also ACKs the openers sequence number.</li>
<li>Active opener responds its sequence number + 1 and ACKs passive openers sequnce number.</li>
</ol>
<p><strong>Simultaneous open</strong></p>
<p>Both clientes know each other's port number.</p>
<ol>
<li>Both sides send SYN and sequence number at the same time.</li>
<li>Both sides ACKs the others sequence number</li>
</ol>
<p><strong>Note</strong>: Simultaneous open takes 4 messages, rather than 3.</p>
<p><strong>Teardown</strong></p>
<p>FIN means the sender has no more data to send. But the connection is not closed until both sides has sent a FIN.</p>
<ol>
<li>FIN and ACKs prevoius data</li>
<li>FIN and ACKs the fin</li>
<li>ACKs the fin</li>
</ol>
<p>To avoid problems if either the final ACK gets lost or the same port pair is reused, the active closer goes into <strong>TIME WAIT</strong>. It keeps the socket for twice the "maximum segment lifetime".</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lets-encrypt"><a class="header" href="#lets-encrypt">Let's Encrypt</a></h1>
<p>2 steps</p>
<ul>
<li>the agent proves to the CA that the web server controls a domain.</li>
<li>the agent can request, renew, and revoke certificates for that domain.</li>
</ul>
<p>certbot is a utility that automates Let's Encrypt challanges and certificate handling.</p>
<h2 id="domain-validation"><a class="header" href="#domain-validation">Domain Validation</a></h2>
<p>Let’s Encrypt identifies the server administrator by public key.</p>
<p>The Let’s Encrypt CA will look at the domain name being requested and issue one or more sets of challenges:</p>
<ul>
<li>Provisioning a DNS record, or</li>
<li>Provisioning an HTTP resource under a well-known URI</li>
</ul>
<p>Let’s Encrypt CA also provides a nonce that the agent must sign with its private key pair to prove that it controls the key pair.</p>
<p>Once the agent has completed these steps, it notifies the CA that it’s ready to complete validation.</p>
<p>The CA verifies the signature on the nonce, and it attempts to download the file from the web server and make sure it has the expected content.</p>
<p>The agent is then authorized to do certificate management for that domain.</p>
<p><strong>Note</strong>: The key pair used by the agent is calleda an <em>authorized key pair</em> for the domain.</p>
<h2 id="obtain-certificate"><a class="header" href="#obtain-certificate">Obtain Certificate</a></h2>
<p>The agent constructs a <em>PKCS#10</em> Certificate Signing Request (<a href="https://www.rfc-editor.org/rfc/rfc2986">RFC 2986</a>) for Let's Encrypt CA to issue a certificate for the domain with a specified public key.</p>
<p>The CSR includes a signature by the private key corresponding to the public key in the CSR.</p>
<p>The agent also signs the whole CSR with the authorized key for the domain.</p>
<p>Let's Encrypt CA verifies both signatures and issues a certificate with the public key provided in the CSR.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="netconf-yang"><a class="header" href="#netconf-yang">NETCONF YANG</a></h1>
<ul>
<li><a href="https://datatracker.ietf.org/doc/html/rfc6241">NETCONF RFC 6241</a></li>
<li><a href="https://datatracker.ietf.org/doc/html/rfc7950">YANG RFC 7950</a></li>
</ul>
<h2 id="netconf"><a class="header" href="#netconf">NETCONF</a></h2>
<p>NETCONF is a protocol defined by IETF to install, manipulate and delete the configuration of network devices.</p>
<p>NETCONF operations are realized on top of a Remote Procedure Call (RPC) layer using an XML encoding and provides a basic set of operations to edit and query configuration on a network device.</p>
<p>NETCONF allows network operators to lock and unlock data stores for better control over device configuration with RPC6241.</p>
<h3 id="operations"><a class="header" href="#operations">Operations</a></h3>
<ul>
<li><code>&lt;get&gt;</code></li>
<li><code>&lt;get-config&gt;</code></li>
<li><code>&lt;edit-config&gt;</code></li>
</ul>
<h3 id="datastore"><a class="header" href="#datastore">Datastore</a></h3>
<ul>
<li>Running [REQUIRED]</li>
<li>Candidate</li>
<li>Start-up</li>
</ul>
<h2 id="yang"><a class="header" href="#yang">YANG</a></h2>
<p>YANG is a data modelling lanuguage used to model configuration data, state data RPCs, and notifications for network management protocols.</p>
<p>YANG was originally designed to model configuration and state data manipulated by the Network Configuration Protocol (NETCONF), NETCONF RPCs, and NETCONF notifications.</p>
<p>YANG structures data models into modules and submodules. YANG defines four main types of data nodes for data modeling:</p>
<ul>
<li>Leaf nodes</li>
<li>Leaf-List Nodes</li>
<li>Container Nodes</li>
<li>List Nodes</li>
</ul>
<p>When a node is tagged with "config false", its subhierarchy is flagged as state data.  If it is tagged with "config true", its subhierarchy is flagged as configuration data.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tls"><a class="header" href="#tls">TLS</a></h1>
<p>TLS (formerly SSL).</p>
<p>TLS 1.3 <a href="https://datatracker.ietf.org/doc/html/rfc8446">RFC 8446</a>.</p>
<p>TLS 1.3 is a hybrid cryptosystem</p>
<ul>
<li>TLS Handshake with assymetric encryptions, using ephemeral Diffie-Hellman.</li>
<li>Use session keys (symmetric encryptions) for the rest of the session</li>
</ul>
<p><strong>Note</strong>: Symmetric encryption is much faster than assymetric.</p>
<h2 id="handshake"><a class="header" href="#handshake">Handshake</a></h2>
<ol>
<li><strong>Client hello</strong>: protocol version, "client random" (string of random bytes), list of cipher suites. Also parameters for calculating the premaster secret.</li>
<li><strong>Server generates master secret</strong>: creates the master secret using client random, cipher suites and a server random.</li>
<li><strong>Server hello and "Finished"</strong>: the server hello includes the server's certificate, digital signature, server random and chosen cipher suite. Also sends "Finished".</li>
<li><strong>Final steps and client "Finished"</strong>: client verifies signature and certificate, generates master secret. Sends "Finished".</li>
</ol>
<p>0-RTT mode for session resumption is also supported.</p>
<h2 id="certificate-signing-request-csr"><a class="header" href="#certificate-signing-request-csr">Certificate Signing Request (CSR)</a></h2>
<p>To obtain an SSL certificate from a Certificate Authority (<strong>CA</strong>), you must generate a Certificate Signing Request (<strong>CSR</strong>).</p>
<p>The information provided in the CSR is called Distinguished Name (<strong>DN</strong>). One of the fields in DN is Common Name (<strong>CN</strong>), which should be the FQDN.</p>
<p>CSR -&gt; CA = SSL certificate</p>
<h3 id="generate-private-key-and-csr"><a class="header" href="#generate-private-key-and-csr">Generate Private Key and CSR</a></h3>
<p>To create a new key and a CSR with <code>openssl</code>:</p>
<pre><code class="language-bash">openssl req \
    -newkey rsa:2048 \  # 2048-bit RSA key
    -nodes \            # private key not encrypted with pass phrase
    -keyout domain.key \
    -out domain.csr
</code></pre>
<p><strong>Note</strong>: <code>-new</code> is implied, which indicates that a CSR should be generated.</p>
<h3 id="generate-csr-from-private-key"><a class="header" href="#generate-csr-from-private-key">Generate CSR from Private Key</a></h3>
<p>To create a CSR from existing key</p>
<pre><code class="language-bash">openssl req \
    -key domain.key \   # existing private key
    -new \              # generate CSR
    -out domain.csr
</code></pre>
<h3 id="genereate-csr-from-certificate-and-private-key"><a class="header" href="#genereate-csr-from-certificate-and-private-key">Genereate CSR from Certificate and Private Key</a></h3>
<pre><code class="language-bash">openssl x509 \
    -in domain.crt \        # existing CSR
    -signkey domain.key \   # existing private key
    -x509toreq \            # using an X509 cert to make a CSR
    -out domain.csr
</code></pre>
<h2 id="self-signed-certificates"><a class="header" href="#self-signed-certificates">Self-Signed Certificates</a></h2>
<p>A <em>self-signed certificate</em> is not signed by a CA. A self-signed certificate is a certificate that is signed with its own private key.</p>
<p>Self-signed certificates should only be used if you do not need to prove your service's identity to its users.</p>
<h3 id="generate-self-signed-certificate"><a class="header" href="#generate-self-signed-certificate">Generate Self-Signed Certificate</a></h3>
<pre><code class="language-bash">openssl req \
    -newkey rsa:2048 \
    -nodes \
    -keyout domain.key \
    -x509 \                 # generates self-signed when together with req option 
    -days 365 \
    -out domain.crt         # temporary CSR
</code></pre>
<h3 id="generate-self-signed-certificate-from-private-key"><a class="header" href="#generate-self-signed-certificate-from-private-key">Generate Self-Signed Certificate from Private Key</a></h3>
<pre><code class="language-bash">openssl req \
    -key domain.key \   # existing private key
    -new \
    -x509 \
    -days 365 \
    -out domain.crt
</code></pre>
<h3 id="generate-self-signed-certificate-from-private-key-and-csr"><a class="header" href="#generate-self-signed-certificate-from-private-key-and-csr">Generate Self-Signed Certificate from Private Key and CSR</a></h3>
<pre><code class="language-bash">openssl x509 \
    -signkey domain.key \   # existing private key
    -in domain.csr \        # existing CSR
    -req \
    -days 365 \
    -out domain.crt
</code></pre>
<h2 id="viewing-certificates"><a class="header" href="#viewing-certificates">Viewing Certificates</a></h2>
<p>Certificate and CSR files are encoded in PEM format. <code>openssl</code> can be used to convert to and from other formats, such as DER, PKCS7, PKCS12.</p>
<p>To view a CSR</p>
<pre><code class="language-bash">openssl req -text -noout -verify -in domain.csr
</code></pre>
<p>To view a Certificate</p>
<pre><code class="language-bash">openssl x509 -text -noout -in domain.crt
</code></pre>
<p>Verify a certificate was signed by a CA</p>
<pre><code class="language-bash">openssl verify -verbose -CAFile ca.crt domain.crt
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="javascript"><a class="header" href="#javascript">Javascript</a></h1>
<h2 id="operators"><a class="header" href="#operators">Operators</a></h2>
<ul>
<li><code>&amp;&amp;</code> <strong>Logical AND</strong>. returns the value of the <em>first falsey operand</em> or the value of the last operand (if all are truthy).
<ul>
<li><code>true &amp;&amp; "hello"</code> returns <code>hello</code></li>
<li><code>0 &amp;&amp; "hello"</code> returns <code>0</code></li>
</ul>
</li>
<li><code>||</code> <strong>Logical OR</strong>. returns the value of the <em>first truthy operand</em> or the value of the last operand (if all are falsey).
<ul>
<li><code>42 || "hello"</code> returns <code>42</code></li>
<li><code>0 || "hello"</code> returns <code>hello</code></li>
<li><code>0 || false || "" </code> returns <code>""</code></li>
</ul>
</li>
</ul>
<h2 id="static-import-declaration"><a class="header" href="#static-import-declaration">Static <code>import</code> declaration</a></h2>
<p>Used to import read-only <em>live bindings</em> from another module. The imported
module will be evaluated at load time.</p>
<p>In order to use the <code>import</code> declaration in a source file, the file must be
interpreted by the runtime as a module.</p>
<p>If the same module is imported into multiple other modules, its code is executed
only once, upon the first import. Then its exports are given to all further
importers.</p>
<p><code>import</code> declarations can only be present in modules, and only at the top-level.</p>
<p>There are 4 form of <code>import</code> decalarations</p>
<ul>
<li>Named import <code>import { export1, export2 } from "module-name";</code></li>
<li>Default import <code>import defaultImport from "module-name";</code></li>
<li>Namespace import <code>import * as name from "module-name";</code></li>
<li>Side effect import <code>import "module-name";</code></li>
</ul>
<h2 id="promises"><a class="header" href="#promises">Promises</a></h2>
<p><code>Promise.all()</code> returns a promise that waits for all of the promises in
the array to resolve and then resolves to an array of the values that these
promises produced (in the same order as the original array).
If any promise is rejected, the result of Promise.all is itself rejected.</p>
<p><code>Promise.allSettled()</code> is same as above, but does not reject if any
promises do.</p>
<p><code>Promise.race()</code> returns the first promise that settles (fulfilled or rejected).</p>
<p><code>Promise.any()</code> returns the first promise that settles (only fulfilled).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="angular"><a class="header" href="#angular">Angular</a></h1>
<p>Single Page Application (SPA).</p>
<h2 id="component"><a class="header" href="#component">Component</a></h2>
<p><code>@Component(...)</code></p>
<ul>
<li>Define Views.</li>
</ul>
<p>Inject the store in order to be able to gain access to the global state.</p>
<h3 id="interaction"><a class="header" href="#interaction">Interaction</a></h3>
<ul>
<li><code>@Input()</code></li>
<li><code>@Output()</code></li>
<li><code>ngOnChanges()</code></li>
</ul>
<h4 id="input"><a class="header" href="#input"><code>@Input()</code></a></h4>
<p>Either a variable</p>
<pre><code class="language-js">@Input() aVariable: string;
...
[aVariable]="value"
</code></pre>
<p>or a setter function</p>
<pre><code class="language-js">aVariable: string;
@Input()
set aVariable(inputVar: string) {...}
...
[aVariable]="value"
</code></pre>
<h4 id="output"><a class="header" href="#output"><code>@Output()</code></a></h4>
<p>Emit event.</p>
<h4 id="ngonchanges"><a class="header" href="#ngonchanges"><code>ngOnChanges()</code></a></h4>
<p>By changing the <code>changeDetection</code> property, you will change when the component is re-rendered.</p>
<p>ngOnChanges can listen to update handling.</p>
<h3 id="lifecyle-componentdirective-hook-methods"><a class="header" href="#lifecyle-componentdirective-hook-methods">Lifecyle Component/Directive Hook Methods</a></h3>
<ul>
<li><code>ngOnChanges()</code></li>
<li><code>ngOnInit()</code> once</li>
<li><code>ngDoCheck()</code></li>
<li><code>ngAfterContentInit()</code> once</li>
<li><code>ngAfterContentChecked()</code></li>
<li><code>ngAfterViewInit()</code> once</li>
<li><code>ngAfterViewChecked()</code></li>
<li><code>ngOnDestroy()</code> once</li>
</ul>
<p>Angular only calls a directive/component hook method if it is defined.</p>
<h2 id="service"><a class="header" href="#service">Service</a></h2>
<p><code>@Injectible(...)</code></p>
<ul>
<li>use <code>providedIn</code> to declare module <code>name-provider.ts</code> that provides it</li>
</ul>
<h2 id="template"><a class="header" href="#template">Template</a></h2>
<ul>
<li>
<p>directive</p>
</li>
<li>
<p>binding markup</p>
<ul>
<li>event</li>
<li>property</li>
</ul>
</li>
<li>
<p>pipes</p>
</li>
<li>
<p><code>&lt;ng-template&gt;</code></p>
</li>
<li>
<p><code>&lt;ng-container&gt;</code> is not rendered</p>
</li>
<li>
<p><code>&lt;ng-content&gt;</code> input HTML rendered here</p>
</li>
</ul>
<h2 id="module"><a class="header" href="#module">Module</a></h2>
<p><code>@NgModule(...)</code></p>
<p>3 files</p>
<ul>
<li><code>name.module.ts</code>
<ul>
<li><code>imports</code>: things the module uses</li>
<li><code>declarations</code>: everything in the module</li>
<li><code>exports</code>: exported components</li>
</ul>
</li>
<li><code>name-provider.ts</code>, class services should assign to</li>
<li><code>name-routing.ts</code>, declares paths</li>
</ul>
<p>Declares compilation contex for a set of modules.</p>
<h2 id="resolver"><a class="header" href="#resolver">Resolver</a></h2>
<p>Implements <code>Resolve</code> interface from <code>@angular/router</code> module.</p>
<pre><code>interface Resolve&lt;T&gt; {
  resolve(route: ActivatedRouteSnapshot, state: RouterStateSnapshot)
  : Observable&lt;T&gt; | Promise&lt;T&gt; | T
}
</code></pre>
<ul>
<li>Connected to a path</li>
<li>Run before anything is showed and gives ready data to the component on the
path. This means observables will be resolved properly.</li>
</ul>
<h2 id="guard"><a class="header" href="#guard">Guard</a></h2>
<ul>
<li>Run before resolvers</li>
<li>Used for access verification</li>
</ul>
<h2 id="rxjs"><a class="header" href="#rxjs">RxJS</a></h2>
<p><code>async</code></p>
<h3 id="operators-1"><a class="header" href="#operators-1">Operators</a></h3>
<p>Operators can be used in <code>.pipe(...)</code>.</p>
<ul>
<li><code>.map</code></li>
<li><code>.switchMap</code></li>
<li><code>.switchMapTo</code></li>
<li><code>.combineLatest</code></li>
<li>...</li>
</ul>
<h3 id="observable"><a class="header" href="#observable">Observable</a></h3>
<p>Naming convention <code>varName$</code>.</p>
<p>Is like a Promise.</p>
<ul>
<li><code>.pipe(...)</code></li>
<li><code>.subscribe(...)</code></li>
</ul>
<p><strong>Note</strong>: subscribing via an <code>async</code> pipe will automatically unsubscribe. When manually subscribing,
unsubscribe has to be called to prevent memory leaks (e.g. in <code>ngOnDestroy()</code>).</p>
<h3 id="subjects"><a class="header" href="#subjects">Subjects</a></h3>
<h2 id="ngrx-store"><a class="header" href="#ngrx-store">NgRx store</a></h2>
<p>Global state.</p>
<p><code>store.dispatch(Action)</code> to update state.</p>
<h3 id="reducer"><a class="header" href="#reducer">Reducer</a></h3>
<ul>
<li>Create a new state (cannot change current state object)</li>
<li>Pure functions</li>
<li>no side effects</li>
<li>sync</li>
</ul>
<p>Move as much logic as possible here from component.</p>
<h3 id="selector"><a class="header" href="#selector">Selector</a></h3>
<ul>
<li>filters state</li>
<li>used in <code>.pipe()</code></li>
</ul>
<h3 id="effect"><a class="header" href="#effect">Effect</a></h3>
<ul>
<li>Listen on <code>.ofType(Action)</code> and produces new Action</li>
<li>Must return a new Action</li>
<li>async</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="jest"><a class="header" href="#jest">Jest</a></h1>
<ul>
<li><code>jest.fn()</code> - creates function mock</li>
<li><code>jest.spyOn()</code> - replace existing method of any class or imported module.
<strong>Note</strong>: still calls the original function unless other implementation is provided</li>
<li><code>jest.mock()</code> - overrides whole existing module and provides its replacement</li>
</ul>
<h2 id="jestfn"><a class="header" href="#jestfn"><code>jest.fn()</code></a></h2>
<p>A function that records calls in the <code>.mock</code> property.</p>
<ul>
<li>Can return values with <code>.mockReturnValue</code> or <code>.mockResolvedValue</code></li>
</ul>
<h2 id="jestspyone"><a class="header" href="#jestspyone"><code>jest.spyOne()</code></a></h2>
<p><strong>Note</strong>: <code>.mockReturnValue()</code> etc are shorthand notation for
<code>.mockImplementation(...)</code>, so they also replace the implementation.</p>
<h2 id="jestmock-and-jestdomock"><a class="header" href="#jestmock-and-jestdomock"><code>jest.mock()</code> and <code>jest.doMock()</code></a></h2>
<pre><code>import { A } from 'B';
jest.mock('B'); // hoisted
const mockA = A as jest.MockedFunction&lt;typeof A&gt;;
</code></pre>
<p><strong>Note</strong>: <code>jest.mock()</code> is hoisted because module needs to be mocked <em>before</em> it is imported.
This means that it is <strong>not</strong> possible to use any variables in the mock.</p>
<p>For this reason there is <code>jest.doMock()</code> which is executed at place. But import statements are
also hoisted which means they need to be changed into a non-hoisted version.</p>
<pre><code class="language-js">import {CONSTANT_VALUE} from './constants';
jest.doMock('./myModuke', 8) =&gt; ({
        doSomething: jest.fn(() =&gt; CONSTANT_VALUE),
    })
);
// Class containing doSomething function
const {Class} = require('./Class');
)
</code></pre>
<h2 id="clear"><a class="header" href="#clear">Clear</a></h2>
<ul>
<li><code>jest.clearAllMocks()</code> - clear all mock usage data</li>
<li><code>jest.resetAllMocks()</code> - clear all mock usage data and also resets implementation with new <code>jest.fn()</code></li>
<li><code>jest.restoreAllMocks()</code> - restore mocks back to original implementation (<strong>Note</strong>: only applies for <code>jest.spyOn</code>!)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="javascript-1"><a class="header" href="#javascript-1">Javascript</a></h1>
<h2 id="operators-2"><a class="header" href="#operators-2">Operators</a></h2>
<ul>
<li><code>&amp;&amp;</code> <strong>Logical AND</strong>. returns the value of the <em>first falsey operand</em> or the value of the last operand (if all are truthy).
<ul>
<li><code>true &amp;&amp; "hello"</code> returns <code>hello</code></li>
<li><code>0 &amp;&amp; "hello"</code> returns <code>0</code></li>
</ul>
</li>
<li><code>||</code> <strong>Logical OR</strong>. returns the value of the <em>first truthy operand</em> or the value of the last operand (if all are falsey).
<ul>
<li><code>42 || "hello"</code> returns <code>42</code></li>
<li><code>0 || "hello"</code> returns <code>hello</code></li>
<li><code>0 || false || "" </code> returns <code>""</code></li>
</ul>
</li>
</ul>
<h2 id="static-import-declaration-1"><a class="header" href="#static-import-declaration-1">Static <code>import</code> declaration</a></h2>
<p>Used to import read-only <em>live bindings</em> from another module. The imported
module will be evaluated at load time.</p>
<p>In order to use the <code>import</code> declaration in a source file, the file must be
interpreted by the runtime as a module.</p>
<p>If the same module is imported into multiple other modules, its code is executed
only once, upon the first import. Then its exports are given to all further
importers.</p>
<p><code>import</code> declarations can only be present in modules, and only at the top-level.</p>
<p>There are 4 form of <code>import</code> decalarations</p>
<ul>
<li>Named import <code>import { export1, export2 } from "module-name";</code></li>
<li>Default import <code>import defaultImport from "module-name";</code></li>
<li>Namespace import <code>import * as name from "module-name";</code></li>
<li>Side effect import <code>import "module-name";</code></li>
</ul>
<h2 id="promises-1"><a class="header" href="#promises-1">Promises</a></h2>
<p><code>Promise.all()</code> returns a promise that waits for all of the promises in
the array to resolve and then resolves to an array of the values that these
promises produced (in the same order as the original array).
If any promise is rejected, the result of Promise.all is itself rejected.</p>
<p><code>Promise.allSettled()</code> is same as above, but does not reject if any
promises do.</p>
<p><code>Promise.race()</code> returns the first promise that settles (fulfilled or rejected).</p>
<p><code>Promise.any()</code> returns the first promise that settles (only fulfilled).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="react"><a class="header" href="#react">React</a></h1>
<h2 id="component-lifecycle"><a class="header" href="#component-lifecycle">Component Lifecycle</a></h2>
<ol>
<li><strong>Triggering</strong>: Happens because of
<ul>
<li>it is the initial render, or</li>
<li>the component’s (or one of its ancestors’) state has been updated. Ie, <code>set</code> function has been called.</li>
</ul>
</li>
<li><strong>Rendering</strong>: React calls the component function. It's a recursive process in the sense that it also calls child components.
<ul>
<li>initial: React will call the root component.</li>
<li>re-render: React calls the function component whose state update triggered the render, and calculates the difference since previous render.</li>
</ul>
</li>
<li><strong>Committing</strong>: React commit changes to the DOM.
<ul>
<li>initial: React uses <code>appendChild()</code></li>
<li>re-render: React applies minimal nevessary operation calculated from <em>Rendering</em> phase.</li>
</ul>
</li>
</ol>
<p><strong>Note</strong>: React only changes the DOM nodes if there is a difference between renders.</p>
<p>After these steps, the browser will repaint the screen.</p>
<h2 id="useeffect-hook"><a class="header" href="#useeffect-hook">useEffect hook</a></h2>
<pre><code class="language-js">useEffect(() =&gt; {
    &lt;LOGIC&gt;
    return &lt;CLEANUP FUNCTION&gt;
}, [&lt;DEPENDENCIES&gt;])
</code></pre>
<ul>
<li><code>useEffect(() =&gt; {...})</code> runs on every render</li>
<li><code>useEffect(() =&gt; {...}, [])</code> runs on first render</li>
<li><code>useEffect(() =&gt; {...}, [x, y])</code> runs when <code>x</code> or <code>y</code> renders with a new value</li>
</ul>
<h2 id="usestate-hook"><a class="header" href="#usestate-hook">useState hook</a></h2>
<pre><code class="language-js">const [something, setSomething] = useState(&lt;INITIAL STATE&gt;)
</code></pre>
<p><strong>Note</strong>: State variable <code>something</code> is not updated until next render. Ie, the new value is not directly present in the current snapshot of the component after <code>setSomething()</code>.</p>
<h2 id="eslint-and-prettier"><a class="header" href="#eslint-and-prettier">ESLint and Prettier</a></h2>
<p>Prettier is for formatting rules. ESLint is for code quality rules.</p>
<ul>
<li><a href="https://github.com/airbnb/javascript/tree/master/packages/eslint-config-airbnb">eslint-config-airbnb</a> is a base config for react. <code>npx install-peerdeps --dev eslint-config-airbnb</code></li>
<li><a href="https://github.com/prettier/eslint-config-prettier">eslint-config-prettier</a> turns off rules that conflict with prettier, needs to be last in extends</li>
<li><a href="https://github.com/prettier/eslint-plugin-prettier">eslint-plugin-prettier</a> turns prettier changes inte ESLint rules (not neccessary)</li>
</ul>
<pre><code class="language-sh">npx install-peerdeps --dev eslint-config-airbnb
npm install --save-dev --save-exact prettier
</code></pre>
<p><em>.eslinttrc.json</em></p>
<pre><code class="language-json">{
  "extends": [
    "airbnb",
    "prettier" // eslint-config-prettier
  ]
}
</code></pre>
<p><strong>Note:</strong> <em>eslint.config.js</em> is used for eslint &gt;= v8</p>
<p>formatting</p>
<pre><code>npx prettier . --write
npx eslint . --fix
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="python"><a class="header" href="#python">Python</a></h1>
<h2 id="python--m-module_name"><a class="header" href="#python--m-module_name"><code>python -m module_name</code></a></h2>
<p>Does 2 things:</p>
<ol>
<li></li>
</ol>
<p>It sets the name of <code>module_name</code> will be main, ie <code>__name__</code> will be <code>__main__</code>.</p>
<ol start="2">
<li></li>
</ol>
<p>Prevents <code>path/to</code> in <code>module_name</code> to be added to <code>PYTHONPATH</code>.
The difference between <code>python -m path.to.module_name</code> and <code>python path/to/module_name.py</code> is that the latter will
add <code>path/to</code> to the front of <code>PYTHONPATH</code>, potentially creating conflicting import names (where the local will be chosen).</p>
<h2 id="structure-src-layout"><a class="header" href="#structure-src-layout">Structure, src-layout</a></h2>
<pre><code>├─ src
│  └─ packagename
│     ├─ __init__.py
│     └─ ...
├─ tests
│  └─ ...
├─ requirements.txt
└─ setup.py
</code></pre>
<p><a href="https://blog.ionelmc.ro/2014/05/25/python-packaging/#the-structure%3E">blog</a>
<a href="https://setuptools.pypa.io/en/latest/userguide/package_discovery.html#src-layout">setuptools src-layout</a></p>
<p>Use <code>pip</code> and <code>venv</code>.</p>
<p>cf. flat-layout</p>
<h2 id="virtual-environment"><a class="header" href="#virtual-environment">Virtual Environment</a></h2>
<pre><code>python -m venv .venv
source .venv/bin/activate
...
deactivate
</code></pre>
<p><code>activate</code> sets pip's path to the dir selected, this can be shown with <code>pip -V</code>.</p>
<p>Virtual environments does not litter the global pip installs.</p>
<p><strong>NOTE</strong>: always use <code>python -m pip ...</code> for <code>pip</code> operations in a venv.</p>
<h2 id="development-mode-aka-editable-installs"><a class="header" href="#development-mode-aka-editable-installs">Development Mode (a.k.a. “Editable Installs”)</a></h2>
<p>Setuptools instruct the Python interpreter and its import machinery to load the code under development
directly from the project folder without having to copy the files to a different location on disk.
Making changes to the source code take place in immediately, without requiring a new installation.</p>
<pre><code>python -m venv .venv
source .venv/bin/activate
pip install --editable .
</code></pre>
<p><a href="https://setuptools.pypa.io/en/latest/userguide/development_mode.html">setuptools site</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="distribution-package"><a class="header" href="#distribution-package">Distribution Package</a></h1>
<h2 id="requirements"><a class="header" href="#requirements">Requirements</a></h2>
<ul>
<li><code>build</code></li>
<li><code>setuptools</code> build backend</li>
<li><em>pyproject.toml</em> with <code>build-backend</code> specified</li>
</ul>
<hr />
<h2 id="build"><a class="header" href="#build"><code>build</code></a></h2>
<ul>
<li>sdist: unbuilt</li>
<li>wheel: build</li>
</ul>
<p>Install <code>build</code></p>
<pre><code>pip install --upgrade build
</code></pre>
<p>which also install <code>setuptools</code> (build backend).</p>
<pre><code>python -m build
</code></pre>
<h2 id="pyprojecttoml"><a class="header" href="#pyprojecttoml"><em>pyproject.toml</em></a></h2>
<p><em>pyproject.toml</em> tells the build frontend which build backend to use.</p>
<p>Three possible tables:</p>
<ul>
<li><code>[build-system]</code></li>
<li><code>[project]</code></li>
<li><code>[tool]</code></li>
</ul>
<p>Fields can be static or dynamic. When a field is dynamic, it is the build backend’s responsibility to fill it. Consult your build backend’s documentation to learn how it does it.</p>
<h3 id="build-system"><a class="header" href="#build-system"><code>[build-system]</code></a></h3>
<ul>
<li><code>build-backend</code>: specifies which build backend to use.</li>
<li><code>requires</code>: list of dependencies needed to build the project – typically just build backend package.</li>
</ul>
<h3 id="project"><a class="header" href="#project"><code>[project]</code></a></h3>
<p>example:</p>
<pre><code>[build-system]
requires = ["setuptools &gt;= 61.0"]
build-backend = "setuptools.build_meta"
</code></pre>
<h2 id="source"><a class="header" href="#source">Source</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="aws"><a class="header" href="#aws">AWS</a></h1>
<h2 id="compute"><a class="header" href="#compute">Compute</a></h2>
<h3 id="ecs"><a class="header" href="#ecs">ECS</a></h3>
<p>Instance families:</p>
<ul>
<li>general purpose</li>
<li>compute optimized</li>
<li>memory optimized</li>
<li>accelerated computing</li>
<li>storage optimized</li>
</ul>
<h4 id="scaling"><a class="header" href="#scaling">Scaling</a></h4>
<p>Autoscaling additional instances.</p>
<p>Elastic Load Balancing (ELB) routes traffic.</p>
<h3 id="lambda"><a class="header" href="#lambda">Lambda</a></h3>
<p>For less than 15 minutes.</p>
<h4 id="deployment"><a class="header" href="#deployment">Deployment</a></h4>
<p><em>Deployment packages</em> are used to deploy a lambda.</p>
<p>2 types of deployment packages are supported:</p>
<ul>
<li>.zip archive (uploaded to S3 or local machine)</li>
<li>container image (uploaded to Amazon ECR)</li>
</ul>
<h2 id="network--security"><a class="header" href="#network--security">Network &amp; Security</a></h2>
<ul>
<li>Route 53 - DNS</li>
<li>CloudFront - CDN</li>
<li>Virtual Private Cloud (VPC)</li>
<li>Security Groups</li>
<li>Internet Gateway (IGW)</li>
<li>Public/private subnets</li>
<li>Elastic Load Balancer (ELB)</li>
</ul>
<h3 id="vpc"><a class="header" href="#vpc">VPC</a></h3>
<ul>
<li>Comes with a default customizable network access control list (ACL)</li>
<li>Can have private and public subnets</li>
</ul>
<h3 id="igw"><a class="header" href="#igw">IGW</a></h3>
<p>Connects VPC to internet. Attach to VPC and specify as a target in subnet route
table.</p>
<ul>
<li>Enables internet connection of resource with public IP addresses in subnets
that are public</li>
<li>Routes traffic to subnet according to routing table</li>
</ul>
<h3 id="subnet"><a class="header" href="#subnet">Subnet</a></h3>
<p>Public and private grouping of resources. A range of IP addresses in a VPC.</p>
<p>Subnets must be connected to an ACL, if not it will be associated with the
default ACL of the VPC.</p>
<p>Get resources in subnet</p>
<pre><code>aws ec2 describe-network-interfaces --filters Name=subnet-id,Values=subnet-id-here | grep Description
</code></pre>
<h3 id="elb"><a class="header" href="#elb">ELB</a></h3>
<p>Elastic Load Balancing. To connect with a VPC; specify one or more subnets for
the load balancer nodes.</p>
<p>Register listerners (a process that checks for connection requests) with a
specified target group and conditions. When conditions are met, traffic is
forwarded to the target group.</p>
<ul>
<li>Monitors health of registred targets and only routes to healthy</li>
</ul>
<h3 id="security-group"><a class="header" href="#security-group">Security Group</a></h3>
<p>A Security Group acts as a virtual firewall. <strong>Inbound</strong> and <strong>outbound</strong> rules
specify which access are allowed. Unless specifically allowed, it defauls to
denied.</p>
<ul>
<li>Supports only allow rules, not deny rules</li>
<li>Stateful: always allows response traffic (in both directions)</li>
<li>Operates at instance level (applies to instance only if associated)</li>
<li>When resources are associated with multiple Security Groups, their rules are
aggregated into one set of rules</li>
</ul>
<h3 id="acl"><a class="header" href="#acl">ACL</a></h3>
<ul>
<li>Operates at subnet level (applies to all instances in the subnet)</li>
<li>Supports allow rules and deny rules</li>
<li>Stateless (return traffic must be explicitly allowed by rules)</li>
</ul>
<h2 id="messages"><a class="header" href="#messages">Messages</a></h2>
<h3 id="sqs"><a class="header" href="#sqs">SQS</a></h3>
<p>Simple Queue Service.</p>
<p>Send, store, and receive messages between software components, without losing
messages or requiring other services to be available.</p>
<h3 id="sns"><a class="header" href="#sns">SNS</a></h3>
<p>Simple Notification Service.</p>
<p>Publish/subscribe model. Publish to a topic. Subscribe to topics.</p>
<h2 id="container-orchestration-tools"><a class="header" href="#container-orchestration-tools">Container Orchestration Tools</a></h2>
<p>Docker containers.</p>
<h3 id="ecs-1"><a class="header" href="#ecs-1">ECS</a></h3>
<p>Elastic Container Service.</p>
<h3 id="eks"><a class="header" href="#eks">EKS</a></h3>
<p>Elastic Kubernetes Service.</p>
<h3 id="fargate"><a class="header" href="#fargate">Fargate</a></h3>
<p>Run containers on top of serverless compute platform for ECS or EKS.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-gateway"><a class="header" href="#api-gateway">API Gateway</a></h1>
<ul>
<li>Websocket (Stateful)</li>
<li>HTTP</li>
<li>public REST API</li>
<li>private REST API</li>
</ul>
<h2 id="authentification-and-authorization"><a class="header" href="#authentification-and-authorization">Authentification and Authorization</a></h2>
<p>3 options for Authentification:</p>
<ul>
<li>IAM</li>
<li>Custom Lambda</li>
<li>Cognito</li>
</ul>
<h2 id="proxy-vs-integration"><a class="header" href="#proxy-vs-integration">Proxy vs Integration</a></h2>
<p>Lambda-proxy sends request from API Gateway directly to lambda without
modifications.</p>
<p>In a Lambda integration the request and response can be modified in the API
Gateway using Velocity Template Language (VTL).</p>
<p><strong>Method Request</strong>: request originated from the client.</p>
<p><strong>Integration Request</strong> the transformation that you can do with API Gateway.
The request body can be transformed as per your body mapping template.</p>
<p><strong>Integration Response</strong>: This is where you can assign appropriate status code
and do response transformation, if present. After transformation, the response
is sent to client.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="aws-certified-cloud-practitioner-foundational-clf-c01"><a class="header" href="#aws-certified-cloud-practitioner-foundational-clf-c01">AWS Certified Cloud Practitioner Foundational (CLF-C01)</a></h1>
<h2 id="order-of-certificates"><a class="header" href="#order-of-certificates">Order of Certificates</a></h2>
<ol>
<li>AWS Certified Cloud Practitioner Foundational (CCP)</li>
<li>AWS Certified Solutions Architect Associate (CSAA)
<strong>most in demand</strong></li>
<li>AWS Certified Developer Associate
<strong>overlaps CSAA</strong></li>
<li>AWS Sysops Administrator Associate</li>
</ol>
<hr />
<h2 id="module-1-intro"><a class="header" href="#module-1-intro">Module 1: Intro</a></h2>
<p>Bird's eye view of AWS.</p>
<p>4 domains:</p>
<ul>
<li>26% Domain 1: Cloud Concepts</li>
<li>25% Domain 2: Security and Compliance</li>
<li>33% Domain 3: Technology</li>
<li>15% Domain 4: Billing and Pricing</li>
</ul>
<p>Exam:</p>
<ul>
<li>Passing ~700/1000</li>
<li>65 questions (50 scored, 15 unscored)</li>
<li>1.5 hours</li>
<li>Valid for 36 months</li>
</ul>
<p><strong>Client Server Model</strong>: a client makes a request to a server.</p>
<h3 id="cloud-computing"><a class="header" href="#cloud-computing">Cloud Computing</a></h3>
<p><strong>Cloud Computing</strong>: The on-demand delivery of IT resources over the internet
with pay-as-you-go pricing.</p>
<ul>
<li>Trade upfront expenses for variable expenses</li>
<li>Don't pay for data center maintenance</li>
<li>Don't need to guess capacity</li>
<li>Benefit from economies of scale</li>
<li>Flexibility increases speed and agility</li>
<li>Easy to go global</li>
</ul>
<hr />
<h2 id="module-2-compute-in-the-cloud"><a class="header" href="#module-2-compute-in-the-cloud">Module 2: Compute in the Cloud</a></h2>
<h3 id="ec2"><a class="header" href="#ec2">EC2</a></h3>
<p>Multitenancy - Hypervisor - VMs.</p>
<p>Supports vertical scaling.</p>
<p>Instance family types to optimize either memory, cpu, storage or networking
capacity.</p>
<ul>
<li><em>General purpose</em>, <code>M</code> and <code>T</code></li>
<li><em>Compute optimized</em> (eg batch processing), <code>C</code></li>
<li><em>Memory optimized</em>, <code>R</code> and <code>X</code></li>
<li><em>Accelerated computing</em> (utilize hardware accelerators; coprocessors), <code>P</code> and <code>G</code></li>
<li><em>Storage optimized</em> (&gt; 10k IOPS), <code>I</code> and <code>D</code></li>
<li><em>HPC optimized</em>, <code>Hp</code></li>
</ul>
<h4 id="pricing"><a class="header" href="#pricing">Pricing</a></h4>
<ul>
<li><em>On-demand</em> (per hour or per second)</li>
<li><em>Savings plan</em> (usage above committed usage is charged on-demand prices. 1 or 3 year term)</li>
<li><em>Reserved instances</em> (1 or 3 year term, for steady state workload)</li>
<li><em>Spot instances</em> (can be reclaimed with 2 min warning, should be able to handle interruptions)</li>
<li><em>Dedicated host</em> (no shared tenancy)</li>
</ul>
<h3 id="scalability-and-elasticity"><a class="header" href="#scalability-and-elasticity">Scalability and Elasticity</a></h3>
<p><strong>Scaling</strong></p>
<p>Vertical scaling: <em>scale up</em> / <em>scale down</em></p>
<p>Horizontal scaling: <em>scale in</em> / <em>scale out</em>.</p>
<p><em>Amazon EC2 Auto Scaling</em> provides automatic horizontal scaling.</p>
<ul>
<li><em>Dynamic scaling</em> responds to changing demand</li>
<li><em>Predictive scaling</em> schedule</li>
</ul>
<p><strong>Load Balancing</strong></p>
<p><em>Elastic Load Balancing, (ELB)</em></p>
<ul>
<li>Regional construct (highly available)</li>
<li>Distributes traffic across multiple resources</li>
<li>Scales automatically</li>
</ul>
<h3 id="messaging-and-queueing"><a class="header" href="#messaging-and-queueing">Messaging and Queueing</a></h3>
<p>If services communicate directly, that is a <em>Tightly Coupled Architecture</em>; errors
in application B will propagate to application A. <em>Loosely Coupled Architecture</em>
means that single failures does not cause cascading failures. Queues and buffers
solve this.</p>
<p><em>Simple Queue Service (SQS)</em></p>
<ul>
<li>Send/Recieve</li>
<li>Store</li>
<li>Supports any volume</li>
<li>Scale automatically</li>
</ul>
<p><em>Simple Notification Service (SNS)</em></p>
<ul>
<li>Publish/Subscibe model (SNS Topic)</li>
</ul>
<h4 id="monoliths-and-microservices"><a class="header" href="#monoliths-and-microservices">Monoliths and Microservices</a></h4>
<ul>
<li>Applications consists of Components</li>
<li>Components need to communicate</li>
<li>Monoliths promote tight coupling</li>
<li>Microservices are loosely coupled by design</li>
</ul>
<h3 id="additional-compute-services"><a class="header" href="#additional-compute-services">Additional Compute Services</a></h3>
<p><em>Serverless</em>: You cannot see or access the underlying infrastructure.</p>
<p><strong>Lambda</strong></p>
<ul>
<li>Scale automatically</li>
<li>&lt;15 min</li>
<li>zip or Docker container</li>
</ul>
<p><strong>Container Orchestration Tools</strong></p>
<p>Container (Docker) Services.</p>
<ul>
<li>Elastic Container Service (ECS)</li>
<li>Elastic Kubernetes Service (EKS)</li>
</ul>
<p>The host is an EC2 instance.</p>
<p><em>Fargate</em>: Serverless compute platform for ECS or EKS, allows to run containers
on top of a Serverless compute platform. An alternative to running containers
directly in an EC2 machine.</p>
<hr />
<h2 id="module-3-global-infrastructure-and-reliability"><a class="header" href="#module-3-global-infrastructure-and-reliability">Module 3: Global Infrastructure and Reliability</a></h2>
<p>Edge Locations are not the same as Regions. Regions can push their content to
several edge locations.</p>
<p><strong>AWS Local Zones</strong>: for even more low-latency requirements.</p>
<h3 id="regions-and-availability-zones"><a class="header" href="#regions-and-availability-zones">Regions and Availability Zones</a></h3>
<p>Regions are geographically isolated from one another without an explicit approve.</p>
<p>Regions can be connected with high speed fiber network.</p>
<p><em>Availability Zone (AZ)</em>: One data center inside a region.</p>
<p><strong>Best Practice</strong>: Run across at least 2 AZs for mitigating effect of downtime.
Any service marked with <em>Regionally scoped service</em> are already doing this by
default (eg ELB, SNS, SQS).</p>
<p>Factors when deciding a region:</p>
<ul>
<li>Compliance with data governance and legal requirements</li>
<li>Proximity</li>
<li>Feature availability</li>
<li>Pricing</li>
</ul>
<p><strong>AWS Outposts</strong>: Run AWS services locally.</p>
<h3 id="edge-locations"><a class="header" href="#edge-locations">Edge Locations</a></h3>
<p><em>Content Delivery Network (CDN)</em>: Cache data close to client.</p>
<p><em>Amazon CloudFront</em> is the CDN in AWS.</p>
<p><em>Route 53</em>: DNS server.</p>
<h3 id="provisioning"><a class="header" href="#provisioning">Provisioning</a></h3>
<p>When interacting with AWS services, everything is an API call.</p>
<ul>
<li>AWS Management Console (Browser)</li>
<li>AWS Command Line Interface (CLI)</li>
<li>AWS Software Development Kits (SDK)</li>
<li>Other tools (eg CloudFormation, Elastic Beanstalk)</li>
</ul>
<p><strong>AWS Elastic Beanstalk</strong>: Helps provision EC2 based environments.</p>
<p><strong>AWS CloudFormation</strong>: IaC tool.</p>
<hr />
<h2 id="module-4-networking"><a class="header" href="#module-4-networking">Module 4: Networking</a></h2>
<h3 id="vpc-1"><a class="header" href="#vpc-1">VPC</a></h3>
<p><img src="aws/img/igw_sg.png" alt="overview" /></p>
<p><strong>Virtual Private Cloud (VPC)</strong>: Provision logically isolated section.
Resources in VPC can be public facing or private.</p>
<p><strong>Subnets</strong>: Chunks of IP adresses in the VPC that allows to group resources
together. They can be <strong>public</strong> or <strong>private</strong>.</p>
<p>Subnets plus networking rules control whether resources are publicly, or
privately available.</p>
<ul>
<li>For public traffic an <strong>Internet Gateway (IGW)</strong> must be attached to allow
traffic in and out of VPC to the public internet.</li>
<li>For private traffic <strong>Virtual Private Gateway</strong> is attached using VPN
(public encrypted traffic to VPC).</li>
<li><strong>AWS Direct Connect</strong> physical private line to VPC.</li>
</ul>
<p><strong>Note:</strong> A VPC can have many different gateways, but connected to different
Subnets.</p>
<p>Packages entering and leaving a VPC gets checked against a <strong>Network access
control list (Network ACL)</strong>. Network ACL only checks if package can cross a
subnet boundary, and not what it can reach inside the subnet.</p>
<p><strong>Security Groups</strong> blocks all incoming traffic to a group of resources (by
default), but allows all outgoing traffic. Security groups are stateful in the
sense that they allow responses regardless of SG rules.</p>
<p><strong>Note:</strong> Security Group is stateful, Network ACL is stateless.</p>
<h3 id="global-networking"><a class="header" href="#global-networking">Global Networking</a></h3>
<p>DNS <strong>Route 53</strong> routing policies:</p>
<ul>
<li>Latency-based routing</li>
<li>Geolocation DNS</li>
<li>Geoproximity routing</li>
<li>Weighted round robin</li>
</ul>
<p>CDN <strong>CloudFront</strong> cache at an edge location.</p>
<hr />
<h2 id="module-5-storage-and-databases"><a class="header" href="#module-5-storage-and-databases">Module 5: Storage and Databases</a></h2>
<h3 id="elastic-block-storage-ebs"><a class="header" href="#elastic-block-storage-ebs">Elastic Block Storage (EBS)</a></h3>
<p>Block level storage.</p>
<p>EC2 machines might have local storage called <em>Instance Store Volumes</em>. When the
image stops, that storage will be deleted (because Instance Store Volumes are
specific to the host machine which might change).</p>
<p><strong>Elastic Block Store (EBS)</strong>. Written data is persisted between starts and
stops of the EC2 instance. Incremental backups are supported (<em>snapshots</em>).</p>
<ul>
<li>Attached to EC2</li>
<li>Scoped to an AZ</li>
</ul>
<h3 id="s3"><a class="header" href="#s3">S3</a></h3>
<p>Object storage.</p>
<ul>
<li>Stores data as objects. Each object consists of data, metadata, and a key.</li>
<li>5 TB object size limit</li>
<li>Support versioning of objects</li>
<li>Support staging data between different tiers</li>
<li>Regionally distributed</li>
</ul>
<p>Types:</p>
<ul>
<li><em>S3 Standard</em> stored in min 3 AZ</li>
<li><em>S3 Standard-Infrequent Access (S3 Standard-IA)</em> stored in min 3 AZ. Less frequent but rapid access. Lower storage price, higher retrieval price.</li>
<li><em>S3 One Zone-Infrequent Access (S3 One Zone-IA)</em> stored in 1 AZ but lower cost, used for reproducable data.</li>
<li><em>S3 Intelligent-Tiering</em> Automatically moves objects between IA and standard tiers.</li>
<li><em>S3 Glacier Flexible Retrieval</em> for less frequent access, slow retrieval.</li>
<li><em>S3 Glacier Instant Retrieval</em> same retrieval as S3 Standard.</li>
<li><em>S3 Glacier Deep Archive</em> lowest-cost storage, data retrieval from 12 to 48 hours. Objects replicated min three geographically dispersed AZs.</li>
<li><em>S3 Outposts</em> storage on-premises AWS Outposts environment</li>
</ul>
<p><em>S3 Lifecycle management</em>: Move data automatically between tiers</p>
<h3 id="ebs-vs-s3"><a class="header" href="#ebs-vs-s3">EBS vs S3</a></h3>
<p>S3 is optimized for write once, ready many. Each object is immutable and
changes needs to upload the whole object again. EBS is not as optimized for
reading, but it supports delta changes to files.</p>
<h3 id="elastic-file-system-efs"><a class="header" href="#elastic-file-system-efs">Elastic File System (EFS)</a></h3>
<p>Managed Linux file system.</p>
<p>Use case a large number of services and resources need to access the same data
at the same time.</p>
<ul>
<li>Multiple instances can access data in EFS at the same time.</li>
<li>Automatic scaling</li>
<li>Regional resource</li>
</ul>
<h3 id="relational-database-service-rds"><a class="header" href="#relational-database-service-rds">Relational Database Service (RDS)</a></h3>
<p>Managed service. Supports</p>
<ul>
<li>Automated patching</li>
<li>Backups</li>
<li>Redundancy</li>
<li>Failover</li>
<li>Disaster recovery</li>
<li>Encryption</li>
</ul>
<p>Six available database engines</p>
<ul>
<li>Aurora</li>
<li>MariaDB</li>
<li>MySQL</li>
<li>PostgreSQL</li>
<li>Oracle Database</li>
<li>Microsoft SQL Server</li>
</ul>
<p>Support <em>Lift and Shift Operation</em> to move on premise DB to the cloud.</p>
<h4 id="aurora"><a class="header" href="#aurora">Aurora</a></h4>
<ul>
<li>
<p>MySQL</p>
</li>
<li>
<p>PostgreSQL</p>
</li>
<li>
<p>Data replication</p>
</li>
<li>
<p>Up to 15 read replicas</p>
</li>
<li>
<p>Continuous backup to S3</p>
</li>
<li>
<p>Point in time recovery</p>
</li>
</ul>
<h3 id="dynamo-db"><a class="header" href="#dynamo-db">Dynamo DB</a></h3>
<p>NoSQL, key-value.</p>
<ul>
<li>Purpose built</li>
<li>Millisecond response time</li>
<li>Highly scalable</li>
<li>Fully managed</li>
</ul>
<h3 id="redshift"><a class="header" href="#redshift">Redshift</a></h3>
<p>Data warehouse as a service.</p>
<p>For historical analytics. Big data, allows to collect data from many sources.</p>
<h3 id="database-migration-service-dms"><a class="header" href="#database-migration-service-dms">Database Migration Service (DMS)</a></h3>
<p>Uses cases:</p>
<ul>
<li>Migrating a database to EC2 or RDS</li>
<li>Database migratiom (Test against production data)</li>
<li>Database consolidation (Combining several DBs into one)</li>
<li>Continuous database replication (Sending ongoing copies of data to other sources)</li>
</ul>
<h4 id="homogenous"><a class="header" href="#homogenous">Homogenous</a></h4>
<p>Source can be:</p>
<ul>
<li>on-premises</li>
<li>EC2</li>
<li>RDS</li>
</ul>
<p>Target can be:</p>
<ul>
<li>EC2</li>
<li>RDS</li>
</ul>
<h4 id="hetrogenous"><a class="header" href="#hetrogenous">Hetrogenous</a></h4>
<p>First use AWS Schema Conversion Tool, then use DMS.</p>
<h3 id="additional-database-services"><a class="header" href="#additional-database-services">Additional Database Services</a></h3>
<ul>
<li>Netptune: Graph database</li>
<li>Quantum Ledger Database (QLDB): complete immutable history</li>
<li>Managed Blockchain: distributed ledger</li>
<li>ElastiCache: caching layer on top of DB. Supports Redis and Memcached</li>
<li>DynamoDB Accelerator (DAX): in-memory cache</li>
</ul>
<hr />
<h2 id="module-6-security"><a class="header" href="#module-6-security">Module 6: Security</a></h2>
<p><strong>AWS Shared Responsibility Model</strong>: Customers are responsible for <em>security
<strong>in</strong> the cloud</em>, AWS is responsible for <em>security <strong>of</strong> the cloud</em>.</p>
<h3 id="identity-and-access-management-iam"><a class="header" href="#identity-and-access-management-iam">Identity and Access Management (IAM)</a></h3>
<p>The user that creates an AWS account becomes the <em>root user</em> and has access to everything.
Should turn on MFA and use IAM Users instead.</p>
<ul>
<li><em>IAM Policy</em>: JSON object that explicitly allows or denies access to resources. EPARC.</li>
<li><em>IAM User</em>: Identity, represents person or application that interacts with AWS
services and resources. Starts with no permissions.</li>
<li><em>IAM Group</em>: Collection of IAM Users.</li>
<li><em>IAM Role</em>: Temporal permissions assumable by a trusted entity.</li>
</ul>
<p>Best practice: Follow principle of least privilege. Use MFA.</p>
<h3 id="aws-organizations"><a class="header" href="#aws-organizations">AWS Organizations</a></h3>
<p>AWS Organizations automatically creates a <strong>root</strong>, which is the parent
container for all the accounts in the organization.</p>
<ul>
<li>Centralized management of accounts.</li>
<li>Consolidated billing</li>
</ul>
<p><strong>Organizational Units (OU)</strong>: Groupings of accounts. Similar to IAM Groups.</p>
<p><strong>Service Control Policies (SCPs)</strong>: Apply permissions to root, member account or an OU.
Allows to place restrictions on services, resource and API actions allowed.</p>
<h3 id="compliance"><a class="header" href="#compliance">Compliance</a></h3>
<ul>
<li><strong>AWS Artifacts</strong> access to AWS security and compliance reports.</li>
<li><strong>AWS Compliance</strong></li>
</ul>
<h3 id="ddos-attacks"><a class="header" href="#ddos-attacks">DDoS attacks</a></h3>
<p>Some types of attacks</p>
<ul>
<li><strong>UDP Flood</strong>
<ul>
<li>Fake return address.</li>
<li><em>Solution</em>: Security Groups</li>
</ul>
</li>
<li><strong>HTTP Level Attack</strong></li>
<li><strong>SlowLoris Attack</strong>
<ul>
<li>Faking a slow connection</li>
<li><em>Solution</em>: Elastic Load Balancer</li>
</ul>
</li>
</ul>
<p><strong>AWS Shield</strong>: Shields against DDoS attacks.</p>
<ul>
<li><em>Standard</em>: no cost, real time analysis of malicious traffic</li>
<li><em>Advanced</em>: paid service, can handle more sophisticated attacks. Integrates with other services.
Integrates with <em>AWS WAF</em>.</li>
</ul>
<p><strong>AWS WAF</strong>: Web Application Firewall. Allows monitoring of network requests. Works together with
CloudFront and ELB. Uses a <em>web access control list (ACL)</em> to block IP addresses.</p>
<h3 id="additional-security"><a class="header" href="#additional-security">Additional Security</a></h3>
<p><strong>AWS Key Management Service (AWS KMS)</strong>: Create, use, and manage cryptographic keys.</p>
<ul>
<li><em>Encryption at rest</em></li>
<li><em>Encryption in transit</em></li>
</ul>
<p><strong>AWS Inspector</strong>: Automated security assessment. Checks applications for security vulnerabilities and deviations from security best practices.</p>
<p><strong>AWS GuardDuty</strong>: Threat detection by monitoring network activity and account behavior.</p>
<hr />
<h2 id="module-7-monitoring-and-analytics"><a class="header" href="#module-7-monitoring-and-analytics">Module 7: Monitoring and Analytics</a></h2>
<p><em>Monitoring</em>: Observing systems, collecting metrics, and then using data to make decisions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="aws-cli"><a class="header" href="#aws-cli">AWS CLI</a></h1>
<p>To setup a default user</p>
<pre><code>aws configure
</code></pre>
<p>To setup a profile</p>
<pre><code>aws configure --profile &lt;profile name&gt;
</code></pre>
<p><em>AWS Access Key ID</em> and <em>AWS Secret Access Key</em> are stored in
<code>~/.aws/credentials</code>. These are associated with an IAM user or role.</p>
<p>All other configuration is stored in <code>~/.aws/config</code>.</p>
<p>Get default user credentials</p>
<pre><code>aws sts get-caller-identity
aws sts get-caller-identity --profile &lt;profile name&gt;
</code></pre>
<p>List profiles</p>
<pre><code>aws configure list-profiles
</code></pre>
<h2 id="files"><a class="header" href="#files">Files</a></h2>
<ul>
<li><em>~/.aws/config</em> non-sensitive information</li>
</ul>
<pre><code>[default]
region = eu-north-1
output = yaml
</code></pre>
<ul>
<li><em>~/.aws/credentials</em> sensitive information</li>
</ul>
<pre><code>[default]
aws_access_key_id = &lt;access key&gt;
aws_secret_access_key = &lt;secret access key&gt;
</code></pre>
<h2 id="profiles"><a class="header" href="#profiles">Profiles</a></h2>
<p>Use</p>
<ul>
<li><code>--profile</code> flag, or</li>
<li><code>AWS_PROFILE</code> environment variable.</li>
</ul>
<p>Eg,</p>
<pre><code>aws s3 ls --profile profile_name
</code></pre>
<p>Add</p>
<pre><code>[profile profile_name]
</code></pre>
<p>to <em>~/.aws/config</em>, and</p>
<pre><code>[profile_name]
</code></pre>
<p>to <em>~/.aws/credentials</em>.</p>
<p><strong>Note</strong>: <code>[profile ...]</code> in <em>~/.aws/credentials</em> file.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cognito"><a class="header" href="#cognito">Cognito</a></h1>
<ul>
<li>User Pools</li>
<li>Identity Pools</li>
</ul>
<p>Access Token is not the same as Identity Token.</p>
<h2 id="user-pool-lambda-triggers"><a class="header" href="#user-pool-lambda-triggers">User Pool Lambda Triggers</a></h2>
<pre><code class="language-yaml">CognitoUserPoolLogicalName:
  Type: 'AWS::Cognito::UserPool'
  Properties:
    ...
    LambdaConfig:
      CreateAuthChallenge: String
      CustomEmailSender: CustomEmailSender
      CustomMessage: String
      CustomSMSSender: CustomSMSSender
      DefineAuthChallenge: String
      KMSKeyID: String
      PostAuthentication: String
      PostConfirmation: String
      PreAuthentication: String
      PreSignUp: String
      PreTokenGeneration: String
      UserMigration: String
      VerifyAuthChallengeResponse: String
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dynamodb"><a class="header" href="#dynamodb">DynamoDB</a></h1>
<ul>
<li>NoSQL</li>
<li>key-value</li>
</ul>
<p>Supports <code>AWS::Backup</code></p>
<h2 id="cap-theorem"><a class="header" href="#cap-theorem">CAP Theorem</a></h2>
<p>CAP</p>
<ul>
<li>Consistency (same across all replication points before returning result)
<ul>
<li>DynomDB supports <em>strongly</em> or <em>eventually</em> consistent reads</li>
</ul>
</li>
<li>Availability</li>
<li>Partition Tolerance</li>
</ul>
<p>Of these 3, we can only have 2 at the same time.</p>
<h2 id="nosql"><a class="header" href="#nosql">NoSQL</a></h2>
<p>No cross table relationships</p>
<p>3 main types:</p>
<ul>
<li>Key-value (DynamoDB)</li>
<li>Column-based (eg Cassandra)</li>
<li>Document-based (eg MongoDB)</li>
</ul>
<h2 id="design"><a class="header" href="#design">Design</a></h2>
<h3 id="queries-first"><a class="header" href="#queries-first">Queries first</a></h3>
<p>Design of DynamoDB tables requires query patterns to be evaluated <em>first</em>.</p>
<p><strong>Note</strong>: DynamoDB does not support joins.</p>
<p>In order to limit the number of round trips, the data must be ordered in a way
to minimize the number of calls to the database.</p>
<h3 id="partitioning"><a class="header" href="#partitioning">Partitioning</a></h3>
<p>DynamoDB is designed to partition the underlying data into different storages.</p>
<p>The partitioning is guided by the partition key, therefore it is very important
to design the partition key so that the data is distributed equally. Otherwise
you can get hot partitions that impede the performance.</p>
<hr />
<h2 id="table"><a class="header" href="#table">Table</a></h2>
<p>A collection of 0 or more items.
Items can be queried through their keys.
Items are made up of their attributes</p>
<p><code>primary key</code> (or <code>partition key</code>) is mandatory.
<code>sort key</code> is optional.</p>
<p><strong>Note</strong>: Primary key or sort key <strong>can</strong> be duplicated, but <strong>not both</strong> at the same time.</p>
<p>Extra keys are attributes.</p>
<p>By default queries are only supported on partition and sort key. To support
queries on other keys, secondary indexes are needed.</p>
<h3 id="item-types"><a class="header" href="#item-types">Item types</a></h3>
<ul>
<li><code>S</code> – String</li>
<li><code>N</code> – Number</li>
<li><code>B</code> – Binary</li>
<li><code>BOOL</code> – Boolean</li>
<li><code>NULL</code> – Null</li>
<li><code>M</code> – Map</li>
<li><code>L</code> – List</li>
<li><code>SS</code> – String Set</li>
<li><code>NS</code> – Number Set</li>
<li><code>BS</code> – Binary Set</li>
</ul>
<h2 id="item"><a class="header" href="#item">Item</a></h2>
<ul>
<li>Max size is 400 kB</li>
<li><code>partition key</code> min length is 1 byte, max length 2048 bytes</li>
<li><code>sort key</code> min length is 1 byte, max length 1024 bytes</li>
</ul>
<p>Items need not have the same number of attributes.</p>
<h2 id="query"><a class="header" href="#query">Query</a></h2>
<p>Find items based on</p>
<ul>
<li><code>partition key</code> value alone, or</li>
<li><code>partition key</code> value and <code>sort key</code> value in cases where sort key is defined</li>
</ul>
<h2 id="scan"><a class="header" href="#scan">Scan</a></h2>
<pre><code>aws dynamodb scan --table-name &lt;TABLE&gt;
</code></pre>
<p>Retrieves all items in a table. More costly than a query.</p>
<p>Scans can be supplied with the <code>--max-items &lt;NUMBER&gt;</code> flag.</p>
<p><strong>Note</strong>: filters will happen <em>after</em> a scan is complete, so it will <strong>not</strong>
make the scan more efficient.</p>
<p><strong>Note</strong>: Scans only returns data up to a limit (by default 1MB).</p>
<p><strong>Note</strong>: Scans are by default paginated.</p>
<h2 id="secondary-index"><a class="header" href="#secondary-index">Secondary Index</a></h2>
<p>Basically creates a copy of the table with an alternate key schema.</p>
<ul>
<li><em>Local secondary index</em>, allows to create an alternate sort key</li>
<li><em>Global secondary index</em>, allows to create an alternate partition and sort key</li>
</ul>
<h2 id="batchgetitem--batchwriteitem"><a class="header" href="#batchgetitem--batchwriteitem"><code>BatchGetItem</code> &amp; <code>BatchWriteItem</code></a></h2>
<p>Each write in <code>BatchWriteItem</code> is atomic, but the command as whole is <strong>not</strong>.</p>
<p><code>BatchGetItem</code> is <em>eventually consistent</em> by default.</p>
<p><strong>Note</strong>: You will be provided with a list of unprocessed items.</p>
<h2 id="aws-cli-1"><a class="header" href="#aws-cli-1">AWS CLI</a></h2>
<pre><code>aws dynamodb list-tables
aws dynamodb put-item --table-name &lt;TABLE&gt; --item file://&lt;JSON FILE&gt;
aws dynamodb delete-item --table-name &lt;TABLE&gt; --key file://&lt;JSON FILE&gt;
aws dynamodb query --table-name &lt;TABLE&gt; --key-condition-expression ... --expression-attribute-values file://&lt;JSON FILE&gt;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="static-website"><a class="header" href="#static-website">Static Website</a></h1>
<p><img src="aws/img/static_website_overview.png" alt="overview" /></p>
<h2 id="public---private-key-pair"><a class="header" href="#public---private-key-pair">Public - Private key pair</a></h2>
<p>Generate by</p>
<pre><code class="language-sh">openssl genrsa -out private_key.pem 2048
openssl rsa -pubout -in private_key.pem -out public_key.pem
</code></pre>
<ul>
<li><strong>private key</strong> goes into SSM for use by Lambda to sign the cookie</li>
<li><strong>public key</strong> goes to CloudFront (<code>AWS::CloudFront::PublicKey</code> and <code>AWS::CloudFront::KeyGroup</code>)</li>
</ul>
<h2 id="cloudfront-distribution"><a class="header" href="#cloudfront-distribution">CloudFront Distribution</a></h2>
<ul>
<li><code>Origins</code>: Locations where content is stored, and from which CloudFront gets content to serve to viewers.</li>
<li><code>CacheBehaviors</code>: Each cache behavior specifies the one origin from which you want CloudFront to get objects.</li>
</ul>
<h2 id="cookie-lambdaedge"><a class="header" href="#cookie-lambdaedge">Cookie Lambda@Edge</a></h2>
<h3 id="limitations"><a class="header" href="#limitations">Limitations</a></h3>
<p>Lambda@Edge</p>
<ul>
<li>does not support environment variables.</li>
<li>must be in us-east-1</li>
<li>cannot be in VPC</li>
<li>cannot be referenced with <code>$LATEST$</code>; must use a version number</li>
</ul>
<hr />
<p><code>LambdaFunctionAssociations: 'viewer-request'</code></p>
<p>Needs to return <code>Set-Cookie</code> header with values</p>
<ul>
<li><code>CloudFront-Policy</code></li>
<li><code>CloudFront-Signature</code></li>
<li><code>CloudFront-Key-Pair-Id</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="iam---identity-and-access-management"><a class="header" href="#iam---identity-and-access-management">IAM - Identity and Access Management</a></h1>
<p>Default access is "Deny".</p>
<h2 id="iam-identities"><a class="header" href="#iam-identities">IAM Identities</a></h2>
<p>There are 3 types of IAM identities:</p>
<ul>
<li>IAM user</li>
<li>IAM user group</li>
<li>IAM role</li>
</ul>
<p><strong>Note</strong>: IAM identities live inside an AWS Account, which is a boundary - by
default, no access is given to identities outside the account (but can be
allowed).</p>
<p><strong>Note</strong>: The <strong>root</strong> user has access to everything and cannot be limited by
IAM policies.</p>
<h3 id="iam-user"><a class="header" href="#iam-user">IAM User</a></h3>
<p>An <strong>IAM user</strong> represents a the person or service that interacts with AWS. IAM
users have long-term credentials.</p>
<h3 id="iam-role"><a class="header" href="#iam-role">IAM Role</a></h3>
<p>An <strong>IAM role</strong> is not associated with an identity, and has no long-term access
keys (as users do). IAM roles are <em>assumed</em> by trusted entities, which gives
that entity the permissions of the role temporarily (assumed role expires).</p>
<p><strong>Note</strong>: Assuming a role gives credentials that last between 15 minutes and 36
hours.</p>
<h3 id="iam-group"><a class="header" href="#iam-group">IAM Group</a></h3>
<p>An <strong>IAM group</strong> is a collection of users.</p>
<hr />
<p><strong>Best practice</strong>: Prefer roles over users when possible.</p>
<p><strong>Best practice</strong>: Prefer attaching a user to a group over giving credentials
directly to the user.</p>
<h2 id="iam-policy-e-parc"><a class="header" href="#iam-policy-e-parc">IAM Policy (E-PARC)</a></h2>
<p>Policies are attached to IAM identities (users, groups and roles).</p>
<p>Required parts are</p>
<ul>
<li><strong>Effect</strong>: statement result; "Allow" or "Deny"</li>
<li><strong>Action</strong>: activity or call the statement covers</li>
<li><strong>Resource</strong>: object or objects (by ARN) the statement covers</li>
</ul>
<pre><code>{
  "Version" "2012-10-17"
  "Statement": {
    "Effect": "Allow",            # Allow or Deny
    "Action": "ec2:RunInstances", # Describes the specific Action
    "Resource": "*"               # ARN it applies to (here: all EC2 instances)
  }
}
</code></pre>
<p><strong>Note</strong>: <em>Action</em> and <em>Resource</em> accepts wildcards.</p>
<p>Optional parts are</p>
<ul>
<li><strong>Principal</strong>: Specifies the principal that is allowed to access a resource.</li>
<li><strong>Condition</strong>: Specifies conditions for when a policy is in effect.</li>
</ul>
<h3 id="policy-types"><a class="header" href="#policy-types">Policy Types</a></h3>
<ul>
<li>Identity based policies (attached to an identity)</li>
<li>Resource based policies (attached to a resource)</li>
</ul>
<p>Resource based policies are used to attach permissions to the <strong>Principal</strong>.
Identity based policies do <strong>not</strong> make use of the Principal element.</p>
<p><strong>Example</strong>: IAM Policy that allows all Principals, but ony from certail IP
addresses</p>
<pre><code>"Principal": "*"`,
"Condition": { "IpAddress": { "aws:SourceIp": ["&lt;IP ADDRESS&gt;"]}}
</code></pre>
<h3 id="managed-policy-vs-inline-policy"><a class="header" href="#managed-policy-vs-inline-policy">Managed Policy vs Inline Policy</a></h3>
<p>Both <em>managed policies</em> and <em>inline policies</em> can be attached to user, groups,
and roles.</p>
<ul>
<li>A <em>managed policy</em> is a standalone policy that can have its own ARN. It can
have a 1-to-many relationship to users, groups, and roles.</li>
<li>An <em>identity policy</em> has a 1-to-1 relationship with a user, group or role. It
is deleted when the related principal entity is deleted.</li>
</ul>
<p>Managed policy can be created with either <code>AWS::IAM:ManagedPolicy</code>, or
<code>AWS::IAM:Policy</code> with <code>PolicyType: Managed</code>. The main difference is the former
is standalone with its own ARN. The latter is embedded in the stack its created
in.</p>
<h2 id="iam-evaluation-logic"><a class="header" href="#iam-evaluation-logic">IAM Evaluation Logic</a></h2>
<ol>
<li>Is the user the root user   -&gt; <strong>Allow</strong></li>
<li>Is there a specific "Deny"? -&gt; <strong>Deny</strong></li>
<li>Is there a specific "Allow" -&gt; <strong>Allow</strong></li>
<li>-&gt; <strong>Deny</strong></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lambda-1"><a class="header" href="#lambda-1">Lambda</a></h1>
<ul>
<li>15 min runtime</li>
</ul>
<h2 id="lambdaedge"><a class="header" href="#lambdaedge">Lambda@Edge</a></h2>
<p>Maximum size of 1 MB.</p>
<p>Limitations:</p>
<ul>
<li>does not support environment variables</li>
<li>must be in us-east-1</li>
<li>cannot be in VPC</li>
<li>cannot be referenced with $LATEST$ or aliases; must use a version number</li>
<li>can only be triggered by certain CloudFront events
<ul>
<li>Viewer request</li>
<li>Origin request</li>
<li>Origin response</li>
<li>Viewer response</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="linux---systemd"><a class="header" href="#linux---systemd">Linux - Systemd</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="systemd"><a class="header" href="#systemd">systemd</a></h1>
<ul>
<li>Name: <code>name.service</code></li>
</ul>
<h2 id="unit-file"><a class="header" href="#unit-file">Unit File</a></h2>
<p>A simple structure</p>
<pre><code>[Unit]
Description=The name of the service
Wants=other services to start up
Requires=requires named service to start or fail
After=guaranteed to start after named service

[Service]
Type=simple
User=root
Group=root
Environment=SOMEVAR=someval
WorkingDirectory=/root
ExecStart=/root/my_program.sh
TimeoutSec=30s
Restart=always
RestartSec=15s

[Install]
WantedBy=multi-user.target
</code></pre>
<p>Unit files are stored in</p>
<ul>
<li><code>/etc/systemd/system/</code></li>
</ul>
<p><code>systemctl list-unit-files</code></p>
<h2 id="systemctl"><a class="header" href="#systemctl"><code>systemctl</code></a></h2>
<ul>
<li><code>systemctl start name.service</code></li>
<li><code>systemctl stop name.service</code></li>
<li><code>systemctl enable name.service</code> starts when system boots</li>
<li><code>systemctl disable name.service</code> does not start when system boots</li>
</ul>
<p>Status</p>
<pre><code class="language-sh">systemctl restart name.service
</code></pre>
<pre><code class="language-sh">systemctl status name.service
</code></pre>
<p><strong>Note</strong>: <code>.service</code> can be omitted in <code>name.service</code>.</p>
<h2 id="logs"><a class="header" href="#logs">Logs</a></h2>
<pre><code class="language-sh">journalctl -fu &lt;service name&gt;
</code></pre>
<p>where <code>-f</code> is short for <code>--follow</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="users-and-groups"><a class="header" href="#users-and-groups">Users and Groups</a></h1>
<ul>
<li><em>/etc/passwd</em></li>
<li><em>/etc/group</em></li>
<li><em>/etc/shadow</em></li>
</ul>
<h2 id="etcpasswd"><a class="header" href="#etcpasswd"><em>/etc/passwd</em></a></h2>
<pre><code>&lt;user name&gt;:x:&lt;id of user&gt;:&lt;id of primary group&gt;:&lt;description of user&gt;:&lt;home dir&gt;:&lt;login shell&gt;
</code></pre>
<h2 id="etcgroup"><a class="header" href="#etcgroup"><em>/etc/group</em></a></h2>
<pre><code>&lt;group name&gt;:x:&lt;id of group&gt;:&lt;members&gt;
</code></pre>
<h2 id="etcshadow"><a class="header" href="#etcshadow"><em>/etc/shadow</em></a></h2>
<pre><code>&lt;user name&gt;:&lt;password hash&gt;:&lt;password meta data&gt;
</code></pre>
<h3 id="password-hash"><a class="header" href="#password-hash"><em>password hash</em></a></h3>
<ul>
<li>If starts with ! it denotes that the account is locked</li>
<li>If it is onlt an asterix * it means the user cannot be logged into with a password</li>
</ul>
<h2 id="users"><a class="header" href="#users">Users</a></h2>
<ul>
<li>normal users</li>
<li>root users
<ul>
<li>the <em>root</em> user</li>
<li>normal users with sudo access</li>
</ul>
</li>
</ul>
<p>Create user with home directory (<code>-m</code>)</p>
<pre><code>usermod -m &lt;user name&gt;
</code></pre>
<p><em>Note</em>: prepopulated with stuf from <em>/etc/skel</em>.</p>
<p>Change shell (<code>-s</code>) of user</p>
<pre><code>usermod -s /bin/bash &lt;user name&gt;
</code></pre>
<p>Change password of user</p>
<pre><code>passwd &lt;user name&gt;
</code></pre>
<p>Lock user</p>
<pre><code>passwd -l &lt;user name&gt;
</code></pre>
<p>Unlock user</p>
<pre><code>passwd -u &lt;user name&gt;
</code></pre>
<h3 id="sudoers"><a class="header" href="#sudoers">Sudoers</a></h3>
<p>Must use <code>visudo</code></p>
<pre><code>visudo /etc/sudoers
</code></pre>
<h2 id="groups"><a class="header" href="#groups">Groups</a></h2>
<p><code>groupadd</code>, <code>groupdel</code></p>
<p>Append user to group</p>
<pre><code>usermod -a -G &lt;group name&gt; &lt;user name&gt;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="debian-package"><a class="header" href="#debian-package">Debian Package</a></h1>
<pre><code>sudo apt install build-essential debhelper debmake devscripts
</code></pre>
<p>Do not build as root.</p>
<hr />
<p>A Debian package is a collection of files that allow for applications or libraries to be distributed via the package management system.</p>
<p>The aim of packaging is to allow the automation of installing, upgrading, configuring, and removing computer programs for Debian in a consistent manner.</p>
<p>A package consists of one source package, and one or more binary packages.</p>
<ul>
<li>Binary packages contain executables, standard configuration files, other resources required for executables to run.</li>
<li>Source packages contain the upstream source distribution, configuration for the package build system, list of runtime dependencies and conflicting packages, a machine-readable description of copyright and license information, initial configuration for the software, and more.</li>
</ul>
<p>The Debian Policy specifies the standard format for a package, which all packages must follow.</p>
<p>The source package (.dsc) and binary packages (.deb) will be built for you by tools such as dpkg-buildpackage.</p>
<hr />
<ul>
<li>upstream tarball: tar.gz containing software written by upstream developer.</li>
<li>source package: built from upstream source.</li>
<li>binary package: built from source package. Is distributed and installed.</li>
</ul>
<h2 id="source-package"><a class="header" href="#source-package">Source Package</a></h2>
<p>The simplest source package consists of three files:</p>
<ul>
<li>The <strong>upstream tarball</strong>, renamed according to the naming convention</li>
<li>A <strong>debian</strong> directory containing the changes made to upstream source, plus all the files required for the creation of a binary package.</li>
<li>A <strong>description file</strong> (with .dsc extension), which contains metadata for the above two files.</li>
</ul>
<h2 id="the-packaging-workflow-manual"><a class="header" href="#the-packaging-workflow-manual">The packaging workflow (Manual)</a></h2>
<h3 id="step-1-rename-the-upstream-tarball"><a class="header" href="#step-1-rename-the-upstream-tarball"><strong>Step 1</strong>: Rename the upstream tarball</a></h3>
<p>Naming convention: <code>&lt;source package name&gt;_&lt;upstream version number&gt;.orig.tar.gz</code>.
The source package name should be all lower case, and can contain letters, digits, and dashes.</p>
<pre><code>mv foo-1.0.tar.gz foo_1.0.orig.tar.gz
</code></pre>
<h3 id="step-2-unpack-the-upstream-tarball"><a class="header" href="#step-2-unpack-the-upstream-tarball"><strong>Step 2</strong>: Unpack the upstream tarball</a></h3>
<p>The source should unpack into a directory of the same name and upstream version with a hyphen in between (not an underscore),
so the upstream tarball should unpack into a directory called <code>&lt;source package name&gt;-&lt;upstream version number&gt;</code></p>
<pre><code>foo-1.0
</code></pre>
<h3 id="step-3-add-the-debiantargz-files"><a class="header" href="#step-3-add-the-debiantargz-files"><strong>Step 3</strong>: Add the debian.tar.gz files</a></h3>
<p><strong>Note</strong>: Use</p>
<pre><code>debmake
</code></pre>
<p>to create sensible template files. They need to be modified.</p>
<hr />
<p><code>cd</code> into extracted tarball and create <code>debian/</code> directory, then add the following files</p>
<ul>
<li><code>debian/changelog</code> This is the log of changes to the Debian package. It has a standard format, use the <code>dch</code> tool.
<strong>Note</strong>: version can be eg <code>1.9.2-4</code>.</li>
</ul>
<pre><code>dch --create -v &lt;upstream version&gt;-&lt;Debian version&gt; --package &lt;source package name&gt;
</code></pre>
<ul>
<li><code>debian/control</code>: describes the source and binary package, and gives some information about them.
Eg</li>
</ul>
<pre><code>Source: foo
Section: python
Priority: optional
Maintainer: noone &lt;noone@nocomp.com&gt;
Build-Depends: debhelper-compat (= 12),
               dh-python,
               python3-all,
               python3-setuptools,
               pybuild-plugin-pyproject
Standards-Version: 4.5.0
X-Python3-Version: &gt;= 3.10

Package: python3-foo
Architecture: all
Multi-Arch: foreign
Depends: ${misc:Depends}, ${python3:Depends}
Description: Dummy description
</code></pre>
<p><strong>Note</strong>: pybuild-plugin-pyproject is needed when using <em>pyproject.toml</em> file.</p>
<ul>
<li><code>debian/copyright</code></li>
<li><code>debian/rules</code>: a makefile</li>
</ul>
<pre><code>#!/usr/bin/make -f
# You must remove unused comment lines for the released package.
#export DH_VERBOSE = 1
export PYBUILD_NAME = foo
export PYBUILD_INTERPRETERS = python3.10

%:
	dh $@ --with python3 --buildsystem=pybuild
</code></pre>
<ul>
<li><code>debian/source/format</code>: it should contain the version number for the format of the source package, eg</li>
</ul>
<pre><code>3.0 (quilt)
</code></pre>
<h3 id="step-4-build-the-package"><a class="header" href="#step-4-build-the-package"><strong>Step 4</strong>: Build the package</a></h3>
<h4 id="debuild"><a class="header" href="#debuild">debuild</a></h4>
<pre><code>$ debuild -us -uc
</code></pre>
<p>Reiterate until it works. The files will be found in parent directory <code>ls ..</code>.</p>
<h4 id="pbuilder"><a class="header" href="#pbuilder">pbuilder</a></h4>
<pre><code>sudo apt install pbuilder debootstrap devscripts debian-archive-keyring
</code></pre>
<pre><code>sudo pbuilder create --distribution sid --mirror http://ftp.us.debian.org/debian/ --debootstrapopts "--keyring=/usr/share/keyrings/debian-archive-keyring.gpg"
</code></pre>
<pre><code>pdebuild
</code></pre>
<pre><code>sudo pbuilder build ../&lt;source file .dsc&gt;
</code></pre>
<p>deb file will be under <em>/var/cache/pbuilder/result/</em>.</p>
<p>Inspect contents of deb package with</p>
<pre><code>dpkg -c &lt;.deb&gt;
</code></pre>
<h3 id="step-5-test-the-package"><a class="header" href="#step-5-test-the-package"><strong>Step 5</strong>: Test the package</a></h3>
<pre><code>sudo dpkg -i ../&lt;source package name&gt;_&lt;version&gt;_&lt;architecture&gt;.deb
</code></pre>
<h2 id="git-buildpackage"><a class="header" href="#git-buildpackage">git-buildpackage</a></h2>
<p>Config file at <em>debian/gbp.conf</em>.</p>
<ul>
<li><strong>debian-branch</strong> (default = <em>master</em>)</li>
<li><strong>upstream-branch</strong> (default = <em>upstream</em>)</li>
<li><strong>pristine-tar branch</strong> (default = <em>pristine-tar</em>)</li>
<li><strong>patch-queue branch</strong> (default eg <em>patch-queue/master</em>)</li>
</ul>
<p><a href="https://dep-team.pages.debian.net/deps/dep14/">Suggested naming</a></p>
<ul>
<li><strong>debian-branch</strong>
<ul>
<li><em>debian/latest</em> for the main packaging branch</li>
<li><em>debian/bookworm</em> for distribution release</li>
</ul>
</li>
<li><strong>upstream-branch</strong>
<ul>
<li><em>upstream/latest</em> for most recent upstream code</li>
</ul>
</li>
</ul>
<h3 id="steps"><a class="header" href="#steps">Steps</a></h3>
<h3 id="import-upstream-package"><a class="header" href="#import-upstream-package">Import upstream package</a></h3>
<h4 id="import-dsc"><a class="header" href="#import-dsc">Import dsc</a></h4>
<p>dsc file is metadata file that points at tarballs</p>
<pre><code>gbp import-dsc --allow-unauthorized --create-missing-branches &lt;dsc file&gt;
</code></pre>
<p><strong>Note</strong>: Omitting <code>--allow-unauthorized</code> requires checks against author's gpg keys.</p>
<h4 id="import-orig"><a class="header" href="#import-orig">Import orig</a></h4>
<pre><code>gbp import-orig -u 0.1 ../package-0.1.tar.gz
</code></pre>
<pre><code>git merge upstream
</code></pre>
<p>This breaks patches, so do</p>
<pre><code>gbp pq rebase
</code></pre>
<p>resolve conflicts</p>
<h4 id="import-ref"><a class="header" href="#import-ref">Import ref</a></h4>
<ol>
<li><code>git tag upstream/&lt;version&gt;</code> in upstream-branch</li>
<li><code>gbp import-ref -u &lt;version&gt;</code> in debian-branch</li>
<li><code>gbp dch -N &lt;version&gt;-&lt;debian rev&gt;</code> and commit debian/changelog</li>
<li><code>gbp buildpackage</code></li>
</ol>
<h3 id="refresh-patches"><a class="header" href="#refresh-patches">Refresh patches</a></h3>
<p>Import patches, then exprt them. This makes diffs cleaner for later, since gbp uses sligthly different sytnax</p>
<pre><code>gbp pq import
</code></pre>
<p>creates patch queue on a branch</p>
<pre><code>gbp pq export
</code></pre>
<pre><code>git add -u &amp;&amp; git commit -m "refresh patches"
</code></pre>
<p>Each patch is a single commit</p>
<h3 id="pick-patch"><a class="header" href="#pick-patch">Pick patch</a></h3>
<pre><code>git switch patch-queue/&lt;...&gt;
</code></pre>
<pre><code>git cherry-pick &lt;HASH&gt;
</code></pre>
<pre><code>gbp pq export
</code></pre>
<p>exports them to debian-branch.</p>
<ul>
<li>debian/patches/ will have a new file for the changes</li>
<li>debian/patches/series will be modified for telling machinery how to apply in order</li>
</ul>
<pre><code>git add debian/ &amp;&amp; git commit -m "upstream commit &lt;hash&gt;"
</code></pre>
<h3 id="update-changelog"><a class="header" href="#update-changelog">Update changelog</a></h3>
<p>Use <code>dch</code> or <code>gbp dch</code></p>
<pre><code>dch -v 3.2-4build1+something
</code></pre>
<p><code>gbp dch</code> generate debian/changelog automatically from previous git commit messages.</p>
<ul>
<li>
<p>New version <code>gbp dch -N &lt;new-version&gt;</code></p>
</li>
<li>
<p>Snapshot <code>gbp dch -S</code></p>
</li>
<li>
<p>Release <code>gbp dch -R</code></p>
</li>
<li>
<p>fill out changelog</p>
</li>
<li>
<p>modify UNRELEASED to our os release version</p>
</li>
</ul>
<pre><code>git add debian &amp;&amp; git commit -m "finish changelog for 3.2-4build1+something" 
</code></pre>
<h3 id="build-package"><a class="header" href="#build-package">Build package</a></h3>
<pre><code>gbp buildpackage -us -uc --git-pristine-tar --git-debian-branch=&lt;branch name&gt;
</code></pre>
<p><strong>Note</strong>: <code>-us -uc</code> turns off gpg signing</p>
<p>Try in Docker</p>
<pre><code>docker run -v $PWD/../dist:/dist:ro --rm --it ubuntu:jammy bash
</code></pre>
<p><strong>Note</strong>: Change <code>$PWD/../dist</code> to wherever deb packages gets put into</p>
<p>Then do <code>apt update</code> and <code>apt install</code> on the deb package.</p>
<h3 id="build-source-package-for-uploading"><a class="header" href="#build-source-package-for-uploading">Build source package (for uploading)</a></h3>
<pre><code>gbp buildpackage --git-builder="debuild -S" --git-pristine-tar --git-debian-branch=&lt;branch name&gt;
</code></pre>
<p>Upload the <code>_source.changes</code> file to Launchpad</p>
<pre><code>dput ppa:&lt;name of ppa&gt; *_source.changes
</code></pre>
<p>Launchpad infrastructure builds it fromt there.</p>
<h2 id="random"><a class="header" href="#random">Random</a></h2>
<ul>
<li><code>quilt</code> is used for patching.</li>
<li><code>sudo dpkg-buildpackage -r fakeroot -b -uc -us</code>, <code>-b</code> for binary, <code>-uc</code> for no crypt sign, <code>-us</code> for no source sign.</li>
<li><code>sudo dpkg -i &lt;deb&gt;</code></li>
<li><code>sudo apt install -f</code> install missing dependencies for package</li>
<li><code>/etc/apt/sources.list</code> uncomment src to be able to do <code>apt source &lt;pkg&gt;</code> to install source files</li>
<li>Go from Unstable (sid) -&gt; Testing -&gt; Stable</li>
<li>Many 3rd party packages install to /opt/PACKAGE, so that they don't have to think about clashing with other packages. If you're installing into /usr/ you do need to pay some attention to debian policy and other packages, to avoid conflicts.</li>
<li>generally: /usr/{share,lib,bin} belongs to the package managed system and /usr/local/ belongs to the local sysadmin, not apt. So apt install should <em>not</em> go into /usr/local/bin/.</li>
</ul>
<h2 id="source-1"><a class="header" href="#source-1">Source</a></h2>
<ul>
<li><a href="https://wiki.debian.org/Packaging/Intro">Debian packaging intro</a></li>
<li><a href="https://wiki.debian.org/Packaging/Learn">Debian packaging learn</a></li>
<li><a href="https://wiki.debian.org/Python/Pybuild">Pybuild</a></li>
<li><a href="https://wiki.debian.org/PackagingWithGit">Packaging with Git</a></li>
<li><a href="https://honk.sigxcpu.org/projects/git-buildpackage/manual-html/index.html">Building Debian Packages with git-buildpackage</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="linux-essential-tools"><a class="header" href="#linux-essential-tools">Linux Essential Tools</a></h1>
<ul>
<li>cron</li>
<li>systemctl</li>
</ul>
<h2 id="networking"><a class="header" href="#networking">Networking</a></h2>
<ul>
<li>curl</li>
<li>ping</li>
<li>traceroute</li>
<li>dig</li>
<li>ss</li>
<li>lsof</li>
<li>ip</li>
<li>tcpdump</li>
<li>wireshark</li>
<li>strace</li>
<li>gdb</li>
<li>bpftrace</li>
<li>ebpf</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="iproute2"><a class="header" href="#iproute2">iproute2</a></h1>
<p>iproute2 is a collection of userspace utilities for controlling and monitoring various aspects of networking in the Linux kernel. They communicate with the kernel using the <strong>netlink</strong> protocol.</p>
<p>iproute2 collection contains the following command-line utilities:</p>
<ul>
<li><code>arpd</code></li>
<li><code>bridge</code></li>
<li><code>ctstat</code></li>
<li><code>dcb</code></li>
<li><code>devlink</code></li>
<li><code>ip</code></li>
<li><code>lnstat</code></li>
<li><code>nstat</code></li>
<li><code>rdma</code></li>
<li><code>routef</code></li>
<li><code>routel</code></li>
<li><code>rtacct</code></li>
<li><code>rtmon</code></li>
<li><code>rtstat</code></li>
<li><code>ss</code>: sockets</li>
<li><code>tc</code>: used for traffic control</li>
<li><code>tipc</code></li>
<li><code>vdpa</code></li>
</ul>
<h1 id="ip-2"><a class="header" href="#ip-2">ip</a></h1>
<p><code>ip link show</code>: information about network interface device. Shows information on <strong>OSI layer 2</strong> ("data link layer").</p>
<p><strong>Note</strong>: <code>ip -d link show</code> shows extra information. Can also be combined with types, eg <code>ip -d l show type bridge</code></p>
<p><code>ip address show</code>: Same information as <code>ip l</code> but also <strong>OSI layer 3</strong> ("network layer").</p>
<p><code>ip route show</code> the connection to other ip networks</p>
<p>default gateway and routes available on system.</p>
<p>A default gateway needs to be on the same network.</p>
<p>The lower the metric, the higher the priority for that network interface.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="wireguard"><a class="header" href="#wireguard">Wireguard</a></h1>
<p>WireGuard securely encapsulates IP packets over UDP.</p>
<p>You add a WireGuard interface, configure it with your private key and your peers' public keys, and then you send packets across it.</p>
<p>All issues of key distribution and pushed configurations are out of scope of WireGuard.</p>
<p>WireGuard works by adding a network interface. This network interface can then be configured normally using ifconfig(8) or ip-address(8), with routes for it added and removed using route(8) or ip-route(8), and so on with all the ordinary networking utilities. The specific WireGuard aspects of the interface are configured using the wg(8) tool. This interface acts as a tunnel interface.</p>
<h2 id="cryptokey-routing-table"><a class="header" href="#cryptokey-routing-table">Cryptokey Routing Table</a></h2>
<p>Simple association of peer public key and allowed IPs.</p>
<p>A <strong>Peer</strong> is defined by its public key. If the packet, when decrypted, is also from an allowed ip, it will be allowed onto the interface.</p>
<p>Outgoing traffic destination address will be matched on <strong>AllowedIPs</strong>, and in that case be put on the WireGuard interface.</p>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<h3 id="generate-keys"><a class="header" href="#generate-keys">Generate Keys</a></h3>
<pre><code>wg genkey | tee privatekey | wg pubkey &gt; publickey
</code></pre>
<h3 id="example-1"><a class="header" href="#example-1">Example</a></h3>
<pre><code># /etc/wireguard/wg0.conf

[Interface]
PrivateKey = AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEE=
Address = 10.0.0.1/32
ListenPort = 51821

[Peer]
PublicKey = fE/wdxzl0klVp/IR8UcaoGUMjqaWi3jAd7KzHKFS6Ds=
AllowedIPs = 192.168.200.0/24
Endpoint = 203.0.113.2:51822
</code></pre>
<ul>
<li>Interface
<ul>
<li><code>PrivateKey</code>: your private key used to decrypt messages</li>
<li><code>Address</code>: virtual address of the local WireGuard peer, it’s the IP address of the virtual network interface that WireGuard sets up for the peer</li>
<li><code>ListenPort</code>: Port WireGuard will listen for incoming UDP traffic</li>
</ul>
</li>
<li>Peer
<ul>
<li><code>PublicKey</code>: public key of peer used to encrypt messages</li>
<li><code>AllowedIPs</code>: whitelist of IPs from messages with PublicKey</li>
<li><code>Endpoint</code>: When traffic is routed to a virtual WireGuard endpoint, endpoint tells which real IP to send the traffic to</li>
</ul>
</li>
</ul>
<p>Using this example, after running <code>wg-quick up wg0</code>, the host will have an network interface with IP 10.0.0.1.</p>
<p><code>wg showconf wg0</code> will show the current <strong>ListenPort</strong>. Running <code>ss -ulpn | grep &lt;ListenPort&gt;</code> will show that process. Note that lsof will not show anything since WireGuard is running in the kernel.</p>
<h3 id="custom-rouing"><a class="header" href="#custom-rouing">Custom Rouing</a></h3>
<p><code>PostUp</code>: execute custom script when the interface is brought up.</p>
<p><code>PostDown</code>: execute custom script when the interface is brought down.</p>
<pre><code>PostUp = /usr/local/bin/fw --wg-if %i --up
PostDown = /usr/local/bin/fw --wg-if %i --down
</code></pre>
<ul>
<li><code>%i</code> is replaced by interface name</li>
</ul>
<pre><code>Table = off
</code></pre>
<p>By default WireGuard adds routes to the system, but <code>Table = off</code> disables this feature. Routing needs to be managed by itself if this options is turned off.</p>
<h2 id="flow"><a class="header" href="#flow">Flow</a></h2>
<p>Outgoing</p>
<ol>
<li>When the host sends a request to an ip inside <strong>AllowedIPs</strong>, eg 192.168.200.22, the OS will check its routing table to see which local network interface to bind the new TCP socket to - in this case <em>wg0</em>.</li>
<li><em>wg0</em> is selected as interface, and it will use the source IP of 10.0.0.1 (<strong>Address</strong> field).</li>
<li>A packet is created that is handled by the <em>wg0</em> interface that checks its lists of <strong>AllowedIPs</strong> to see if a <strong>Peer</strong> is associated with the packet's destination address (in this case 192.168.200.22 is).</li>
<li>WireGuard encrypts the message with the <strong>PublicKey</strong> of the peer, and wraps it into an UDP packet and sends it to the <strong>Endpoint</strong> ip of the <strong>Peer</strong>.</li>
<li>WireGuard will consult the routing table for which local network interface to use for the new UDP packet created by WireGuard. The source ip will be that of the interface used (eg <em>wlan0</em>'s), and the source port will be <strong>ListenPort</strong> from configuration.</li>
</ol>
<p>Incoming</p>
<ol>
<li>WireGuard will be listening for UDP on <strong>ListenPort</strong> (51821)</li>
<li>WireGuard will decrypt it using <strong>PrivateKey</strong> and place any decrypted packets on the network stack as if they had come directly from <em>wg0</em> interface.</li>
</ol>
<h2 id="useful-commands"><a class="header" href="#useful-commands">Useful Commands</a></h2>
<ul>
<li><code>sudo wg</code></li>
<li><code>wg showconf</code></li>
<li><code>wg show</code></li>
<li><code>wg-quick up &lt;interface name&gt;</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kvm"><a class="header" href="#kvm">KVM</a></h1>
<p>KVM (Kernel-based Virtual Machine) is a virtualization infractructure that turns the kernel into a type 1 hypervisor (native/bare-metal) - a software layer that sits between the hardware and the VMs, managing resource allocation, scheduling, and communication.</p>
<p>Virtualization is the abstraction of computing resources from the hardware layer, allowing multiple virtual environments to run simultaneously on a single physical machine (the host) while ensuring full resource separation. These virtual environments, known as virtual machines (VMs) or guests, act as self-contained entities with their own operating systems, kernels and applications.</p>
<h2 id="qemu"><a class="header" href="#qemu">QEMU</a></h2>
<p>QEMU is an emulator that can also be used as a virtualizer with the help of KVM to provide a native speed by accessing Intel VT-x or AMD V technology of modern processors.</p>
<h2 id="virtual-machine-manager"><a class="header" href="#virtual-machine-manager">Virtual Machine Manager</a></h2>
<p><code>virt-manager</code></p>
<p>GUI for KVM.</p>
<h2 id="install-and-test"><a class="header" href="#install-and-test">Install and Test</a></h2>
<p>Install KVM, QEMU and Virtual Machine Manager</p>
<pre><code class="language-bash">sudo apt install bridge-utils cpu-checker libvirt-clients libvirt-daemon qemu qemu-kvm virt-manager
</code></pre>
<p><em>Note</em>: bridge-utils is to use a bridged network adapter which allows VMs to be seen as real machines on the network.</p>
<p>Check that KVM is functioning</p>
<pre><code class="language-bash">kvm-ok
</code></pre>
<p>Download iso image, eg from <a href="http://cdimage.ubuntu.com/">ubuntu</a></p>
<pre><code class="language-bash">systemctl status libvirtd.service
</code></pre>
<p>Add user to <code>kvm</code> and <code>libvirtd</code></p>
<pre><code class="language-bash">sudo usermod -aG kvm $USER
sudo usermod -aG libvirtd $USER
</code></pre>
<p>Libvirt is a wrapper around kvm and qemu. The qemu commands themselves are very complicated.</p>
<h2 id="network-1"><a class="header" href="#network-1">Network</a></h2>
<p>Choose <strong>Network source</strong> to be <strong>Bridge device</strong>, and <strong>Device name</strong> is usually <strong>virbr0</strong> (the network interface on the host machine).</p>
<p>DHCP speaks on port 67 and 68 (incoming and outcoming traffic), make sure they are not blocked bu the firewall.</p>
<h2 id="copy-paste"><a class="header" href="#copy-paste">Copy Paste</a></h2>
<pre><code>sudo apt install spice-vdagent
</code></pre>
<h2 id="sources"><a class="header" href="#sources">Sources</a></h2>
<ul>
<li><a href="https://linux.how2shout.com/how-to-install-qemu-kvm-and-virt-manager-gui-on-ubuntu-20-04-lts/">kvm, qemu  &amp; virt-manager</a></li>
<li><a href="https://medium.com/@DrewViles/using-libvirt-kvm-qemu-to-create-vms-792e49262304">tutorial</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="log"><a class="header" href="#log">Log</a></h1>
<p>systemd-journald.service listens for all messages on the system by way of the <em>syslog protocol</em>.</p>
<p><code>journalctl</code> aggregates all the different sources into one journal.</p>
<p>rsyslog reads all systemd-journald messages and puts them in their respective log files.</p>
<p><code>logrotate</code> is the tool for log management.</p>
<h2 id="rsyslog"><a class="header" href="#rsyslog">rsyslog</a></h2>
<p><em>/etc/rsyslog.conf</em> and <em>/etc/rsyslog.d/<file name>.conf</em> has the format of</p>
<pre><code># Facility.priority		 location 
mail.err                 /var/mail/log.err

# wildcards
kern.*                   /var/log/kern.log
*lpr.*                   /var/log/lpr.log
</code></pre>
<h2 id="files-1"><a class="header" href="#files-1">Files</a></h2>
<p>Logs go into <em>/var/log/</em>.</p>
<ul>
<li><em>/var/log/syslog</em> contains all logs except auth</li>
<li><em>/var/log/auth.log</em> auth messages</li>
<li><em>/var/log/dmesg</em> kernel ring buffer messages</li>
<li><em>/var/log/kern.log</em> superset of dmesg</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lutris"><a class="header" href="#lutris">Lutris</a></h1>
<h2 id="install-wine"><a class="header" href="#install-wine">Install Wine</a></h2>
<pre><code class="language-sh">sudo dpkg --add-architecture i386
sudo apt update
sudo apt install -y wine64 wine32 libasound2-plugins:i386 libsdl2-2.0-0:i386 libdbus-1-3:i386 libsqlite3-0:i386
</code></pre>
<h2 id="install-lutris"><a class="header" href="#install-lutris">Install Lutris</a></h2>
<pre><code class="language-sh">sudo add-apt-repository ppa:lutris-team/lutris
sudo apt update
sudo apt install lutris
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="nftables"><a class="header" href="#nftables">nftables</a></h1>
<p>Successor of iptables.</p>
<p>Provides hooks to <code>conntrack</code>.</p>
<h2 id="basics"><a class="header" href="#basics">Basics</a></h2>
<p>Supports stateless and stateful rules.</p>
<p>Supports bitwise operators on packets.</p>
<p>Rules are processed from top to bottom until a match is found.
If no match is found, the default policy is found (if not explicitly stated it is deny).</p>
<p>Basic approach is to create a <em>table</em>, then a <em>chain</em>, then a <em>rule</em>. There are no predefined tables or chains in nftables, they have to be created.</p>
<p>Each command should include an <em>address family</em>, which are one of</p>
<ul>
<li>ip, IPv4</li>
<li>ip6, IPv6</li>
<li>inet, internet (IPv4/IPv6)</li>
<li>arp, ARP (IPv4 ARP packets)</li>
<li>bridge, Bridge (L2)</li>
<li>netdev, Netdev</li>
</ul>
<p>Chains are <em>input</em>, <em>output</em> or <em>forward</em>.</p>
<h3 id="install"><a class="header" href="#install">Install</a></h3>
<pre><code>sudo apt install nftables
systemctl enable nftables.service
</code></pre>
<pre><code>sudo nft list ruleset
</code></pre>
<p>Check if enabled in the kernel with</p>
<pre><code>lsmod | grep ^nf
</code></pre>
<p>To see the current configuration, use</p>
<pre><code>nft list ruleset
</code></pre>
<p>Be sure not to have Xtables and iptables on at the same time</p>
<pre><code>systemctl stop iptables ;\
 iptables --flush ; iptables --list
</code></pre>
<pre><code>systemctl stop ip6tables ;\
 ip6tables --flush; ip6tables --list
</code></pre>
<p><em>Note</em>: <code>nft flush ruleset</code> to disable <code>nftables</code>.</p>
<hr />
<h2 id="config"><a class="header" href="#config">Config</a></h2>
<p><em>/etc/nftables.conf</em></p>
<pre><code>#!/usr/sbin/nft -f

flush ruleset

table inet filter {
	chain input {
        # default drop
        type filter hook input priority 0; policy drop;

        ct state invalid drop

        # established, related
        ct state {established,related} accept comment "accept traffic originating from us"

        # loopback
        iif lo accept comment "accept loopback"
        iif != lo ip daddr 127.0.0.1/8 drop comment "drop connections to loopback not coming from loopback" 
        iif != lo ip6 daddr ::1/128 drop comment "drop connections to loopback not coming from loopback" 

        # accept neighbour discovery otherwise connectivity breaks
        icmpv6 type { nd-neighbor-solicit, nd-router-advert, nd-neighbor-advert } accept

        # accept ssh
        #ip saddr &lt;ip&gt; tcp dport 22 accept
	}
	chain forward {
        # default drop
		type filter hook forward priority 0; policy drop;
	}
	chain output {
        # default accept
		type filter hook output priority 0; policy accept;
	}
}
</code></pre>
<p><em>Note</em>: Changes with <code>nft</code> CLI will dissappear after reboot unless explicitly saved. To save current setup use</p>
<pre><code>nft -s list ruleset | tee filename
</code></pre>
<p><em>Note</em>: Use <code>counter</code> keyword before verb and watch with <code>sudo watch -n 1 "nft -n list table inet filter"</code></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gnu-screen"><a class="header" href="#gnu-screen">GNU Screen</a></h1>
<p>Meta <code>Ctrl+a</code>.</p>
<h2 id="window"><a class="header" href="#window">Window</a></h2>
<p>Meta +</p>
<ul>
<li><code>c</code> create new window</li>
<li><code>"</code> list all windows</li>
<li><code>p</code> previous window</li>
<li><code>n</code> next window</li>
<li><code>&lt;number&gt;</code> select window</li>
</ul>
<p><code>Ctrl+d</code> kill window</p>
<h2 id="session"><a class="header" href="#session">Session</a></h2>
<ul>
<li><code>screen -ls</code> list sessions</li>
<li><code>screen -S &lt;session name&gt;</code> start session with given name</li>
<li><code>Ctrl+a</code> <code>d</code> detatch session</li>
<li><code>screen -x &lt;session name&gt;</code> resume session with given name</li>
<li><code>screen -S &lt;session name&gt; -X quit</code> terminate detached session</li>
</ul>
<h2 id="layout"><a class="header" href="#layout">Layout</a></h2>
<ul>
<li><code>Ctrl+a</code> <code>S</code> split horizontally</li>
<li><code>Ctrl+a</code> <code>|</code> split vertically</li>
<li><code>Ctrl+a</code> <code>X</code> close current region</li>
<li><code>Ctrl+a</code> <code>&lt;TAB&gt;</code> switch to next region</li>
<li><code>Ctrl+a</code> <code>Q</code> close all but current region</li>
</ul>
<h2 id="buffer-mode"><a class="header" href="#buffer-mode">Buffer mode</a></h2>
<ul>
<li><code>Ctrl+a</code> <code>&lt;ESC&gt;</code> enter copy mode</li>
<li><code>&lt;SPACE&gt;</code> select and copy text in copy mode</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="wine"><a class="header" href="#wine">Wine</a></h1>
<ol>
<li>Look</li>
<li>Smell</li>
<li>Taste</li>
</ol>
<p>maature/old --&gt; more intense, more complex</p>
<p>warmer --&gt; more sugar --&gt; more alcohol</p>
<p>Tounge:</p>
<pre><code>| BB |
|A  A|
|_SS_|
</code></pre>
<p>B: Bitter
A: Acid
S: Sweet</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust"><a class="header" href="#rust">Rust</a></h1>
<ul>
<li>Statically typed</li>
</ul>
<h2 id="commandline"><a class="header" href="#commandline">Commandline</a></h2>
<h3 id="rustup"><a class="header" href="#rustup">rustup</a></h3>
<p>CLI for managing rust and associated tools.</p>
<p>update Rust</p>
<pre><code class="language-sh">rustup update
</code></pre>
<p>Documentation</p>
<pre><code class="language-sh">rustup doc
</code></pre>
<p>Uninstall</p>
<pre><code class="language-sh">rustup self uninstall
</code></pre>
<h3 id="rustc"><a class="header" href="#rustc">rustc</a></h3>
<p>Compiler</p>
<pre><code class="language-sh">rustc main.rs
</code></pre>
<h3 id="rustfmt"><a class="header" href="#rustfmt">rustfmt</a></h3>
<p>Format code</p>
<pre><code class="language-sh">rustfmt
</code></pre>
<h3 id="cargo"><a class="header" href="#cargo">cargo</a></h3>
<p>Build system and package manager</p>
<ul>
<li>Crates <em>Cargo.toml</em></li>
<li>Autogenerated <em>Cargo.lock</em></li>
</ul>
<p>Create new project</p>
<pre><code class="language-sh">cargo new &lt;project-name&gt;
</code></pre>
<p>Compile binary in <em>target/debug/</em> directory</p>
<pre><code class="language-sh">cargo build
</code></pre>
<p>Compile binary with optimizations in <em>target/release/</em> directory</p>
<pre><code class="language-sh">cargo build --release
</code></pre>
<p>Compile and run</p>
<pre><code class="language-sh">cargo run
</code></pre>
<p>Checks code without compiling</p>
<pre><code class="language-sh">cargo check
</code></pre>
<p>Open documentation</p>
<pre><code class="language-sh">cargo doc --open
</code></pre>
<h2 id="file-structure"><a class="header" href="#file-structure">File structure</a></h2>
<pre><code class="language-sh">.
├── Cargo.lock
├── Cargo.toml
├── src
│    └── main.rs
└── target
     └── debug
     └── release
</code></pre>
<h2 id="running"><a class="header" href="#running">Running</a></h2>
<p>Entrypoint is the <code>main</code> function</p>
<pre><pre class="playground"><code class="language-rust">fn main() {
    Ok(())
}</code></pre></pre>
<p>The <em>prelude</em> is the list of things that Rust automatically imports into every
Rust program. Eg <code>std::result::Result::{self, Ok, Err}</code>;</p>
<h2 id="dependencies"><a class="header" href="#dependencies">Dependencies</a></h2>
<p><em>Cargo.toml</em>: dependencies used by cargo.</p>
<p><em>Cargo.io</em>: registry of dependencies.</p>
<h2 id="variables"><a class="header" href="#variables">Variables</a></h2>
<ul>
<li><code>let</code>: define variable.</li>
<li><code>const</code>: define constant.</li>
</ul>
<p><em>Note:</em> <code>const</code> variables must have type annotation.</p>
<p><em>Note:</em> <code>const</code> variables must be assigned to a compile time expression.</p>
<h3 id="ownership-variables-on-the-heap"><a class="header" href="#ownership-variables-on-the-heap">Ownership (variables on the heap)</a></h3>
<p><em>Ownership</em> is an alternative to garbage collection and manual memory
allcoation.</p>
<ul>
<li>Each value has a variable that's called its owner.</li>
<li>There can only be one owner at a time.</li>
<li>When the owner goes out of scope, the value will be dropped (the function
<code>drop</code> is called).</li>
</ul>
<p>if another variable is assigned to its value, the value is moved and the old
variable is invalidated.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let s1 = String::from("a string");
let s2 = s1; // s1 is invalidated here
println!("{}", s1); // panic
<span class="boring">}</span></code></pre></pre>
<p><em>Note</em>: For <em>stack</em> data, values are always copied, ie types with known size
at compile time.</p>
<p><em>Note</em>: If a type implements the <code>Copy</code> trait, an older variable is still
usable after assignment. Rust won't let us annotate a type with the <code>Copy</code>
trait if the type, or any of its parts, has implemented the <code>Drop</code> trait.</p>
<h4 id="ownership-and-functions"><a class="header" href="#ownership-and-functions">Ownership and Functions</a></h4>
<p>Passing a variable to a function will move or copy in the same way a assignment
does.</p>
<pre><pre class="playground"><code class="language-rust">fn main() {
  let s1 = String::from("a string");
  let s2 = take_and_gives_back(s1);
  takes_ownership(s2);
}

fn gives_ownership() {
  let s = String::from("a string");
  s
}

fn takes_ownership(s: String) {
  println!("{}", s);
}

fn take_and_gives_back(s: String) {
  s
}</code></pre></pre>
<h3 id="references-and-borrowing"><a class="header" href="#references-and-borrowing">References and Borrowing</a></h3>
<p><code>&amp;</code> is the reference operator. References refer to a value without taking
ownership.</p>
<pre><pre class="playground"><code class="language-rust">fn main() {
  let s = String::from("a string");
  let len = calc_length(&amp;s);   // s is borrowed
  println!("{} - {}", s, len); // s was not dropped
}

fn calc_length(&amp;s: String) -&gt; usize {
}</code></pre></pre>
<p><em>Note</em>: Any amount of immutable borrows are allowed at the same time (as long
as there are no mutable borrows).</p>
<p><em>Note</em>: The compiler will ensure that data will not go out of scope before a
reference to the data does, ie no <em>dangling pointers</em>.</p>
<h4 id="mutable-reference"><a class="header" href="#mutable-reference">Mutable Reference</a></h4>
<p><code>&amp;mut</code></p>
<ul>
<li>There can only be <em>one</em> mutable borrow at a time.</li>
<li>There cannot be a mutable borrow at the same time as there are immutable
borrows.</li>
</ul>
<pre><pre class="playground"><code class="language-rust">fn main() {
  let mut s = String::from("hello");

  let r1 = &amp;s; // no problem
  let r2 = &amp;s; // no problem
  println!("{} and {}", r1, r2);
  // variables r1 and r2 will not be used after this point

  let r3 = &amp;mut s; // no problem
  println!("{}", r3);
}
</code></pre></pre>
<p><em>Note</em>: The compiler uses <em>Non-Lexical Lifetimes</em> to know a variable is not in
use before its scope ends.</p>
<h3 id="immutability"><a class="header" href="#immutability">Immutability</a></h3>
<p>Varibles are <em>immutable</em> by default.</p>
<p>Use <code>mut</code> keyword to make <em>mutable</em> variables.</p>
<p><em>Note:</em> <code>const</code> variables cannot be <code>mut</code>.</p>
<h3 id="scalar-types"><a class="header" href="#scalar-types">Scalar types</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Length</th><th style="text-align: left">Signed</th><th style="text-align: left">Unsigned</th><th style="text-align: left">Floating</th></tr></thead><tbody>
<tr><td style="text-align: left">8-bit</td><td style="text-align: left"><code>i8</code></td><td style="text-align: left"><code>u8</code></td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left">16-bit</td><td style="text-align: left"><code>i16</code></td><td style="text-align: left"><code>u16</code></td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left">32-bit</td><td style="text-align: left"><code>i32</code></td><td style="text-align: left"><code>u32</code></td><td style="text-align: left"><code>f32</code></td></tr>
<tr><td style="text-align: left">64-bit</td><td style="text-align: left"><code>i64</code></td><td style="text-align: left"><code>u64</code></td><td style="text-align: left"><code>f64</code></td></tr>
<tr><td style="text-align: left">128-bit</td><td style="text-align: left"><code>i128</code></td><td style="text-align: left"><code>u128</code></td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left">arch</td><td style="text-align: left"><code>isize</code></td><td style="text-align: left"><code>usize</code></td><td style="text-align: left"></td></tr>
</tbody></table>
</div>
<p><em>Note:</em> Literal integers default to <code>i32</code> or <code>f64</code> unless suffix is used.</p>
<p><em>Note:</em> Literal integers can contain underscores, eg <code>1_000</code>.</p>
<p><em>Note:</em> <code>isize</code> and <code>usize</code> depend on the computer architecture: 64 bits on a
64-bit architecture and 32 bits on a 32-bit architecture.</p>
<p><em>Note:</em> In debug mode, integer overflow will panic, but in release mode it will
overflow. Can be handled with <code>wwrapping_*</code>, <code>checked_*</code>, <code>overflowing_*</code> and
<code>saturating_*</code> methods.</p>
<h4 id="characters"><a class="header" href="#characters">Characters</a></h4>
<ul>
<li>4 bytes</li>
<li>Unicode Scalar Value</li>
<li>Wrapped in single-quotes, eg <code>let c: char = '😻'</code></li>
</ul>
<h3 id="compound-types"><a class="header" href="#compound-types">Compound Types</a></h3>
<p>Arrays and tuples.</p>
<h4 id="tuples"><a class="header" href="#tuples">Tuples</a></h4>
<p>Fixed size</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let tup: (i32, f64, u8) = (42, 3.14, 1);
<span class="boring">}</span></code></pre></pre>
<p>Can be destructured with pattern matching</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let (x, y, z) = tup;
<span class="boring">}</span></code></pre></pre>
<p>Individual elements can be accessed with <code>.&lt;index&gt;</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let x = tup.2;
<span class="boring">}</span></code></pre></pre>
<p>The empty tuple <code>()</code> is called the <em>unit type</em> and the value is called the
<em>unit value</em>. Expressions implicitly return the unit value if they don't return
any other value.</p>
<h4 id="arrays"><a class="header" href="#arrays">Arrays</a></h4>
<ul>
<li>All elements must have the same type</li>
<li>Fixed length</li>
<li>Lives on the stack</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let arr: [i32, 3] = [1, 2, 3];
<span class="boring">}</span></code></pre></pre>
<p>To initialize an array with the same value</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let arr = [3; 5];
<span class="boring">}</span></code></pre></pre>
<h3 id="shadowing"><a class="header" href="#shadowing">Shadowing</a></h3>
<p>Variables can be shadowed by reusing the <code>let</code> keyword.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let spaces = "     ";
let spaces = spaces.len();
<span class="boring">}</span></code></pre></pre>
<h3 id="reference"><a class="header" href="#reference">Reference</a></h3>
<p><code>&amp;</code> indicates a <em>reference</em>.</p>
<h2 id="control-flow"><a class="header" href="#control-flow">Control flow</a></h2>
<h3 id="if"><a class="header" href="#if"><code>if</code></a></h3>
<p><em>Note</em>: <code>if</code> is an expression, thus it can eg be used in a <code>let</code> statement.</p>
<p><em>Note</em>: <code>condition</code> must be a <code>bool</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if condition {
} else if {
} else {
}

<span class="boring">}</span></code></pre></pre>
<h3 id="match"><a class="header" href="#match"><code>match</code></a></h3>
<p>must cover all arms.</p>
<h3 id="if-let"><a class="header" href="#if-let"><code>if let</code></a></h3>
<p>Shorthand for covering on only one arm.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if let Ok(i) = h() 
  // ...
}
<span class="boring">}</span></code></pre></pre>
<h3 id="while-let"><a class="header" href="#while-let"><code>while let</code></a></h3>
<h3 id=""><a class="header" href="#"><code>?</code></a></h3>
<p>Shorthand for match or throw error.</p>
<h3 id="loops"><a class="header" href="#loops">Loops</a></h3>
<p><code>loop</code>, <code>while</code> and <code>for</code>.</p>
<h4 id="while"><a class="header" href="#while"><code>while</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>while index &lt; 5 {
  // snip
}
<span class="boring">}</span></code></pre></pre>
<h4 id="for"><a class="header" href="#for"><code>for</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>for e in elements {
  // snip
}
<span class="boring">}</span></code></pre></pre>
<h4 id="loop"><a class="header" href="#loop"><code>loop</code></a></h4>
<ul>
<li><code>break</code></li>
<li><code>break return_value;</code></li>
<li><code>continue</code></li>
</ul>
<p><em>Note</em>: can use labels, eg</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>'a_label: loop {
  break 'a_label;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="types"><a class="header" href="#types">Types</a></h2>
<p>Types not in the prelude can be brought into scope with a <code>use</code> statement.</p>
<p><code>::</code> is used to access <em>associated functions</em>, ie a function implemented on a
type.</p>
<h2 id="statements-and-expressions"><a class="header" href="#statements-and-expressions">Statements and Expressions</a></h2>
<p>Statements are instructions that perform some action and do not return a value.
Expressions evaluate to a resulting value.</p>
<p>Expressions do not include ending semicolons. If a semicolon is added, it is
turned into a statement.</p>
<h2 id="enums"><a class="header" href="#enums">Enums</a></h2>
<p>An enumeration is a type that can have a fixed set of values. Those values are
called <em>variants</em>.</p>
<h3 id="option-enum"><a class="header" href="#option-enum"><code>Option</code> enum</a></h3>
<p><code>Option&lt;T&gt;</code> has variants <code>Some(T)</code> or <code>None</code>.</p>
<ul>
<li>Unwrap in a <code>match</code> statement.</li>
<li><code>.map()</code></li>
<li><code>.and()</code></li>
<li><code>.and_then()</code></li>
<li><code>.or()</code></li>
<li><code>.or_else()</code></li>
<li><code>.ok_or()</code></li>
</ul>
<h3 id="result-enum"><a class="header" href="#result-enum"><code>Result</code> enum</a></h3>
<p>Rust does not have any exceptions, they are instead encoded in return types.
<code>Result</code> is the type used for returning and propagating errors.</p>
<p><code>Result&lt;T, E&gt;</code> enum has variants <code>Ok(T)</code> and <code>Err(E)</code>.</p>
<ul>
<li><code>.expect</code>: assert success with <code>expect</code>, or panic</li>
<li><code>?</code>: shortcut for <code>match</code> with return in error arm</li>
<li><code>.unwrap</code>: shortcut for <code>match</code> with <code>panic!</code> in error arm</li>
</ul>
<p><strong>Best practice</strong>: Use an enum for error type.</p>
<h3 id="ordering-enum"><a class="header" href="#ordering-enum"><code>Ordering</code> enum</a></h3>
<p><code>use std::cmp::Ordering</code></p>
<ul>
<li><code>Ordering::Less</code></li>
<li><code>Ordering::Greater</code></li>
<li><code>Ordering::Equal</code></li>
</ul>
<h2 id="module-system"><a class="header" href="#module-system">Module System</a></h2>
<p><strong>crate</strong>: is the smallest amount of code that the Rust compiler considers at a time.
Either <em>binary</em> (executable) or <em>library</em> (no main function).</p>
<p>The <strong>crate root</strong> is a source file that the Rust compiler starts from and makes up the root module of your crate.</p>
<p>A <strong>package</strong> is a bundle of one or more crates that provides a set of functionality.
A package contains a <em>Cargo.toml</em> file that describes how to build those crates.</p>
<p><strong>Note</strong>: A package can contain as many binary crates as you like, but at most only one library crate.
Additional binary crates are placed in the <em>src/bin</em> directory: each file will be a separate binary crate.</p>
<p><strong>Note</strong>: A package must contain at least one crate, whether that’s a library or binary crate.</p>
<p><code>use</code> keyword brings a path into scope.</p>
<p><code>pub</code> keyword make items public</p>
<h2 id="style"><a class="header" href="#style">Style</a></h2>
<ul>
<li>place source code under <code>src/</code></li>
<li>Use 4 spaces</li>
<li>snake_case for functions and variables</li>
<li>Open curly brackets on same row</li>
<li>use <code>cargo</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust-web-app"><a class="header" href="#rust-web-app">Rust Web App</a></h1>
<ul>
<li>Diesel</li>
<li>Rocket</li>
</ul>
<h2 id="diesel"><a class="header" href="#diesel">Diesel</a></h2>
<h3 id="install-diesel-cli"><a class="header" href="#install-diesel-cli">Install diesel cli</a></h3>
<pre><code class="language-sh">cargo install diesel_cli --no-default-features --features postgres
</code></pre>
<p>Add <code>DATABASE_URL</code> in <code>.env</code> file.</p>
<p>Setup and create database</p>
<pre><code class="language-sh">diesel setup
</code></pre>
<p>will create <code>diesel.toml</code> and a pointer to <code>src/schema.rs</code> (maintained by diesel).</p>
<p>Create (empty) migration files</p>
<pre><code class="language-sh">diesel migration generate create_posts
</code></pre>
<p>which updates <code>src/schema.rs</code>.</p>
<p>Populate <code>up.sql</code> and <code>down.sql</code> manually</p>
<p>Apply migration</p>
<pre><code class="language-sh">diesel migration run
</code></pre>
<p>Roll back migration</p>
<pre><code class="language-sh">diesel migration redo
</code></pre>
<hr />
<p>Create connection</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use diesel::pg::PgConnection;
use diesel::prelude::*;
use dotenvy::dotenv;
use std::env;

pub fn establish_connection() -&gt; PgConnection {
    dotenv().ok();

    let database_url = env::var("DATABASE_URL").expect("DATABASE_URL must be set");
    PgConnection::establish(&amp;database_url)
        .unwrap_or_else(|_| panic!("Error connecting to {}", database_url))
}
<span class="boring">}</span></code></pre></pre>
<p>Create model, eg</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use diesel::prelude::*;

#[derive(Queryable, Selectable)]
#[diesel(table_name = crate::schema::posts)]
#[diesel(check_for_backend(diesel::pg::Pg))]
pub struct Post {
    pub id: i32,
    pub title: String,
    pub body: String,
    pub published: bool,
}
<span class="boring">}</span></code></pre></pre>
<ul>
<li><code>#[derive(Queryable)]</code> will generate all of the code needed to load a Post struct from a SQL query.</li>
<li><code>#[derive(Selectable)]</code> will generate code to construct a matching select clause based on your model type based on the table defined via <code>#[diesel(table_name = crate::schema::posts)]</code></li>
<li><code>#[diesel(check_for_backend(diesel::pg::Pg)]</code> adds additional compile time checks to verify that all field types in your struct are compatible with their corresponding SQL side expressions. Optional.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bevy-engine"><a class="header" href="#bevy-engine">Bevy engine</a></h1>
<h2 id="minimal-implementation"><a class="header" href="#minimal-implementation">Minimal Implementation</a></h2>
<p><em>Cargo.toml</em></p>
<pre><code class="language-toml">[dependencies]
bevy = { version = "0.8.1", features = ["dynamic"] }
</code></pre>
<p><strong>Note</strong>: Remove <code>features = ["dynamic"]</code> before release.</p>
<p><em>main.rs</em></p>
<pre><pre class="playground"><code class="language-rust">use bevy::prelude::*;

fn main() {
    App::new().run();
}</code></pre></pre>
<h2 id="ecs-2"><a class="header" href="#ecs-2">ECS</a></h2>
<h3 id="entities"><a class="header" href="#entities">Entities</a></h3>
<p>structs containing unique integer</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Entity(u64);
<span class="boring">}</span></code></pre></pre>
<h3 id="components"><a class="header" href="#components">Components</a></h3>
<p>structs implementing <code>Component</code> trait.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Component)]
struct Position {
    x: f32,
    y: f32,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="systems"><a class="header" href="#systems">Systems</a></h3>
<p>functions.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn print_position_system(query: Query&lt;&amp;Transform&gt;) {
    for transform in qury.iter() {
        println!("position {:?}", transform.translation);
    }
}
<span class="boring">}</span></code></pre></pre>
<p><code>add_system()</code> adds to App's <code>Schedule</code>.</p>
<h4 id="startup-systems"><a class="header" href="#startup-systems">Startup Systems</a></h4>
<p>Like <strong>systems</strong>, but run only once.</p>
<p><code>add_startup_system()</code></p>
<h2 id="-1"><a class="header" href="#-1"></a></h2>
<ul>
<li><code>World</code></li>
<li><code>Schedule</code></li>
<li><code>Commands</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gnupg"><a class="header" href="#gnupg">GnuPG</a></h1>
<p>GPG (PGP) follows a design of a smart card. This includes 3 sets of keys.</p>
<p>List public key ids</p>
<pre><code>gpg -k
</code></pre>
<p>Export full key</p>
<pre><code>gpg --armor --export &lt;KEY ID&gt;
</code></pre>
<p>Shows GPG keys</p>
<pre><code>gpg --card-status
</code></pre>
<h2 id="encrypt"><a class="header" href="#encrypt">Encrypt</a></h2>
<pre><code>gpg --symmetric -o encrypted.gpg unencrypted.txt
</code></pre>
<h2 id="decrypt"><a class="header" href="#decrypt">Decrypt</a></h2>
<pre><code>gpg --decrypt encrypted.gpg
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ssh"><a class="header" href="#ssh">SSH</a></h1>
<div class="table-wrapper"><table><thead><tr><th>Packet</th></tr></thead><tbody>
<tr><td>packet length</td></tr>
<tr><td>padding amount</td></tr>
<tr><td>payload</td></tr>
<tr><td>padding</td></tr>
<tr><td>message authentication code</td></tr>
</tbody></table>
</div>
<p><em>Note</em>: Compression can be applied to the 'padding amount', 'payload' and 'padding' as well.</p>
<h2 id="client"><a class="header" href="#client">Client</a></h2>
<pre><code>ssh-keygen -t rsa
</code></pre>
<p>creates
<em>~/.ssh/id_rsa</em> and <em>~/.ssh/id_rsa.pub</em>
which are cryptographically linked together.</p>
<p><em>Note</em>: A convenient way to copy you id to server</p>
<pre><code>ssh-copy-id user@ip
</code></pre>
<p>The keys needs to be added to the key-agent with <code>ssh-add</code>.</p>
<h2 id="server"><a class="header" href="#server">Server</a></h2>
<p>Set <em>.ssh/</em> folder permissions to 700.
Set <em>~/.ssh/authorized_keys</em> permissions to 600.</p>
<p>Add the client's public key (<em>id_rsa.pub</em>) into <em>authorized_keys</em></p>
<h3 id="turn-of-password-login"><a class="header" href="#turn-of-password-login">Turn of password login</a></h3>
<p>Open <em>/etc/ssh/sshd_config</em></p>
<p>Set</p>
<ul>
<li><code>PasswordAuthentication no</code></li>
<li><code>ChallengeResponseAuthentication no</code></li>
<li><code>UsePAM no</code></li>
</ul>
<p>Restart ssh daemon</p>
<pre><code>systemctl restart sshd
</code></pre>
<h2 id="ssh-host-aliases"><a class="header" href="#ssh-host-aliases">SSH Host Aliases</a></h2>
<p>Use ssh keys and define host aliases in ssh config file (each alias for an account).</p>
<h3 id="steps-1"><a class="header" href="#steps-1">Steps</a></h3>
<ol>
<li><a href="https://help.github.com/articles/generating-a-new-ssh-key/">Generate ssh key pairs for accounts</a>
and <a href="https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/">add them to GitHub accounts</a>.</li>
<li>Edit/Create ssh config file (<code>~/.ssh/config</code>):</li>
</ol>
<pre><code class="language-conf"># Default github account: firstAccountNames
Host github.com
  HostName github.com
  IdentityFile ~/.ssh/oanhnn_private_key
  IdentitiesOnly yes

# Other github account: secondAccountName
Host github-secondAccountName
  HostName github.com
  IdentityFile ~/.ssh/superman_private_key
  IdentitiesOnly yes
</code></pre>
<ol start="3">
<li><a href="https://help.github.com/articles/adding-a-new-ssh-key-to-the-ssh-agent/">Add ssh private keys to your agent</a>:</li>
</ol>
<pre><code class="language-shell">$ ssh-add ~/.ssh/oanhnn_private_key
$ ssh-add ~/.ssh/superman_private_key
</code></pre>
<ol start="4">
<li>Test your connection</li>
</ol>
<pre><code class="language-shell">$ ssh -T git@github.com
$ ssh -T git@github-secondAccountName
</code></pre>
<p>With each command, you may see this kind of warning, type <code>yes</code>:</p>
<pre><code class="language-shell">The authenticity of host 'github.com (192.30.252.1)' can't be established.
RSA key fingerprint is xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:
Are you sure you want to continue connecting (yes/no)?
</code></pre>
<p>If everything is OK, you will see these messages:</p>
<pre><code class="language-shell">Hi firstAccountNames! You've successfully authenticated, but GitHub does not
provide shell access.
</code></pre>
<pre><code class="language-shell">Hi secondAccountName! You've successfully authenticated, but GitHub does not
provide shell access.
</code></pre>
<ol start="5">
<li>Now all are set, just clone your repositories</li>
</ol>
<pre><code class="language-shell">$ git clone git@github-secondAccountName:org2/project2.git /path/to/project2
$ cd /path/to/project2
$ git config user.email "secondAccountName@org2.com"
$ git config user.name  "Super Man"
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="yubikey"><a class="header" href="#yubikey">YubiKey</a></h1>
<p><a href="https://github.com/Yubico/yubikey-manager/">yubikey-manager</a></p>
<pre><code class="language-sh">sudo apt install yubikey-manager
</code></pre>
<ul>
<li><code>ykman info</code></li>
<li><code>ykman fido info</code></li>
<li><code>ykman fido access change-pin</code></li>
<li><code>ykman fido credentials list</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="git"><a class="header" href="#git">Git</a></h1>
<p><code>git init</code> creates 2 things:</p>
<ul>
<li><strong>repository</strong></li>
<li><strong>workspace</strong></li>
</ul>
<p><code>git init --bare</code> create only the <strong>repository</strong>.</p>
<h2 id="key"><a class="header" href="#key">Key</a></h2>
<p>Verify connection</p>
<pre><code>ssh -T git@github.com
</code></pre>
<p>Verity private key is generated and loaded into SSH</p>
<pre><code>ssh-add -l -E sha256
</code></pre>
<p>Start SSH agent</p>
<pre><code>eval "$(ssh-agent -s)"
</code></pre>
<p>Add key</p>
<pre><code>ssh-add &lt;id_ed25519 file&gt;
</code></pre>
<h2 id="worktrees"><a class="header" href="#worktrees">Worktrees</a></h2>
<pre><code>git clone &lt;REPOSITORY&gt; --bare
</code></pre>
<p>Add workspace with</p>
<pre><code>git worktree add &lt;BRANCH_NAME&gt;
</code></pre>
<p>Will create a new workspace folder in the git bare repository.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="neovim"><a class="header" href="#neovim">Neovim</a></h1>
<h2 id="lsp"><a class="header" href="#lsp">LSP</a></h2>
<p>Neovim supports LSP (Language Server Protocol); ie it acts as a client to LSP
servers. Nvim includes a Lua framework <code>vim.lsp</code> for building enhanced LSP tools.</p>
<p>Starting a LSP client will automatically report diagnostics via
<code>vim.diagnostic</code>.</p>
<p>To learn what capabilities are available you can run the following command in
a buffer with a started LSP client:</p>
<pre><code>:lua =vim.lsp.get_active_clients()[1].server_capabilities
</code></pre>
<p><strong>Note</strong>: LSP facilitates features like go-to-definition, find-references, hover,
completion, rename, format, refactor, etc., using semantic whole-project
analysis.</p>
<pre><code class="language-lua">"williamboman/mason.nvim",           -- language server installer
"williamboman/mason-lspconfig.nvim",
"neovim/nvim-lspconfig",             -- configs for Nvim LSP client
</code></pre>
<h3 id="nvim-lspconfig"><a class="header" href="#nvim-lspconfig">nvim-lspconfig</a></h3>
<p><a href="https://github.com/neovim/nvim-lspconfig/blob/master/doc/server_configurations.md">Configs</a>
for the <a href="https://neovim.io/doc/user/lsp.html">Nvim LSP client</a>.</p>
<h3 id="masonnvim"><a class="header" href="#masonnvim">mason.nvim</a></h3>
<p>Manage external toolings for LSP servers, DAP servers, linters, and formatters
through a single interface.</p>
<p>Deprecates <code>nvim-lsp-installer</code>.</p>
<p><code>mason.nvim</code> installs packages to nvim's <code>:h stdpath</code>.</p>
<h3 id="mason-lspconfignvim"><a class="header" href="#mason-lspconfignvim">mason-lspconfig.nvim</a></h3>
<p><code>mason-lspconfig</code>, an extension of <code>mason.nvim</code>, bridges Mason with the <code>nvim-lspconfig</code> plugin.</p>
<ul>
<li><a href="https://github.com/williamboman/mason-lspconfig.nvim#available-lsp-servers">Available servers</a></li>
</ul>
<p><strong>Note</strong> mason-lspconfig uses <code>lspconfig</code> server names, <strong>not</strong> <code>mason.nvim</code>
package names.
<a href="https://github.com/williamboman/mason-lspconfig.nvim/blob/main/doc/server-mapping.md">List of mappings</a>
between lspconfig names and mason registry names.</p>
<h3 id="null-ls"><a class="header" href="#null-ls">null-ls</a></h3>
<pre><code class="language-lua">use "jose-elias-alvarez/null-ls.nvim"
</code></pre>
<p><a href="https://github.com/jose-elias-alvarez/null-ls.nvim/blob/main/doc/BUILTINS.md">Build-in Sources</a></p>
<p>To run built-in sources, the command specified below must be available on your
<code>$PATH</code> and visible to Neovim. Eg, to check if <code>stylua</code> is available, run the
following (Vim, not Lua) command:</p>
<pre><code class="language-vim">" should echo 1 if available (and 0 if not)
:echo executable("stylua")
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="compdocs"><a class="header" href="#compdocs">Compdocs</a></h1>
<h3 id="power"><a class="header" href="#power">Power</a></h3>
<pre><code>upower --enumerate
upower -i &lt;entry&gt;
</code></pre>
<pre><code class="language-bash">for dev in $(upower --enumerate);
do upower -i $dev;
done
</code></pre>
<h3 id="screen-control"><a class="header" href="#screen-control">Screen control</a></h3>
<pre><code>arandr
xrandr
</code></pre>
<h3 id="sound-control"><a class="header" href="#sound-control">Sound control</a></h3>
<pre><code>pavucontrol
pulseaudio
</code></pre>
<h3 id="wifi-control-from-terminal"><a class="header" href="#wifi-control-from-terminal">WiFi control from terminal</a></h3>
<pre><code>nmtui
</code></pre>
<h3 id="prevent-screen-from-sleeping"><a class="header" href="#prevent-screen-from-sleeping">Prevent screen from sleeping</a></h3>
<pre><code>xset dpms 0 0 0
</code></pre>
<h3 id="set-java-javac-version"><a class="header" href="#set-java-javac-version">Set java (javac) version</a></h3>
<pre><code>sudo update-alternatives --display java
sudo update-alternatives --config java
</code></pre>
<h3 id="change-ttl"><a class="header" href="#change-ttl">Change TTL</a></h3>
<pre><code>sudo sysctl -w net.ipv4.ip_default_ttl=128
</code></pre>
<p>to change temporarily.
Edit</p>
<pre><code>/etc/sysctl.conf
</code></pre>
<p>to permanently change.</p>
<h3 id="update-firmware"><a class="header" href="#update-firmware">Update firmware</a></h3>
<pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y
fwupdmgr get-updates
sudo fwupdmgr refresh
sudo fwupdmgr update
</code></pre>
<h3 id="network-debugging"><a class="header" href="#network-debugging">Network debugging</a></h3>
<pre><code>sudo lshw -c network
</code></pre>
<pre><code>dmesg | grep ath10k
</code></pre>
<pre><code>lspci -nnk | grep 0280 -A3
</code></pre>
<h3 id="apt"><a class="header" href="#apt">APT</a></h3>
<ul>
<li>PPTs</li>
</ul>
<pre><code>grep -vhe ^# /etc/apt/sources.list /etc/apt/sources.list.d/*
</code></pre>
<h3 id="link"><a class="header" href="#link">Link</a></h3>
<pre><code>ln -s [Source_File_Name] [Symbolic_Link_Name]
&gt;&gt;&gt;&gt;&gt;&gt;&gt; d39d8f7 (notes)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="c"><a class="header" href="#c">C++</a></h1>
<p>Notes from <em>learncpp.com</em>.</p>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p><em>Best practice</em>: Name code files <em>something.cpp</em>.</p>
<p>Compiler</p>
<ul>
<li>checks <em>.cpp</em> files that they are syntactically correct</li>
<li>creates machine language object files</li>
</ul>
<p>Linker</p>
<ul>
<li>combines all object files into a single executable program</li>
<li>links library files</li>
<li>makes sure all cross file dependencies are resolved properly</li>
</ul>
<p><em>Best practice</em>: Use compiler flags
<code>-Werror -Wall -Weffc++ -Wextra -Wsign-conversion</code>.</p>
<h2 id="basics-1"><a class="header" href="#basics-1">Basics</a></h2>
<p>Every program must have a <code>main</code> function.</p>
<p>After a variable has been defined, it can be assigned a value with
<em>copy assignment</em>:</p>
<pre><code class="language-c++">int x;
x = 3;
</code></pre>
<h3 id="initialization"><a class="header" href="#initialization">Initialization</a></h3>
<p>Initialize variables upon creation.</p>
<p><em>Copy initialization</em>:</p>
<pre><code class="language-c++">int x = 3;
</code></pre>
<p>Efficient for simple types, but sometimes inefficient for complex types.</p>
<p><em>Direct initialization</em>:</p>
<pre><code class="language-c++">int x( 3 );
</code></pre>
<p>Efficient for simple types and tends to be more efficient for complex types.</p>
<p><em>List initialization</em>:</p>
<pre><code class="language-c++">int x{ 3 };     // direct list initialization
int y = { 5 };  // copy list initialization
int z {};       // value initialization
</code></pre>
<p>Same as direct, but disallows narrowing conversions and allows initialization
with more types, such as lists.</p>
<p><em>Best practice</em>: use list initialization.</p>
<h3 id="iostream"><a class="header" href="#iostream">iostream</a></h3>
<p><em>Best practice</em>: use <code>\n</code> instead of <code>std::endl</code> since the latter flushes
output.</p>
<p>--- OLD CONTENT ---</p>
<h2 id="pass-by"><a class="header" href="#pass-by">Pass by</a></h2>
<h3 id="pass-by-value"><a class="header" href="#pass-by-value">Pass by Value</a></h3>
<pre><code class="language-c++">void pbv(int x);
</code></pre>
<p>Pass by value copies parameter. Can be <code>const</code>.</p>
<ul>
<li>prevents side effects</li>
<li>can be heavvy on performance</li>
<li>preffered with fundamental types</li>
</ul>
<h3 id="pass-by-reference"><a class="header" href="#pass-by-reference">Pass by Reference</a></h3>
<pre><code class="language-c++">void pbr(int&amp; x);
</code></pre>
<p>Allows the function to modify the parameter.</p>
<p>Avoid <em>out parameters</em>.</p>
<h3 id="pass-by-const-reference"><a class="header" href="#pass-by-const-reference">Pass by const Reference</a></h3>
<pre><code class="language-c++">void pbcr(const int&amp; x);
</code></pre>
<p>Cannot change parameter (as when passed by value), but the value is not copied,
which saves performance.</p>
<h3 id="pass-by-address"><a class="header" href="#pass-by-address">Pass by Address</a></h3>
<pre><code class="language-c++">void pba(int* x);
</code></pre>
<pre><code class="language-c++">void pbca(const int* x);
</code></pre>
<h2 id="pointers-and-references"><a class="header" href="#pointers-and-references">Pointers and References</a></h2>
<p>References are pointers under the hood.</p>
<h3 id="operators-3"><a class="header" href="#operators-3">Operators</a></h3>
<p><code>&amp;</code>: adress-of operator
<code>*</code>: indirection operator / dereference operator</p>
<p><em>Note</em>: Adress-of operator returns a pointer.</p>
<p><em>Note</em>: Adress-of and indirection operator should not be confused with reference
and pointer variable declarations.</p>
<h3 id="pointer-variables"><a class="header" href="#pointer-variables">Pointer variables</a></h3>
<p>Variable that holds a memory address as value.</p>
<p><code>const int*</code>: pointer to a <code>const int</code></p>
<p><code>int* const</code>: pointer that itself is <code>const</code></p>
<h3 id="reference-variables"><a class="header" href="#reference-variables">Reference variables</a></h3>
<p>Reference variable is an alias for an already exisiting variable.</p>
<p><em>Note</em>: Cannot be null.</p>
<p><em>Note</em>: Cannot be changed to refer to another object.</p>
<p><em>Note</em>: Must be initialized at creation.</p>
<h4 id="reference-to-non-const-value"><a class="header" href="#reference-to-non-const-value">Reference to Non-<code>const</code> Value</a></h4>
<p>Can only be initialized with</p>
<ul>
<li>non-const l-values.</li>
</ul>
<h4 id="reference-to-const-value"><a class="header" href="#reference-to-const-value">Reference to <code>const</code> Value</a></h4>
<p>Can be initialized with</p>
<ul>
<li>non-<code>const</code> l-values</li>
<li><code>const</code> l-values</li>
<li>r-values</li>
</ul>
<h4 id="r-value-reference"><a class="header" href="#r-value-reference">r-value Reference</a></h4>
<p>Extends the life-time of the r-value.</p>
<h3 id="pointers-and-references-as-parameters"><a class="header" href="#pointers-and-references-as-parameters">Pointers and References as Parameters</a></h3>
<p>Parameters are initialized with the variables passed to the function, so
possible variables are limited to what the type can hold.</p>
<p>Passing by reference or by address avoids copying as is done when passing by
value.</p>
<p><em>Note</em>: Passing by non-const reference has the downside that it is unclear if
the variables will be changed or not.</p>
<p><em>Note</em>: Cannot be assigned to literals or temporaries.</p>
<h4 id="move-semantics"><a class="header" href="#move-semantics">Move Semantics</a></h4>
<p>r-values?</p>
<h3 id="pointers-and-references-as-return-values"><a class="header" href="#pointers-and-references-as-return-values">Pointers and References as Return Values</a></h3>
<p>return by adress</p>
<pre><code class="language-c++">return &amp;variable;
</code></pre>
<p><em>Note</em>: Be careful not to create dangling pointers.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="docker"><a class="header" href="#docker">Docker</a></h1>
<p>Contains:</p>
<ul>
<li>Server</li>
<li>Docker client CLI</li>
<li>REST API for client server communication</li>
</ul>
<h2 id="container"><a class="header" href="#container">Container</a></h2>
<p><em>Containers</em> are run from an <em>image</em>.</p>
<p>Container types are</p>
<ul>
<li>short-running tasks that exits when they are done</li>
<li>long-running jobs that are detached</li>
<li>interactive that stays alive while Docker client is connected</li>
</ul>
<h2 id="image"><a class="header" href="#image">Image</a></h2>
<p><code>docker build</code> builds Docker images from a Dockerfile and a build context.</p>
<p><em>Build context</em>: the set of files that your build can access.</p>
<p>To build an image you need to provide <em>repository name</em> and <em>path</em>, and optionally <em>tag</em> which defaults to "latest".</p>
<p>Convention for <em>repository name</em> is <code>&lt;user&gt;/&lt;application&gt;</code>. If no <code>&lt;user&gt;/</code> it means that it is an official image. <em>Tag</em> is usually used for version.</p>
<p><code>&lt;user&gt;/&lt;application&gt;:&lt;tag&gt;</code></p>
<p>Docker client sends the content of the path to the server where it is stored in a working directory called the <em>build context</em>.</p>
<h2 id="dockerfile"><a class="header" href="#dockerfile">Dockerfile</a></h2>
<ul>
<li><code>FROM</code> Only required. Determines which base image to use</li>
<li><code>RUN</code> Execute command</li>
<li><code>ENV</code> Set environment variable</li>
<li><code>COPY</code> Copy from build context into image (<code>ADD</code> is an extended version of <code>COPY</code>)</li>
<li><code>EXPOSE</code> Expose ports</li>
<li><code>VOLUME</code> Create directory in image that can be mapped to external storage</li>
<li><code>CMD</code> Entrypoint when image is <em>run</em></li>
</ul>
<p><strong>Note</strong>: All but <code>CMD</code> instructions are build during <code>image build</code>.</p>
<p><strong>Note</strong>: Each instruction runs a temporary container and saves a new image for caching.</p>
<h3 id="layers"><a class="header" href="#layers">Layers</a></h3>
<p><code>docker image history &lt;id&gt;</code> will give steps, <code>&lt;missing&gt;</code> means it's a step from the base image.</p>
<h2 id="volume"><a class="header" href="#volume">Volume</a></h2>
<p>Docker images can only be changed by explicitly building a new one. To be able to persist data that should be available for another container run from that image, you must use <em>volumes</em>.</p>
<p><em>volume</em>: map a folder on host machine (or other storage) accessible from within the Docker image.</p>
<p>Volumes are owned by one container but can be shared with others.</p>
<h2 id="docker-registry"><a class="header" href="#docker-registry">Docker Registry</a></h2>
<p>Docker Hub is the default registry.</p>
<p>To run a local private registry</p>
<pre><code class="language-bash">docker container run -d -p5000:5000 registry:latest
</code></pre>
<p>To push an image to it you need to tag it with the address, and the push it</p>
<pre><code class="language-bash">docker image tag &lt;user&gt;/&lt;app&gt; localhost:5000/&lt;user&gt;/&lt;app&gt;
docker image push localhost:5000/&lt;user&gt;/&lt;app&gt;
</code></pre>
<p>list the contents with</p>
<pre><code class="language-bash">curl http://localhost:5000/v2/_catalog
</code></pre>
<h2 id="docker-compose"><a class="header" href="#docker-compose">Docker Compose</a></h2>
<p>Used for running multiple containers as a single service.</p>
<h2 id="docker-swarm"><a class="header" href="#docker-swarm">Docker Swarm</a></h2>
<p>Service for controlling multiple docker environments within a single platform.</p>
<p>Each node is Docker daemon, and all Docker daemons interact using the Docker API.</p>
<p>2 types of nodes:</p>
<ul>
<li>Manager node</li>
<li>Worker node</li>
</ul>
<h2 id="commands"><a class="header" href="#commands">Commands</a></h2>
<p><code>systemctl start Docker</code></p>
<p><code>docker rmi image_id</code></p>
<p><code>docker image history &lt;image&gt;</code></p>
<p><code>docker pull image_name</code></p>
<p><code>docker run &lt;image_id&gt;</code></p>
<p><code>docker build -t [image_name]:tag</code></p>
<p><code>-it</code> is short for <code>--interactive</code> and <code>--tty</code>.</p>
<p><code>-e</code> environment variable</p>
<p><code>-d</code> detach</p>
<p><code>--rm</code> automatically removes container when it stops.</p>
<p>Run bash inside docker image</p>
<pre><code class="language-bash">docker exec -it &lt;image name&gt; bash
</code></pre>
<h2 id="podman"><a class="header" href="#podman">Podman</a></h2>
<pre><code>podman run --rm -p 5432:5432 -e "POSTGRES_PASSWORD=postgres" --name pg docker.io/postgres:14
</code></pre>
<h2 id="logs-1"><a class="header" href="#logs-1">Logs</a></h2>
<pre><code class="language-bash">podman logs --follow &lt;CONTAINER ID&gt;
</code></pre>
<h2 id="remove"><a class="header" href="#remove">Remove</a></h2>
<p>Clean up all dangling resources:</p>
<pre><code class="language-bash">docker system prune
</code></pre>
<p>Also remove any stopped containers and all unused images</p>
<pre><code class="language-bash">docker system prune -a
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="flatbuffers"><a class="header" href="#flatbuffers">FlatBuffers</a></h1>
<p>It represents hierarchical data in a flat binary buffer in such a way that it
can still be accessed directly without parsing/unpacking, while also still
supporting data structure evolution (forwards/backwards compatibility).</p>
<ul>
<li><code>namespace</code> - determines the corresponding package/namespace for the generated
code</li>
<li><code>enum</code></li>
<li><code>union</code> - union of tables</li>
<li><code>struct</code> - structs are ideal for data structures that will not change, since
they use less memory and have faster lookup</li>
<li><code>table</code></li>
<li><code>root_type</code> - The root type declares what will be the root table for the
serialized data.</li>
</ul>
<p>Since you cannot delete fields from a table (to support backwards compatability)
, you can set fields as deprecated, which will prevent the generation of
accessors for this field in the generated code. Be careful when using deprecated
, however, as it may break legacy code that used this accessor.</p>
<h2 id="-2"><a class="header" href="#-2"></a></h2>
<ol>
<li>Write fbs schema</li>
<li>Compile schema, eg</li>
</ol>
<pre><code class="language-sh">flatc --ts my_schema.fbs
</code></pre>
<ol start="3">
<li>Import compiled files and <code>FlatBufferBuilder</code></li>
</ol>
<pre><code>let builder = new flatbuffers.Builder(1024);
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="protocol-buffers"><a class="header" href="#protocol-buffers">Protocol Buffers</a></h1>
<p>Protocol Buffers us defined by a <em>.proto</em> text file, eg</p>
<pre><code class="language-proto3">syntax = "proto3";

message MyMessage {
  int32 id = 1;
  string first_name = 2;
  bool is_validated = 3;
}
</code></pre>
<ul>
<li>Fully typed data</li>
<li>Data is compressed automatically</li>
<li>Schema (<em>.proto</em> file) is needed to generate code and read data</li>
<li>Documentation can be embedded in the schema</li>
<li>Data can be read across many language</li>
<li>Schema can evolve over time in a safe manner</li>
<li>Fast and small</li>
<li>Code generated automatically</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="geojson"><a class="header" href="#geojson">GeoJson</a></h1>
<p>GeoJSON is a format for encoding a variety of geographic data structures.</p>
<pre><code>{
  "type": "Feature",
  "geometry": {
    "type": "Point",
    "coordinates": [125.6, 10.1]
  },
  "properties": {
    "name": "Dinagat Islands"
  },
  bbox?: [number, ...] // optional
}
</code></pre>
<p>Geometry types supported:</p>
<ul>
<li><code>Point</code></li>
<li><code>LineString</code></li>
<li><code>Polygon</code></li>
<li><code>MultiPoint</code></li>
<li><code>MultiLineString</code></li>
<li><code>MultiPolygon</code></li>
</ul>
<p>Geometric objects with additional properties are <code>Feature</code> objects. Sets of
features are contained by <code>FeatureCollection</code> objects.</p>
<pre><code>{
  "type":"FeatureCollection",
  "features":[
    {
      "type":"Feature",
      "geometry":{
        "type":"Point",
        "coordinates":[ 102.0, 0.5 ]
      },
      "properties":{
        "prop0":"value0"
      }
    },
    {
      "type":"Feature",
      "geometry":{
        "type":"LineString",
        "coordinates":[
          [ 102.0, 0.0 ],
          [ 103.0, 1.0 ],
          [ 104.0, 0.0 ],
          [ 105.0, 1.0 ]
        ]
      },
      "properties":{
        "prop0":"value0",
        "prop1":0.0
      }
    },
    {
      "type":"Feature",
      "geometry":{
        "type":"Polygon",
        "coordinates":[
          [
            [ 100.0, 0.0 ],
            [ 101.0, 0.0 ],
            [ 101.0, 1.0 ],
            [ 100.0, 1.0 ],
            [ 100.0, 0.0 ]
          ]
        ]
      },
      "properties":{
        "prop0":"value0",
        "prop1":{
          "this":"that"
        }
      }
    }
  ]
}
</code></pre>
<h2 id="linestring"><a class="header" href="#linestring">LineString</a></h2>
<pre><code>{
  "type": "LineString",
  "coordinates": [
    [longitude1, latitude1],
    [longitude2, latitude2],
    [longitude3, latitude3],
    ...
  ],
  "bbox": [west, south, east, north],
  "properties": {...},
  "id": "..."
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="java-stuff"><a class="header" href="#java-stuff">Java stuff</a></h1>
<h2 id="java-version"><a class="header" href="#java-version">Java version</a></h2>
<p>Install</p>
<pre><code class="language-bash">sudo apt install openjdk-16-jdk
</code></pre>
<p>Set version</p>
<pre><code class="language-bash">sudo update-alternatives --config java
</code></pre>
<p>and environment variable <code>JAVA_HOME</code></p>
<pre><code class="language-bash">export JAVA_HOME="/usr/lib/jvm/java-1.16.0-openjdk-amd64"
</code></pre>
<p>Check version with</p>
<pre><code class="language-bash">java -version
</code></pre>
<pre><code class="language-bash">mvn --version
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="jwt"><a class="header" href="#jwt">JWT</a></h1>
<p>Contains</p>
<ul>
<li>header (base64 encoded string of json object)</li>
<li>payload (base64 encoded string of json object)</li>
<li>key (signed and digested)</li>
</ul>
<pre><code>let header = { typ: 'JWT', alg: 'HS256'}
header = new Buffer(JSON.stringify(header)).toString('base64')
</code></pre>
<pre><code>let payload = { iat: Date}
payload = new Buffer(JSON.stringify(payload)).toString('base64')
</code></pre>
<p>Different kinds of claims:</p>
<ul>
<li>public</li>
<li>private</li>
<li>reserved</li>
</ul>
<pre><code>let key = header + '.' + payload
let signature = crypto.createHmac('sha356', 'secret_key')
signature.update(key)
key = signature.digest('base64')
</code></pre>
<p>The token is the header, payload and the signed digested key</p>
<pre><code>let token = header + '.' + payload + '.' key
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes"><a class="header" href="#kubernetes">Kubernetes</a></h1>
<p>Open source orchestration system for Docker containers.</p>
<p>Handles scheduling onto nodes in a compute cluster.
Actively manages work loads so that state matches the user's declared intentions.</p>
<p>Using the concept of labels and pods it groups the containers which makes up an
application into logical units for easy management and discovery.</p>
<p>Pod: a runnable unit of work. Usually 1 container.</p>
<p>Service: tells what services your application provides.</p>
<p>Volume: represents a location where containers can access and store information.</p>
<p>Namespace: grouping mechanism and isolation from other parts of the cluster.</p>
<h2 id="resources"><a class="header" href="#resources">Resources</a></h2>
<p>A kubernetes cluster contains 2 types of resources:</p>
<ul>
<li><strong>Control Plane</strong> - coordinates the cluster</li>
<li><strong>Nodes</strong>         - Workers that run applications</li>
</ul>
<h3 id="control-plane"><a class="header" href="#control-plane">Control Plane</a></h3>
<p>Responsible for managing the cluster.</p>
<h3 id="node"><a class="header" href="#node">Node</a></h3>
<p>A VM or physical computer that serves as a worker machine in the cluster.</p>
<p>Has a <strong>Kubelet</strong>: an agent that manages the node and communicates with the
control plane.</p>
<h2 id="deploy"><a class="header" href="#deploy">Deploy</a></h2>
<p>Tell control plane to start the application containers. Control plane schedules
the containers to run on the cluster's nodes. Nodes communicate with the control
plane through Kubernetes API.</p>
<p><strong>Deployment configuration</strong>: instructions on how to create and update instances
of application.</p>
<p><strong>Kubernetes Deployment Controller</strong> monitors and replaces down or deleted with
instances on another node.</p>
<pre><code>kubectl create deployment &lt;deployment name&gt; &lt;app image location&gt;
</code></pre>
<h2 id="pod"><a class="header" href="#pod">Pod</a></h2>
<p>A Kubernetes abstraction that represents</p>
<ul>
<li>a group of one or more application containers</li>
<li>shared resources
<ul>
<li>shared storage</li>
<li>networking</li>
<li>container information</li>
</ul>
</li>
</ul>
<p>Containers in a Pod share an IP Address and port space, are always co-located
and co-scheduled, and run in a shared context on the same Node. Pods run in an
isolated, private network.</p>
<p>A pod always runs on a Node.</p>
<h2 id="node-1"><a class="header" href="#node-1">Node</a></h2>
<p>A node can contain many pods.</p>
<p>A Node always contains:</p>
<ul>
<li>Kubelet: process responsible for communication with Control Plane.</li>
<li>A container runtime (eg Docker).</li>
</ul>
<h2 id="service-1"><a class="header" href="#service-1">Service</a></h2>
<p>Abstraction which defines a logical set of Pods and a policy by which to access
them.
Services allow your applications to receive traffic. Services can be exposed in
different ways by specifying a <code>type</code> in the ServiceSpec.</p>
<p>Services match a set of Pods using <strong>lables</strong> and <strong>selectors</strong>.</p>
<h2 id="kubectl-cli"><a class="header" href="#kubectl-cli"><code>kubectl</code> CLI</a></h2>
<p><code>kubectl &lt;ACTION&gt; &lt;RESOURCE&gt;</code></p>
<ul>
<li><code>kubectl get</code> - list resources</li>
<li><code>kubectl describe</code> - show detailed information about a resource</li>
<li><code>kubectl logs</code> - print the logs from a container in a pod</li>
<li><code>kubectl exec</code> - execute a command on a container in a pod</li>
<li><code>kubectl cluster-info</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="programming-patterns"><a class="header" href="#programming-patterns">Programming Patterns</a></h1>
<h2 id="dao-pattern"><a class="header" href="#dao-pattern">DAO Pattern</a></h2>
<p>Used to separate low level data accessing from high level business services.</p>
<ul>
<li><strong>DAO Interface</strong>       - <em>defines operations on model</em></li>
<li><strong>DAO Concrete Class</strong>  - <em>implements interface, responsible for getting data</em></li>
<li><strong>Model Object</strong>        - <em>POJO</em></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="puppet"><a class="header" href="#puppet">Puppet</a></h1>
<p>IaC
multiple servers
rollback or new state
configuration management tool
can also be used as a deployment tool for software</p>
<p>Main server - Client</p>
<p>Server:
Manifests
Templates
Files</p>
<p>Client:
Agent
Facter</p>
<p>Master - slave architecture</p>
<p>Client sends certificate with client id to server. Server signs it and sends back to server.
Facter sends state of the client to master. Based on facts, server compiles manifests into catalogs , catalogs are sent to clients.
The agent executes manifests on its machine. A report of changes is sent back to master.</p>
<h2 id="manifests-and-modules"><a class="header" href="#manifests-and-modules">Manifests and Modules</a></h2>
<p>Puppet code is composed primarily of <strong>resource declarations</strong>. A resource describes something about the state of the system</p>
<pre><code class="language-pp">resource_type { 'resource_name'
  attribute =&gt; value
  ...
}
</code></pre>
<p>To list all default resource types available to Puppet</p>
<pre><code>puppet resource --types
</code></pre>
<p>Puppet programs are called <strong>manifests</strong>. The default main manifest in Puppet installed via apt is <code>/etc/puppet/manifests/site.pp</code>.</p>
<p>In Puppet, <strong>classes</strong> are code blocks that can be called in a code elsewhere.</p>
<p>A <strong>class definition</strong></p>
<pre><code class="language-pp">class example_class {
  ...
  code
  ...
}
</code></pre>
<p>A <strong>class declaration</strong> occurs when a class is called in a manifest. A class declaration tells Puppet to evaluate the code within the class. Class declarations come in two different flavors: <em>normal</em> and <em>resource-like</em>.</p>
<p>A <strong>normal class declaration</strong> occurs when the include keyword is used in Puppet code</p>
<pre><code class="language-pp">include example_class
</code></pre>
<p>Using <strong>resource-like class declarations</strong> allows you to specify class parameters, which override the default values of class attributes.</p>
<p>A <strong>module</strong> is a collection of manifests and data (such as facts, files, and templates), and they have a specific directory structure. To add a module to Puppet, place it in the <code>/etc/puppet/modules</code> directory..</p>
<h2 id="templates"><a class="header" href="#templates">Templates</a></h2>
<ul>
<li>Templates go into <em>templates/</em> directory of a module.</li>
<li>A templare file is referenced by <code>&lt;module&gt;/&lt;template file&gt;</code> (note <em>templates/</em> omitted)</li>
<li>Template file can be either <em>.erb</em> (embedded ruby) or <em>.epp</em> (embedded puppet) format</li>
</ul>
<pre><code class="language-pp">file { '/etc/something.conf':
    content =&gt; template('something/something.conf.erb'),
}
</code></pre>
<p>for <em>.epp</em> files, use <code>epp</code> instead of <code>template</code>.</p>
<p>Validate .erb</p>
<pre><code>erb -P -x -T '-' example.erb | ruby -c
</code></pre>
<ul>
<li><code>-P</code> ignore lines starting with <code>%</code></li>
<li><code>-x</code> outputs template's Ruby script</li>
<li><code>-T '-'</code> sets trim mode to be consistent with puppet's behavior.</li>
</ul>
<h3 id="erb"><a class="header" href="#erb">ERB</a></h3>
<p>An ERB template has its own local scope, and its parent scope is set to the class or defined type that evaluates the template.</p>
<p>All variables in the current scope (including global variables) are passed to templates as Ruby instance variables, which begin with “at” signs (<code>@</code>).</p>
<ul>
<li><code>&lt;% expression %&gt;</code> non-printing tag</li>
<li><code>&lt;%= expression %&gt;</code> expression-printing tags</li>
<li><code>&lt;%# expression %&gt;</code> comment tag</li>
</ul>
<p><strong>Note</strong>: A hyphen in a tag (<code>-</code>) strips leading or trailing whitespace when printing the evaluated template.</p>
<p><strong>Note</strong>: Text outside a tag is treated as literal text, but is subject to any tagged Ruby code surrounding it.</p>
<h2 id="test-locally"><a class="header" href="#test-locally">Test locally</a></h2>
<pre><code>.
├── manifests
│   └── site.pp
└── modules
    └── mymod
        ├── manifests
        │   └── init.pp
        └── templates
            └── some_template.erb
</code></pre>
<pre><code class="language-puppet"># manifests/site.pp
node default {
  include mymod
}
</code></pre>
<pre><code class="language-sh">puppet apply --modulepath=./modules manifests/site.pp
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="raid"><a class="header" href="#raid">RAID</a></h1>
<p><strong>RAID</strong>: <em>Reduntant Array of Inexpensive Disks</em> or <em>Reduntant Array of Independent Disks</em>.</p>
<p>Storage virtualization technology. Combines multiple physical disk drive components into one or more logical units.</p>
<p>Provides data redundancy and/or performance improvement.</p>
<p>Data is distributed across drives in one of several ways: RAID levels.</p>
<ul>
<li><strong>RAID 0</strong>: block-level striping, without mirroring or parity. The failure of any drive causes the entire RAID 0 volume and all files to be lost. Reads and writes are done concurrently.</li>
<li><strong>RAID 1</strong>: data mirroring, without parity or striping. Write throughput is limited by the slowest drive's write performance.</li>
<li><strong>RAID 2</strong>: bit-level striping with dedicated Hamming-code parity. As of 2014 it is not used by any commercially available system.</li>
<li><strong>RAID 3</strong>: byte-level striping with dedicated parity. Not commonly used in practice.</li>
<li><strong>RAID 4</strong>: block-level striping with dedicated parity. The main advantage of RAID 4 over RAID 2 and 3 is I/O parallelism. One I/O read operation does not have to spread across all data drives.</li>
<li><strong>RAID 5</strong>: block-level striping with distributed parity. Parity information is distributed among the drives, requiring all drives but one to be present to operate. Requires at least 3 disks.</li>
<li><strong>RAID 6</strong>: block-level striping with double distributed parity. Double parity provides fault tolerance up to two failed drives. Requires at least 4 disks. The larger the drive capacities and the larger the array size, the more important it becomes to choose RAID 6 instead of RAID 5.</li>
</ul>
<p><strong>Parity</strong>: evenness or oddness of integer. It ensures that the total number of 1-bits in the string is even or odd. If the sum is odd, parity bit is 1. Parity bit can only detect errors, it cannot correct it.</p>
<p><strong>Data strinping</strong>: sgmenting logically sequential data so that consequtive segments are stored on different physical storage devices. It is useful if data is requested more quickly than a single device can provide it. It also balances I/O across disks.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="scrum"><a class="header" href="#scrum">SCRUM</a></h1>
<p><strong>Story</strong>: deliverable that the product owner cares about.</p>
<p><strong>Task</strong>: non-deliverable that the team, but not the product owner does not cares
about.</p>
<p><strong>Note</strong>: A bit floating definitions. In Jira, an <strong>Epic</strong> is overreaching goal
containing <strong>Stories</strong>. <strong>Tasks</strong> are smaller and cannot be time-estimated.</p>
<h2 id="backlog-refinement"><a class="header" href="#backlog-refinement">Backlog Refinement</a></h2>
<p>Make sure product backlog is in shape</p>
<ul>
<li>Refined (has a Definition of Done)</li>
<li>Ordered according to importance</li>
<li>Break down items to reasonable size</li>
</ul>
<h2 id="sprint-planning"><a class="header" href="#sprint-planning">Sprint Planning</a></h2>
<p>Each story has 3 variables:</p>
<ul>
<li>scope      (set by product owner)</li>
<li>importance (set by product owner)</li>
<li>estimate   (set by team)</li>
</ul>
<p>Estimate the stories. This might in turn make the PO alter scope or importance.</p>
<p>The team (no the product owner) decides on how many stories to include in the
sprint. The product owner can affect what gets included by</p>
<ul>
<li>re-prioritizing</li>
<li>change scope of a story</li>
<li>split a story</li>
</ul>
<h3 id="sprint-length"><a class="header" href="#sprint-length">Sprint length</a></h3>
<p>A compromise between being <em>agile</em> (change of direction, shorter feedback cycles,
deploy more often) and <em>working undisturbed</em> (less administrative overhead, focus
and momentum)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="serverless-framework"><a class="header" href="#serverless-framework">Serverless Framework</a></h1>
<p>Helps develop your AWS Lambda along with required AWS infrastructure around it.</p>
<pre><code>serverless create -t &lt;template, eg aws-nodejs&gt;
</code></pre>
<pre><code>serverless deploy --stage &lt;stage&gt;
</code></pre>
<pre><code>serverless info
</code></pre>
<pre><code>serverless invoke -f hello --log
</code></pre>
<pre><code>serverless logs -f hello --tail
</code></pre>
<pre><code>serverless remove
</code></pre>
<h2 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h2>
<ul>
<li>A <strong>Function</strong> is an AWS Lambda function</li>
<li><strong>Resources</strong> are AWS infrastructure components which your Functions use</li>
<li>Anything that triggers an AWS Lambda Function to execute is regarded by the
Framework as an <strong>Event</strong></li>
<li>A <strong>Service</strong> is the Framework's unit of organization</li>
<li>You can overwrite or extend the functionality of the Framework using
<strong>Plugins</strong></li>
</ul>
<h2 id="permissions"><a class="header" href="#permissions">Permissions</a></h2>
<ul>
<li><code>provider.profile</code>: framework user permissions for creation ( lookup in <em>~/.aws/credentials</em>)</li>
<li><code>provider.iam.deploymentRole</code>: deployment role after creation</li>
<li><code>provider.iam.role.statements</code>: lambda permissions</li>
</ul>
<h3 id="deployer-role"><a class="header" href="#deployer-role">Deployer Role</a></h3>
<ul>
<li>Fetch configuration data required to synthesise a new CloudFormation template.
(eg SSM)</li>
<li>Create S3 Bucket for storing deplyment artifact</li>
<li>Validating CloudFormation template</li>
<li>Deploy CloudFormation template</li>
</ul>
<h2 id="plugins"><a class="header" href="#plugins">Plugins</a></h2>
<p>Install the plugin then configure <code>serverless.yml</code> file</p>
<pre><code>plugins:
  - &lt;serverless plugin name&gt;
</code></pre>
<h2 id="serverlessyml"><a class="header" href="#serverlessyml"><code>serverless.yml</code></a></h2>
<p>Can also be a json, js or ts file.</p>
<pre><code>service: users

functions: # Your "Functions"
  usersCreate:
    events: # The "Events" that trigger this function
      - httpApi: 'POST /users/create'
  usersDelete:
    events:
      - httpApi: 'DELETE /users/delete'

resources: # The "Resources" your "Functions" use.  Raw AWS CloudFormation goes in here.
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="spring-boot"><a class="header" href="#spring-boot">Spring Boot</a></h1>
<p><code>@Autowired</code> takes injected classes.</p>
<p><code>@Component</code>, <code>@Service</code> can be injected.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sql"><a class="header" href="#sql">SQL</a></h1>
<h2 id="indexes"><a class="header" href="#indexes">Indexes</a></h2>
<p>An index speeds up an additional table with the indexed column sorted.</p>
<p>Speeds up things used in <code>WHERE</code> or <code>JOIN ON</code> clauses.</p>
<p>For multicolumn indexes, order matters.</p>
<p><code>(a, b)</code> also speeds up queries of the type</p>
<pre><code class="language-sql">WHERE a = x
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="terraform"><a class="header" href="#terraform">Terraform</a></h1>
<pre><code>terraform init
</code></pre>
<p>Downloads and installs providers in <code>.terraform/</code> and creates a lock file
<code>.terraform.lock.hcl</code></p>
<pre><code>terraform apply
</code></pre>
<pre><code>terraform destroy
</code></pre>
<p>Terminates resources managed by terraform project. The inverse of
<code>terraform apply</code>.</p>
<h2 id="providers"><a class="header" href="#providers">Providers</a></h2>
<p>Configure specified provider.</p>
<p>Find terraform providers in the terraform registry.</p>
<p><code>main.tf</code></p>
<pre><code>provider "aws" {
  profile = "..."
  region  = "..."
}
</code></pre>
<h2 id="resources-1"><a class="header" href="#resources-1">Resources</a></h2>
<p>Define and configure components.</p>
<ul>
<li><code>resource type</code> - prefix maps to the name of the provdier, eg <code>aws_instance</code></li>
<li><code>resource name</code></li>
</ul>
<p>The resouce type and resource name form a uniqe id for the resource as
<code>&lt;resource_type&gt;.&lt;resource_name&gt;</code>.</p>
<p><code>main.tf</code></p>
<pre><code>resouces "&lt;resource type&gt;" "&lt;resource name&gt;" {
  ami = "..."
  instance_type = ""

  tags = {
    Name = "..."
  }
}
</code></pre>
<h2 id="state"><a class="header" href="#state">State</a></h2>
<p>Terraform uses the state to keep track of the resources it manages. The state
needs to be up to date.</p>
<p>File <code>terraform.tfstate</code>.</p>
<pre><code>terraform show
</code></pre>
<pre><code>terraform state list
</code></pre>
<p><strong>Note</strong>: state stores in plain text, so it contains sensitive information.</p>
<h3 id="backend---remote-state"><a class="header" href="#backend---remote-state">Backend - Remote State</a></h3>
<p>Define where terraform's state snapshots are stored.</p>
<h3 id="s3-1"><a class="header" href="#s3-1">S3</a></h3>
<pre><code>resource "aws_s3_bucket" "&lt;backend name&gt;" {
  bucket = "&lt;globally unique bucket name&gt;"

  lifecycle {
    prevent_destroy = true // prevents terraform to delete
  }

  versioning {
    enabled = true // allows us to see what the state was at a previous moment in time
  }

  server_side_encryption_configuration { // enable encryption of state file
    rule {
      apply_server_side_encryption_by_default {
        sse_algorithm = "AES256"
      }
    }
  }
}
</code></pre>
<p>Use DynamoDB to enable locking of state in order to prevent more than one user
to edit the state at the same time.</p>
<pre><code>resource "aws_dynamodb_table" "&lt;terraform lock&gt;" {
  name = "&lt;dynamodb name&gt;"
  billing_mode = "PAY_PER_REQUEST"
  hash_key = "LockID"

  attribute {
    name = "LockID"
    type = "S"
  }
}
</code></pre>
<p>Define state to use</p>
<pre><code>terraform {
  backend "s3" {
    bucket = "&lt;bucket name&gt;"
    key = "global/s3/terraform.tfstate" // Folder path in bucket to store state file
    region = "&lt;aws region&gt;"
    dynamodb_table = "&lt;dynamodb name&gt;"
    encrypt = true
  }
}
</code></pre>
<p><strong>Remark</strong>: The target backend needs to exist in order for terraform to be able
to use it.</p>
<h2 id="variables-1"><a class="header" href="#variables-1">Variables</a></h2>
<h3 id="input-1"><a class="header" href="#input-1">Input</a></h3>
<p>Terraform automatically loads variable values from any files that end in
<code>.tfvars</code>.</p>
<h4 id="file-variablestf"><a class="header" href="#file-variablestf">File <code>variables.tf</code></a></h4>
<p><code>variables.tf</code></p>
<pre><code>variable "instance_name" {
  description = "Value of the Name tag for the EC2 instance"
  type        = string
  default     = "ExampleAppServerInstance"
}
</code></pre>
<p>Use variables in <code>main.tf</code> by syntax <code>var.instance_name</code>.</p>
<h4 id="cli-parameter"><a class="header" href="#cli-parameter">CLI parameter</a></h4>
<p><code>terraform apply -var 'instance_name=AnotherName'</code>.</p>
<h3 id="output-1"><a class="header" href="#output-1">Output</a></h3>
<p><code>outputs.tf</code></p>
<p>Terraform outputs output variables to the screen on <code>terraform apply</code>.</p>
<p>Output variables can be queried with <code>terraform output</code>.</p>
<h2 id="syntax"><a class="header" href="#syntax">Syntax</a></h2>
<pre><code>terraform fmt
</code></pre>
<pre><code>terraform validate
</code></pre>
<h2 id="terraform-cloud"><a class="header" href="#terraform-cloud">Terraform Cloud</a></h2>
<p>Requires an account available with <code>terraform login</code>.</p>
<h2 id="modules"><a class="header" href="#modules">Modules</a></h2>
<p>A module is a directory containing <code>.tf</code> files. When running commands in that
directory it is considered the <strong>root module</strong>.</p>
<p><strong>Best practice</strong>: Name your provider <code>terraform-&lt;PROVIDER&gt;-&lt;NAME&gt;</code>.</p>
<p>Install modules by using either <code>terraform get</code> or <code>terraform init</code>. Remote
plugins will be downloaded to the <code>.terraform</code> directory.</p>
<h3 id="using-a-module"><a class="header" href="#using-a-module">Using a Module</a></h3>
<p>Use a module with the <code>source</code> argument, it can be either</p>
<ul>
<li>Terraform Registry</li>
<li>HTTP URLs</li>
<li>local path</li>
<li>GitHub</li>
<li>S3 bucket</li>
<li>Modules in Package Sub-directories</li>
</ul>
<p>Declare a module inside a <code>module</code> block.</p>
<pre><code>module "&lt;a name&gt;" {
  source = "./modules/&lt;local path module&gt;"

  &lt;module input variables&gt;
}
</code></pre>
<p>Modules have</p>
<ul>
<li><em>required</em> and <em>optional</em> inputs</li>
<li>outputs accessible by <code>module.&lt;MODULE NAME&gt;.&lt;OUTPUT NAME&gt;</code></li>
</ul>
<p>When Terraform processes a module block, it will inherit the provider from the
enclosing configuration.</p>
<p><strong>Best practice</strong>: Do not include provider blocks in modules.</p>
<h3 id="structure"><a class="header" href="#structure">Structure</a></h3>
<p><strong>Best practice</strong>:</p>
<pre><code>.
├── LICENSE
├── README.md
├── main.tf
├── variables.tf
├── outputs.tf
├── modules
│   └── &lt;module&gt;
</code></pre>
<p><code>variables.tf</code> will define inputs when used as a module. Variables without
a default value will become required inputs.</p>
<p>Don't distribute <code>terraform.tfstate</code>, <code>terraform.tfstate.backup</code>, <code>.terraform</code>,
<code>*.tfvars</code> (they contain sensitive information).</p>
<p><code>LICENSE</code> and <code>README.md</code> are not used by Terraform.</p>
<h3 id="separate-states"><a class="header" href="#separate-states">Separate States</a></h3>
<p>Don't use <code>terraform apply -target x</code> to separate states.</p>
<p>Two methods:</p>
<ul>
<li>directories,</li>
<li>workspaces.</li>
</ul>
<h4 id="directories"><a class="header" href="#directories">Directories</a></h4>
<pre><code>├── prod
│   ├── main.tf
│   ├── variables.tf
│   ├── terraform.tfstate
│   └── terraform.tfvars
└── dev
    ├── main.tf
    ├── variables.tf
    ├── terraform.tfstate
    └── terraform.tfvars
</code></pre>
<h4 id="workspaces"><a class="header" href="#workspaces">Workspaces</a></h4>
<p>Use same Terraform code but have different state files.</p>
<pre><code>terraform workspace new &lt;workspace name&gt;
</code></pre>
<pre><code>terraform apply -var-file=&lt;environment variable file&gt;.tfvars
</code></pre>
<pre><code>terraform destroy -var-file=&lt;environment variable file&gt;.tfvars
</code></pre>
<pre><code>terraform workspace list
</code></pre>
<pre><code>terraform workspace select &lt;environment&gt;
</code></pre>
<p>Terraform workspace name is accessible with <code>terraform.workspace</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="clean-architecture"><a class="header" href="#clean-architecture">Clean Architecture</a></h1>
<h2 id="design-and-architecture"><a class="header" href="#design-and-architecture">Design and Architecture</a></h2>
<p>When software design done right, the maintaining phase is identified by:</p>
<ul>
<li>Requires a fraction of the human resources.</li>
<li>Changes are simple and rapid.</li>
<li>Defects are few and far between.</li>
<li>Effort is minimized.</li>
<li>Functionality and flexibility are maximized.</li>
</ul>
<h3 id="definition"><a class="header" href="#definition">Definition</a></h3>
<pre><code class="language-emph">The goal of software architecture is to minimize the human resources required to
build and maintain the required system.
</code></pre>
<p>The <em>measure</em> of design quality is the effort required to meet the needs of the customer.
If the effort is low, and stays low throughout the lifetime of the system, the
design is good. If that effort grows with each new release, the design is bad.</p>
<p>To build a system with a design and an architecture that minimize effort and
maximize productivity, you need to know which attributes of system architecture
lead to that end.</p>
<h3 id="behaviour-and-structure"><a class="header" href="#behaviour-and-structure">Behaviour and Structure</a></h3>
<p>Behaviour and structure are two values that needs to remain high.</p>
<p>A change must be easy to make.</p>
<p>The difficulty of a change should only be proportional to the scope of the change,
and not the shape of the change.</p>
<p>If the difficulty of change <em>is</em> proportional to the shape of the change, then
the cost of development will increase over time.</p>
<p>It's a quality of the architecture that it might prefer a certain shape over
another, but this will make new features harder and harder to implement.
Therefore architecture should be shape agnostical.</p>
<h2 id="paradigms"><a class="header" href="#paradigms">Paradigms</a></h2>
<p>Paradigms tell you which programming structures to use, and when to use them.</p>
<ul>
<li>Structured programming</li>
<li>Object-oriented programming</li>
<li>Functional programming</li>
</ul>
<p>These three paradigms impose dicipline in different ways</p>
<ul>
<li>Structured programming imposes dicipline on direct transfer of control.</li>
<li>Object-oriented programming imposes dicipline on indirect transfer of control.</li>
<li>Functional programming imposes dicipline upon assignment.</li>
</ul>
<p>These diciplines are linked to architecture</p>
<ul>
<li>We use structured programming as the algorithmic foundation of our modules.</li>
<li>We use polymorphism as the mechanism to cross architectural boundaries.</li>
<li>We use functional programming to impose dicipline on the location of and
access to data.</li>
</ul>
<h3 id="structured-programming"><a class="header" href="#structured-programming">Structured Programming</a></h3>
<p>Recursively decompose a program into a set of small provable functions. We can
then use tests to try and prove those small provable functions incorrect. If
such tests fail to prove incorrectness, then we deem the functions to be correct
enough for our purposes.</p>
<h3 id="object-oriented-programming"><a class="header" href="#object-oriented-programming">Object-oriented Programming</a></h3>
<p><em>Dependency inversion</em>: the code using another, does not need to name it.</p>
<p>Since OO languages provide safe and convinient polymorphism means that any
source code dependency, no matter where it is, can be inverted (by using interfaces).</p>
<p>OO languages means that software architects have absolute control over the
direction of source code dependencies.</p>
<p>OO is the ability, through the use of polymorphism, to gain absolute control
over every source code dependency in the system. It allows the architect to
create a plugin architecture, in which modules that that contain high-level
policies are independent of modules that contain low-level details. The
low-level details are regulated to plugin modules that can be deployed and
developed independently from the modules that contain high-level policies.</p>
<h3 id="functional-programming"><a class="header" href="#functional-programming">Functional Programming</a></h3>
<p>Variables in functional languages do not vary.</p>
<p>Immutability means no problems with race conditions, deadlock conditions or
concurrent update problems.</p>
<h4 id="segregation-of-mutability"><a class="header" href="#segregation-of-mutability">Segregation of Mutability</a></h4>
<p>A common practice is to segregate the application into immutable and mutable
components. Mutable components needs to be safeguarded from concurrency by
transactions. It is wise to push as much processing as possible into the
immutable components, and use as little as possible in the mutable components.</p>
<h4 id="event-sourcing"><a class="header" href="#event-sourcing">Event Sourcing</a></h4>
<p>Store the transactions, not the state.</p>
<h2 id="design-principles"><a class="header" href="#design-principles">Design Principles</a></h2>
<h3 id="solid-principles"><a class="header" href="#solid-principles">SOLID Principles</a></h3>
<ul>
<li>SRP: The Single Responsibility Principle</li>
<li>OCP: The Open-Closed Principle</li>
<li>LSP: The Liskov Substitution Principle</li>
<li>ISP: The Interface Segregation Principle</li>
<li>DIP: The Dependency Inversion Principle</li>
</ul>
<p>The goal of the principles is the creation of mid-level software structures that</p>
<ul>
<li>Tolerate change</li>
<li>Are easy to understand</li>
<li>Are the basis of components that can be used in many software systems</li>
</ul>
<h4 id="srp-the-single-responsibility-principle"><a class="header" href="#srp-the-single-responsibility-principle">SRP: The Single Responsibility Principle</a></h4>
<p>Each software module should have one, and only one, reason to change. Or more accurate</p>
<p><em>A module should be responsible to one, and only one, actor.</em></p>
<p>Here, a <em>module</em> can be thought of as a source file.</p>
<p>An <em>actor</em> can be thought of as a common group of stakeholders.</p>
<p>The SRP comes at play, for example, when different modules uses the same
algorithm. SRP then states that the modules should <em>not</em> be merged, because at a
later time one part using the algorithm might need a change but not the other.</p>
<p>[In this scenario, SRP actually promotes duplication of code.]</p>
<p>The SRP appears at three different levels</p>
<ul>
<li>Functions and classes</li>
<li>Components (<em>Common Closure Principle</em>)</li>
<li>Architectural (<em>Axis of Change</em>)</li>
</ul>
<h4 id="ocp-the-open-closed-principle"><a class="header" href="#ocp-the-open-closed-principle">OCP: The Open-Closed Principle</a></h4>
<p>For software systems to be easy to change, they must be designed to allow the
behaviour of those systems to be changed by adding new code, rather than
changing existing code.</p>
<p>If component A should be protected from changes in component B, then component B
should depend on component A.</p>
<p>The goal is to make the system easy to extend without incurring a high impact of
change. This goal is acomplished by partitioning the system into components,
and arranging those components into a dependency hierarchy that protects
higher-level components from changes in lower-level components.</p>
<h4 id="lsp-the-liskov-substitution-principle"><a class="header" href="#lsp-the-liskov-substitution-principle">LSP: The Liskov Substitution Principle</a></h4>
<p>To build a system from interchangeable parts, those parts must adhere to to a
contract that allows those parts to be substituted one for another.</p>
<p>Barbara Liskov defined subtypes in terms of a substitution property:</p>
<pre><code class="language-definition">If for each object o1 of type S, there is an object o2 of type T such that for
all programs P defined in terms of T, the behaviour of P is unchanged when o1 is
substituted for o2, then S is a subtype of T.
</code></pre>
<h4 id="isp-the-interface-segregation-principle"><a class="header" href="#isp-the-interface-segregation-principle">ISP: The Interface Segregation Principle</a></h4>
<p>In general it is harmful to depend on things that contain more than you need. A
change in such a module would require changes in modules that should not be
affected by the change.</p>
<h4 id="dip-the-dependency-inversion-principle"><a class="header" href="#dip-the-dependency-inversion-principle">DIP: The Dependency Inversion Principle</a></h4>
<p>Code that implements high-level policy should not depend on the code that
implements low-level details. Rather, details should depend on policies.</p>
<p>The most flexible systems are those in which source code refers only to
abstractions, not to concretions.</p>
<ul>
<li>Don't refer to volatile concrete classes. (Refer to abstract interfaces
instead, creation of objects should in general use <em>Abstract Factories</em>).</li>
<li>Don't derive from volatile concrete classes.</li>
<li>Don't override concrete functions.</li>
<li>Never mention the name of anything concrete and volatile.</li>
</ul>
<p>DIP violations cannot be entirely removed, but they can be gathered into a small
number of concrete components and kept separate from the rest of the system.</p>
<p><strong>Note</strong>: Dependency Injection is <em>one</em> way to achieve this.</p>
<h2 id="components-1"><a class="header" href="#components-1">Components</a></h2>
<p>Components are the units of deployment. Well designed components always retain
the ability to be independently deployable, and therefore also independently developable.</p>
<h3 id="component-cohesion"><a class="header" href="#component-cohesion">Component Cohesion</a></h3>
<ul>
<li>REP: The Reuse/Release Equivalence Principle</li>
<li>CCP: The Common Closure Principle</li>
<li>CRP: The Common Reuse Principle</li>
</ul>
<h4 id="rep-the-reuserelease-equivalence-principle"><a class="header" href="#rep-the-reuserelease-equivalence-principle">REP: The Reuse/Release Equivalence Principle</a></h4>
<p><em>The granule of reuse is the granule of release.</em></p>
<p>Classes and and modules that are formed into a component must belong to a
cohesive group. Classes and modules that are grouped together into a component
should be <em>releaseable</em> together. I.e. if classes and modules are released under
the same version, it should make sense.</p>
<h4 id="ccp-the-common-closure-principle"><a class="header" href="#ccp-the-common-closure-principle">CCP: The Common Closure Principle</a></h4>
<p><em>Gather into components those classes that change for the same reasons and at
the same times. Separate into different components those classes that change at
different times and for different reasons.</em></p>
<p>A component should not have multiple reasons to change (see SRP).</p>
<p>If changes are confined to a single component, then we need only to redeploy the
changed component, which in turn lowers to effort of change.</p>
<p>Group into components that are likely to change for the same reasons and are
closed to the same type of changes.</p>
<h4 id="crp-the-common-reuse-principle"><a class="header" href="#crp-the-common-reuse-principle">CRP: The Common Reuse Principle</a></h4>
<p><em>Don't force users of a component to depend on things they don't need.</em></p>
<p>Classes and modules that tend to change together belong in the same component,
and vice verca.</p>
<p>Classes in a component should be inseparable.</p>
<h4 id="rep-ccp-and-crp-interplay"><a class="header" href="#rep-ccp-and-crp-interplay">REP, CCP and CRP Interplay</a></h4>
<p>REP and CCP are <em>inclusive</em> driving components to be larger. CRP is <em>exclusive</em>,
driving components to be smaller.</p>
<p>REP: group for reuse.
CCP: Group for maintenance.
CRP: Split to avoid unneeded releases.</p>
<ul>
<li>REP and CRP: Too many components are impacted when simple changes are made.</li>
<li>CCP and REP: Too many unneeded releases to be generated.</li>
<li>CRP and CCP: Hard to reuse.</li>
</ul>
<h3 id="component-coupling"><a class="header" href="#component-coupling">Component Coupling</a></h3>
<p>Component dependency diagrams have very little to do with describing the
function of the application. Rather, they're a build of the <em>buildability</em> and
<em>maintainability</em> of the application. Hence, they are not designed at the
beginning of the project.</p>
<h4 id="adp-the-acyclic-dependencies-principle"><a class="header" href="#adp-the-acyclic-dependencies-principle">ADP: The Acyclic Dependencies Principle</a></h4>
<p>The component dependency graph must be a <em>DAG</em> (Directed Acyclic Graph).</p>
<p>For solving non-DAG structures, either</p>
<ul>
<li>apply DIP, or</li>
<li>create a new component that both depend on.</li>
</ul>
<h4 id="sdp-the-stable-dependency-principle"><a class="header" href="#sdp-the-stable-dependency-principle">SDP: The Stable Dependency Principle</a></h4>
<p>Depend in the direction of stability.</p>
<p>An instability metric:</p>
<pre><code>I = Fan out / (Fan in + Fan out)
</code></pre>
<p>The metric I should decrease in the direction of dependency.</p>
<h4 id="sap-the-stable-abstractions-principle"><a class="header" href="#sap-the-stable-abstractions-principle">SAP: The Stable Abstractions Principle</a></h4>
<p>A component should be as abstract as it is stable.</p>
<p>Software that encapsulated high-level policies should be placed in stable
components (I = 0). Unstable components (I = 0) should contain onlt the software
that is volatile, that we want to be easy to change.</p>
<p>An abstractness metric:</p>
<pre><code>A = no. classes in component / (no. abstract classes + no. interfaces)
</code></pre>
<h4 id="sap--sdp--dip-for-components"><a class="header" href="#sap--sdp--dip-for-components">SAP + SDP = DIP for Components</a></h4>
<p>SDP: dependencies should run in the direction of stability.</p>
<p>SAP: stability implies abstraction.</p>
<p>Thus: dependencies shold run in the direction of abstraction.</p>
<h4 id="relation-between-instability-and-abstraction"><a class="header" href="#relation-between-instability-and-abstraction">Relation Between Instability and Abstraction</a></h4>
<p>Instability and abstraction is inversly corrolated.</p>
<p><em>The Main Sequence</em></p>
<pre><code>A + I = 1
</code></pre>
<p><em>Zone of Pain</em> is where A and I are both close to 0 (e.g. databases). Volatile
components in this zone is problematic.</p>
<p><em>Zone of Uselessness</em> is where A and I are both close to 1.</p>
<p>Distance from the main sequence</p>
<pre><code>D = |A + I - 1|
</code></pre>
<p>any component that has a D metric that is not near zero should be restructured.</p>
<h2 id="architecture"><a class="header" href="#architecture">Architecture</a></h2>
<p>Systems architecture is the shape of the system:</p>
<ul>
<li>The division of that system into components,</li>
<li>The arrangement of the components,</li>
<li>The ways in which the components communicate with each other.</li>
</ul>
<p>The ultimate purpose of the architecture is to</p>
<ul>
<li>Minimize the lifetime cost of the system,</li>
<li>Maximize the programmer productivity.</li>
</ul>
<p>This is done by considering how the architecture:</p>
<ul>
<li>Facilitates the development,</li>
<li>Facilitates the deployment,</li>
<li>Facilitates the operation,</li>
<li>Facilitates the maintenance.</li>
</ul>
<p>Good architecture are systems that are:</p>
<ul>
<li>Easy to understand,</li>
<li>Easy to develop,</li>
<li>Easy to maintain,</li>
<li>Easy to develop.</li>
</ul>
<h3 id="keeping-options-open"><a class="header" href="#keeping-options-open">Keeping Options Open</a></h3>
<p>Software systems can be divided into two components: <em>Policy</em> and <em>Details</em>.</p>
<p>Policy: embodies all the business rules and procedures.</p>
<p>Details: things that are necessary to enable communicate with the policy, but
does not impact the policy.</p>
<p>Leave as many options open as possible, for as long as possible; the options
that are to be kept open are the details. This leaves room for making more
informed decisions.</p>
<p>Architecture should make policy the most essential part of the system while
making the details irrelevant to that policy.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vocabulary"><a class="header" href="#vocabulary">Vocabulary</a></h1>
<p><strong>Continous Integration (CI)</strong>: A strategy on how to integrate code with the
mainline code continously. Depends upon automatic building and testing within
the development environment.</p>
<p><strong>Continous Delivery</strong>: Extentsion of CI, meaning that code can be put easily
into production. Automatic building and testing in the production environment
as well as automatic deployment.</p>
<p><strong>Continous Deployment</strong>: Different opinions.</p>
<p><strong>Infrastructure as Code (IaC)</strong>: Define the infrastructure in source files.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="motivation"><a class="header" href="#motivation">Motivation</a></h1>
<p>I want to move forward all the time and not stand still. Even if my current
approach is not solving the problem I want it to matter and be a step towards
the solution.</p>
<h1 id="goals"><a class="header" href="#goals">Goals</a></h1>
<ul>
<li>I want to avoid going in cirles; redo the same approach several times if it is
unsuccesseful because this wastes time and creates a stand still.</li>
<li>Even if an approach doesn't solve the problem, I want to be clear on
what sub-goals and conclusions I can get from the approach.</li>
</ul>
<h1 id="strategy"><a class="header" href="#strategy">Strategy</a></h1>
<h3 id="divide-the-problem"><a class="header" href="#divide-the-problem">Divide the problem.</a></h3>
<p>Try to divide the problem into isolated parts that can be solved individually.</p>
<h1 id="procedure"><a class="header" href="#procedure">Procedure</a></h1>
<ol>
<li>When I have a task that needs to be done, the first step should be to stop
and turn to pen and paper.</li>
<li>Try to clearly define the goal and come up with different strategies for
achieving this.</li>
<li>Weigh the different strategies against each other and initially choose one
to start with.</li>
<li>Be clear on what strategy is choosen and try exactly this (if I get new
ideas, write them down on paper for later consideration).</li>
<li>When I reach some kind of end point of the choosen approach, evaluate the
conclusions and save them.</li>
</ol>
<p>When working on one approach, set all others aside. If I get a new idea while
doing an approach: write it down and save for later.</p>
<h1 id="-3"><a class="header" href="#-3"></a></h1>
<ul>
<li>Work become more granulary, and it feels less
heavy.</li>
<li>It is easier to find a comfortable pace.</li>
<li>Gets you more mentally involved and increases understanding of what I'm
acutally trying to solve.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="project-1"><a class="header" href="#project-1">Project</a></h1>
<p>Declarative IoT</p>
<h2 id="easy-to-refactor"><a class="header" href="#easy-to-refactor">Easy to Refactor</a></h2>
<p>Keep code as modular as possible.</p>
<p>Keep coupling as low as possible.</p>
<p>Tested code is easier to refactor.</p>
<h2 id="reduce-cognitive-load"><a class="header" href="#reduce-cognitive-load">Reduce Cognitive Load</a></h2>
<p>Repetition and pedagogical code is good.</p>
<h2 id="things-id-like-to-inclue"><a class="header" href="#things-id-like-to-inclue">Things I'd Like to Inclue</a></h2>
<ul>
<li>DDD</li>
<li>Twelve Factor App</li>
<li>3-Tier Architecture</li>
<li>Easy to run locally</li>
<li>Easy to scale backend</li>
<li>Don't skip documentation, assume I'm going to forget</li>
</ul>
<hr />
<h2 id="phases"><a class="header" href="#phases">Phases</a></h2>
<h3 id="design-and-prototype"><a class="header" href="#design-and-prototype">Design and Prototype</a></h3>
<ul>
<li>What data manipulation is needed?
<ul>
<li>What are the CRUD operations?</li>
<li>HTTP verbs map well to CRUD</li>
</ul>
</li>
<li>DDD</li>
</ul>
<h3 id="development-phase"><a class="header" href="#development-phase">Development Phase</a></h3>
<h3 id="maintenance-phase"><a class="header" href="#maintenance-phase">Maintenance Phase</a></h3>
<ul>
<li>Implement Features</li>
<li>Fix Bugs</li>
<li>Build</li>
<li>Test</li>
<li>Deploy</li>
<li>Scaling</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
